# Model Call Refinement 2: Complex Job Processing

This document provides a complete, verified, and end-to-end implementation plan for complex job management logic into the AI chat service. This feature will allow the system to handle requests that are too large for the input to fix in the model's input window, or too complex for the model to complete in a single pass.

## Legend

*   `[ ]` 1. Unstarted work step. Each work step will be uniquely named for easy reference. We begin with 1.
    *   `[ ]` 1.a. Work steps will be nested as shown. Substeps use characters, as is typical with legal documents.
        *   `[ ]` 1. a. i. Nesting can be as deep as logically required, using roman numerals, according to standard legal document numbering processes.
*   `[✅]` Represents a completed step or nested set.
*   `[🚧]` Represents an incomplete or partially completed step or nested set.
*   `[⏸️]` Represents a paused step where a discovery has been made that requires backtracking or further clarification.
*   `[❓]` Represents an uncertainty that must be resolved before continuing.
*   `[🚫]` Represents a blocked, halted, or stopped step or has an unresolved problem or prior dependency to resolve before continuing.

## Component Types and Labels

The implementation plan uses the following labels to categorize work steps:

*   `[DB]` Database Schema Change (Migration)
*   `[RLS]` Row-Level Security Policy
*   `[BE]` Backend Logic (Edge Function / RLS / Helpers / Seed Data)
*   `[API]` API Client Library (`@paynless/api` - includes interface definition in `interface.ts`, implementation in `adapter.ts`, and mocks in `mocks.ts`)
*   `[STORE]` State Management (`@paynless/store` - includes interface definition, actions, reducers/slices, selectors, and mocks)
*   `[UI]` Frontend Component (e.g., in `apps/web`, following component structure rules)
*   `[CLI]` Command Line Interface component/feature
*   `[IDE]` IDE Plugin component/feature
*   `[TEST-UNIT]` Unit Test Implementation/Update
*   `[TEST-INT]` Integration Test Implementation/Update (API-Backend, Store-Component, RLS)
*   `[TEST-E2E]` End-to-End Test Implementation/Update
*   `[DOCS]` Documentation Update (READMEs, API docs, user guides)
*   `[REFACTOR]` Code Refactoring Step
*   `[PROMPT]` System Prompt Engineering/Management
*   `[CONFIG]` Configuration changes (e.g., environment variables, service configurations)
*   `[COMMIT]` Checkpoint for Git Commit (aligns with "feat:", "test:", "fix:", "docs:", "refactor:" conventions)
*   `[DEPLOY]` Checkpoint for Deployment consideration after a major phase or feature set is complete and tested.

---

## File Structure for Supabase Storage and Export Tools

{repo_root}/  (Root of the user's GitHub repository)
└── {project_name_slug}/
    ├── project_readme.md      (Optional high-level project description, goals, defined by user or initial setup, *Generated at project finish, not start, not yet implemented*)
    ├── {user_prompt}.md (the initial prompt submitted by the user to begin the project generated by createProject, whether provided as a file or text string, *Generated at project start, implemented*)
    ├── project_settings.json (The json object includes keys for the dialectic_domain row, dialectic_process_template, dialectic_stage_transitions, dialectic_stages, dialectic_process_associations, domain_specific_prompt_overlays, and system_prompt used for the project where the key is the table and the value is an object containing the values of the row, *Generated on project finish, not project start, not yet implemented*)
    ├── {export_project_file}.zip (a zip file of the entire project for the user to download generated by exportProject)
    ├── general_resource (all optional)
    │    ├── `{deployment_context}` (where/how the solution will be implemented), 
    │    ├── `{domain_standards}` (domain-specific quality standards and best practices), 
    │    ├── `{success_criteria}` (measurable outcomes that define success), 
    │    ├── `{constraint_boundaries}` (non-negotiable requirements and limitations), 
    │    ├── `{stakeholder_considerations}` (who will be affected and how),
    │    ├── `{reference_documents}` (user-provided reference materials and existing assets), 
    │    └── `{compliance_requirements}` (regulatory, legal, or organizational compliance mandates)    
    ├── Pending/          (System-managed folder populated as the final step of the Paralysis stage)
    │   └── ...                     (When the user begins their work, they move the first file they're going to work on from Pending to Current)
    ├── Current/          (User-managed folder for the file they are actively working on for this project)
    │   └── ...                     (This is the file the user is currently working on, drawn from Pending)
    ├── Complete/         (User-managed folder for the files they have already completed for this project)       
    │   └── ...                     (When the user finishes all the items in the Current file, they move it to Complete, and move the next Pending file into Current)
    └── session_{session_id_short}/  (Each distinct run of the dialectic process)
        └── iteration_{N}/        (N being the iteration number, e.g., "iteration_1")
            ├── 1_thesis/
            │   ├── raw_responses
            │   │   └──{model_name_slug}_{n}_thesis_raw.json
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_name_slug}_{n}_thesis.md (Contains YAML frontmatter + AI response, appends a count so a single model can provide multiple contributions)
            │   ├── ... (other models' hypothesis outputs)
            │   ├── user_feedback_hypothesis.md   (User's feedback on this stage)
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            ├── 2_antithesis/
            │   ├── raw_responses
            │       └── {model_slug}_critiquing_{source_model_slug}_{n}_antithesis_raw.json
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_critiquing_{source_model_slug}_{n}_antithesis.md
            │   ├── ...
            │   ├── user_feedback_antithesis.md
            │   └── documents/                    (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])                
            ├── 3_synthesis/
            │   ├── _work/          (Storage for intermediate, machine-generated artifacts that are not final outputs)
            └── raw_responses/
            │   ├── {model_slug}_from_{source_model_slugs}_{n}_pairwise_synthesis_chunk_raw.json
            │   ├── {model_slug}_reducing_{source_contribution_id_short}_{n}_reduced_synthesis_raw.json
            │   └── {model_slug}_{n}_final_synthesis_raw.json
            ├── _work/
            │   ├── {model_slug}_from_{source_model_slugs}_{n}_pairwise_synthesis_chunk.md
            │   └── {model_slug}_reducing_{source_contribution_id_short}_{n}_reduced_synthesis.md
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_{n}_final_synthesis.md
            │   ├── ...
            │   ├── user_feedback_synthesis.md
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            ├── 4_parenthesis/
            │   ├── raw_responses
            │   │   └──{model_name_slug}_{n}_{stage_slug}_raw.json
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_name_slug}_{n}_{stage_slug}.md
            │   ├── ...
            │   ├── user_feedback_parenthesis.md
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            └── 5_paralysis/
                ├── raw_responses
                │   └──{model_name_slug}_{n}_{stage_slug}_raw.json
                ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
                ├── {model_name_slug}_{n}_{stage_slug}.md
                ├── ...
                └── documents/                      (Optional refined documents, e.g., PRDs from each model)
                    └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])

---

### Phase 9: [REFACTOR] Implement Tiered Context Window Management

This phase implements the critical, tiered strategy for managing model context window limitations without resorting to naive summarization, as defined in the "Computable Determinant" architecture.

#### 25. [BE] [DB] Create and Integrate Prerequisite "Combination" Job Logic

*   `[✅]` 25.a. **Enhance Jobs Table for Prerequisite Tracking:**
    *   `[DB]` **Action:** In a new migration, add a `prerequisite_job_id` (nullable, UUID, foreign key to `dialectic_generation_jobs.id`) to the `dialectic_generation_jobs` table.
    *   `[DB]` **Action:** Add a new job status: `'waiting_for_prerequisite'`.
*   `[✅]` 25.b. **Implement Combination Prompt Strategy:**
    *   `[BE]` `[PROMPT]` **Action:** In the `system_prompts` table, create a new entry for the combination job. It should be along the lines of: *"You are a document synthesis agent. Combine the following documents into a single, coherent text. You must preserve every unique fact, requirement, argument, and detail. Eliminate only redundant phrasing or conversational filler."*
*   `[✅]` 25.c. **[REFACTOR] Implement a Modular, Reusable Model Execution Utility:**
    *   `[✅]` 25.c.i. **Goal:** To refactor the shared logic for calling AI models and saving results into a single, reusable utility, adhering to DRY and SRP principles.
    *   `[✅]` 25.c.ii. **Create Generic `executeModelCallAndSave` Utility:**
        *   `[BE]` `[TEST-UNIT]` **(RED)** Create a new test file: `supabase/functions/dialectic-worker/executeModelCallAndSave.test.ts`. Write a failing test that calls a mock of this utility, providing a prepared prompt and context. Assert that the AI adapter is called and that the `FileManager` is invoked to save the result.
        *   `[BE]` `[REFACTOR]` **(GREEN)** Create the file: `supabase/functions/dialectic-worker/executeModelCallAndSave.ts`. Move the common logic from `processSimpleJob.ts` (the part that calls `callUnifiedAIModel`, handles the response, and then calls the `FileManager` to save the contribution) into this new function.
        *   `[TEST-UNIT]` **(PROVE)** Prove the unit tests for the new utility pass.
    *   `[✅]` 25.c.iii. **Refactor `processSimpleJob` into a "Preparer":**
        *   `[BE]` `[TEST-UNIT]` **(RED)** Update the tests in `processSimpleJob.test.ts`. They should no longer assert that the AI adapter or `FileManager` are called directly. Instead, they should assert that `processSimpleJob` correctly performs its setup (using `PromptAssembler` with stage recipes) and then calls the new `executeModelCallAndSave` utility with the correctly prepared parameters.
        *   `[BE]` `[REFACTOR]` **(GREEN)** Refactor `processSimpleJob.ts`. Remove the logic that was just moved and replace it with a call to the new utility. Its sole responsibility is now preparing the context for a stage-based job.
        *   `[TEST-UNIT]` **(PROVE)** Prove the refactored `processSimpleJob` tests pass.
    *   `[✅]` 25.c.iv. **Implement `processCombinationJob` as a "Preparer":**
        *   `[BE]` `[TEST-UNIT]` **(RED)** Create a new test file: `supabase/functions/dialectic-worker/processCombinationJob.test.ts`. Write a failing test that asserts this new function correctly prepares the context for a utility combination job (fetches the specific 'Tier 2 Document Combiner' prompt, gets documents from the payload) and then calls `executeModelCallAndSave`.
        *   `[BE]` `[REFACTOR]` **(GREEN)** Create the file: `supabase/functions/dialectic-worker/processCombinationJob.ts`. Implement the simple setup logic and have it call the shared `executeModelCallAndSave` utility.
        *   `[TEST-UNIT]` **(PROVE)** Prove the `processCombinationJob` tests pass.
    *   `[✅]` 25.c.v. **Update the Main Worker Router:**
        *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/processJob.ts`.
        *   `[BE]` `[REFACTOR]` **Action:** The main router must be updated to delegate to the new `processCombinationJob` module when a job with `job_type: 'combine'` is received.
*   `[✅]` 25.d. **Implement Orchestration for Prerequisite Jobs:**
    *   `[DB]` **File:** The `handle_child_job_completion()` PostgreSQL function.
    *   `[DB]` `[REFACTOR]` **Action:** The trigger function must be enhanced to be a more generic `handle_job_completion()` orchestrator. When a job completes, it must check both of the following:
        1.  **Parent/Child:** Does this job have a `parent_job_id`? If so, check if all siblings are complete to wake the parent.
        2.  **Prerequisite/Waiting:** Does any other job list this job's `id` in its `prerequisite_job_id` field? If so, update the waiting job's status from `'waiting_for_prerequisite'` to `'pending'`.

#### 26. [BE] [REFACTOR] Integrate Tiered Context Window Management

This step implements a hybrid, two-layer defense mechanism to manage model context windows, ensuring both efficient orchestration and absolute safety against API errors. The strategy involves an initial check at the "planning" stage and a final validation at the "execution" stage.

*   `[✅]` 26.a. **Create `ContextWindowError` Custom Error:**
    *   `[BE]` **File:** `supabase/functions/_shared/utils/errors.ts`.
    *   `[BE]` **Action:** Create and export a new custom error class, `ContextWindowError`, that extends the base `Error` class. This allows for specific `catch` blocks in the worker logic.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/_shared/utils/errors.ts
        export class ContextWindowError extends Error {
          constructor(message: string) {
            super(message);
            this.name = 'ContextWindowError';
          }
        }
        ```

*   `[✅]` 26.b. **Implement Tier 2 Orchestration in the Complex Job Planner:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/task_isolator.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** The `planComplexStage` function will be modified to perform a pre-emptive check on the collected source documents *before* it attempts to plan child jobs.
    *   **Logic:**
        1.  **Location:** The new logic will be placed after the `validSourceDocuments` array is populated.
        2.  **Token Estimation:**
            *   Import `countTokensForMessages` from `supabase/functions/_shared/utils/tokenizer_utils.ts`.
            *   Fetch the `ai_providers` record for the `parentJob.payload.model_id` to get its `max_input_tokens` and `tokenization_strategy`.
            *   Map the `validSourceDocuments` to the `MessageForTokenCounting` format (`[{ role: 'user', content: doc.content }]`).
            *   Calculate the `estimatedTokens` for the entire collection of documents.
        3.  **Tier 1 (Context is OK):** If `estimatedTokens` is less than `max_input_tokens`, the function proceeds with its existing logic to plan and return child jobs.
        4.  **Tier 2 (Context is Too Large):** If `estimatedTokens` exceeds `max_input_tokens`:
            *   The function will create a *new* prerequisite job.
            *   **New Job Payload:**
                *   `job_type`: `'combine'`
                *   `payload`: Contains the `resource_ids` of all documents in `validSourceDocuments`. This gives the `processCombinationJob` worker the information it needs to fetch the content later.
                *   Inherit necessary fields from the `parentJob` (e.g., `sessionId`, `projectId`, `user_id`).
            *   **Database Operations:**
                *   Use `dbClient` to `insert` the new "combine" job into `dialectic_generation_jobs`.
                *   Use `dbClient` to `update` the original `parentJob`, setting its `status` to `'waiting_for_prerequisite'` and `prerequisite_job_id` to the ID of the new combine job.
            *   The function will then log this action and `return []`, halting the planning process for the current parent job until the prerequisite is met.

*   `[✅]` 26.c. **Implement Final Validation in the Model Executor:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/executeModelCallAndSave.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** This function will be modified to act as the final safeguard, validating the token count of the *fully rendered prompt* just before making the API call.
    *   **Logic:**
        1.  **Location:** The new logic will be placed immediately before the call to `deps.callUnifiedAIModel`.
        2.  **Token Calculation:**
            *   Import `countTokensForMessages` from `supabase/functions/_shared/utils/tokenizer_utils.ts`.
            *   Construct the `MessageForTokenCounting` array from the `renderedPrompt.content` and `previousContent`.
            *   Calculate the `finalTokenCount` using the `providerDetails` (which is an `AiModelExtendedConfig`).
        3.  **Validation:**
            *   If `finalTokenCount` exceeds `providerDetails.max_input_tokens`, the function will `throw new ContextWindowError(...)` with a detailed message. This is a hard failure, as the context is too large even after potential planning and combination. The check should account for a small buffer if necessary (e.g., `max_input_tokens * 0.98`).

*   `[✅]` 26.d. **Update Worker Error Handling:**
    *   `[BE]` `[REFACTOR]` **Files:** `supabase/functions/dialectic-worker/processSimpleJob.ts` and `supabase/functions/dialectic-worker/processComplexJob.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** The top-level `try/catch` block in these worker files must be updated to specifically handle the `ContextWindowError`.
    *   **Logic:**
        1.  Add `import { ContextWindowError } from '../_shared/utils/errors.ts';`.
        2.  Inside the `catch (e)` block, add a specific check: `if (e instanceof ContextWindowError) { ... }`.
        3.  **On Catch:**
            *   Log the specific error.
            *   Update the job's status to `'failed'`.
            *   Set the `error_details` field with a clear message explaining that the context window was exceeded and no strategy could resolve it.
            *   Use the `notificationService` to dispatch a user-facing failure notification. This ensures the user is informed about why the job could not be completed.

---

### Phase 10: [REFACTOR] Implement Reusable, Database-Driven Step Prompts

This phase refactors the worker to use pre-defined, reusable prompt templates for each step within a complex stage, making the system more modular and easier to maintain.

#### 27. [DB] [BE] Formalize Step Recipes and Prompts

*   `[✅]` 27.a. **Create Database Migration/Seed File:**
    *   `[DB]` **Action:** Create a new migration or seed file.
    *   `[DB]` **Action:** Seed the `system_prompts` table with specific, reusable prompt templates for each step of a complex stage.
        *   **Example 1 (`synthesis_step1_pairwise`):** *"As an expert synthesizer, your task is to analyze the following user prompt, an original thesis written to address it, and a single antithesis that critiques the thesis. Combine the thesis and antithesis into a more complete and accurate response that is more fit-for-purpose against the original user prompt. Preserve all critical details."*
        *   **Example 2 (`synthesis_step2_combine`):** *"As an expert editor, your task is to analyze the following user prompt and a set of preliminary syntheses. Combine these documents into a single, unified synthesis that is maximally fit-for-purpose against the original user prompt. You must eliminate redundancy and conflicting information while ensuring every unique and critical detail is preserved."*
*   `[✅]` 27.b. **Populate `synthesis` Stage with Recipe Data:**
    *   `[DB]` **Action:** Create a new, single-purpose migration file to populate the `synthesis` stage with its formal, multi-step recipe. This enables the worker to follow a pre-defined plan instead of using hardcoded logic.
    *   `[DB]` **Action:** In the new migration file, write an `UPDATE` statement for the `dialectic_stages` table, targeting the row where `slug = 'synthesis'`.
    *   `[DB]` **Implementation Detail:** The `UPDATE` statement will set the `input_artifact_rules` JSONB value to a new structure containing a `steps` array. Each object within this array will define a step, including a `prompt_template_name` that references the prompts seeded in step `27.a`. This action effectively applies the new recipe schema to the `synthesis` stage.
*   `[✅]` 27.c. **[BE] [REFACTOR] Update Job Enqueuer for Recipe Awareness:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-service/generateContribution.ts`
    *   `[BE]` `[REFACTOR]` **Action:** The logic must be updated to first fetch the stage recipe before creating the parent job. This is critical for populating the `step_info` object correctly.
    *   **Implementation Detail:**
        ```typescript
        // In generateContribution.ts, inside the main try block:

        // 1. Fetch the recipe for the stage
        const { data: stageDef, error: recipeError } = await dbClient
            .from('dialectic_stages')
            .select('input_artifact_rules')
            .eq('slug', stageSlug)
            .single();

        if (recipeError || !stageDef) {
            // Handle error: couldn't find the stage definition
            return { success: false, error: { message: `Could not find recipe for stage ${stageSlug}.`, status: 500 } };
        }
        
        // 2. Calculate total steps from the recipe
        const totalSteps = (stageDef.input_artifact_rules)?.steps?.length || 1;

        // 3. Inside the loop for creating jobs, construct the formal payload:
        const jobPayload: Json = {
            // ...existing context like projectId, sessionId, model_id
            job_type: 'plan',
            step_info: {
                current_step: 1,
                total_steps: totalSteps,
                status: 'pending',
            }
        };

        // 4. Insert the job with this new payload
        // ...
        ```

#### 28. [BE] [TEST-UNIT] Implement Core Granularity Strategy Functions

This step implements the core "Strategy" pattern for the complex job planner. It decouples the orchestration logic in `processComplexJob` from the specific logic of how to break down a task by creating a set of modular, testable "planner" functions. Each function aligns with a `granularity_strategy` defined in the stage recipes. The implementation will follow a strict Test-Driven Development (TDD) methodology.

*   `[✅]` 28.a. **Create Granularity Strategy Module & Directory Structure:**
    *   `[BE]` **Action:** Create a new directory: `supabase/functions/dialectic-worker/strategies/`. This will serve as the home for all planner-related logic.
    *   `[BE]` **Action:** Inside the new directory, create another directory: `planners/`. This will contain the individual planner function files.
    *   `[BE]` **Action:** Create the main strategy registry file: `supabase/functions/dialectic-worker/strategies/granularity.strategies.ts`.
    *   `[BE]` **Action:** In this file, define and export the `granularityStrategyMap` and the `getGranularityPlanner` function as specified in `A Computable Determinant for Task Isolation.md`. This map will associate strategy strings (e.g., `'pairwise_by_origin'`) with the actual planner function implementations.
    *   **Implementation Detail:**
        ```typescript
        // In granularity.strategies.ts
        import { planPairwiseByOrigin, planPerSourceDocument, planAllToOne, planPerSourceGroup } from './planners';

        export const granularityStrategyMap = {
          'per_source_document': planPerSourceDocument,
          'pairwise_by_origin': planPairwiseByOrigin,
          'per_source_group': planPerSourceGroup,
          'all_to_one': planAllToOne,
        };

        export function getGranularityPlanner(strategyId: string) {
            return granularityStrategyMap[strategyId] || planPerSourceDocument; // Default strategy
        }
        ```

*   `[✅]` 28.b. **Implement `planPairwiseByOrigin` Strategy (Map):**
    *   `[BE]` `[TEST-UNIT]` **(RED)** In the `strategies/planners/` directory, create a new test file: `planPairwiseByOrigin.test.ts`. Write a failing unit test that defines the function's contract.
        *   **Test Case:** Provide a mock set of source documents (e.g., 2 `thesis` contributions and 3 related `antithesis` contributions) and a mock parent job context.
        *   **Assertion:** Assert that the planner function returns the correct number of child job payloads and that each payload is correctly formed (e.g., `job_type: 'execute'`, correct `prompt_template_name`, and correctly paired `thesis_id` and `antithesis_id` in the `inputs`).
    *   `[BE]` `[TEST-UNIT]` **(RED)** Create helper utility tests. For example, in a new `strategy.helpers.test.ts` file, write failing tests for `groupSourceDocumentsByType` and `findRelatedContributions`.
    *   `[BE]` `[REFACTOR]` **(GREEN)** Create `strategy.helpers.ts` and implement the helper functions to make the tests pass. These helpers will be responsible for sorting input documents by type and finding related documents based on `source_contribution_id`.
    *   `[BE]` **(GREEN)** In the `strategies/planners/` directory, create `planPairwiseByOrigin.ts`. Implement the planner function logic as described in the documentation, using the tested helpers. The function will loop through `thesis` documents, find their corresponding `antithesis` documents, and generate a child job payload for each pair.
    *   `[TEST-UNIT]` **(PROVE)** Prove that all unit tests in `planPairwiseByOrigin.test.ts` now pass.
    *   **Implementation Detail (Skeleton):**
        ```typescript
        // In a file like /strategies/planners/planPairwiseByOrigin.ts
        export function planPairwiseByOrigin(sourceDocs: SourceDocuments, parentJobPayload: ParentJobPayload, recipeStep: RecipeStep): ChildJobPayload[] {
            const childJobs: ChildJobPayload = [];
            const { theses, antitheses } = groupSourceDocuments(sourceDocs); // Utility to sort inputs

            for (const thesis of theses) {
                // Find antitheses derived from this thesis
                const relatedAntitheses = findRelated(antitheses, thesis.id);
                for (const antithesis of relatedAntitheses) {
                    const newPayload = {
                        // ... core context from parent
                        job_type: 'execute',
                        // The planner now gets the prompt name directly from the recipe!
                        prompt_template_name: recipeStep.prompt_template_name,
                        inputs: {
                            thesis_id: thesis.resource_id,
                            antithesis_id: antithesis.resource_id,
                        }
                    };
                    childJobs.push(newPayload);
                }
            }
            return childJobs;
        }
        ```

*   `[✅]` 28.c. **Implement `planPerSourceDocument` Strategy (Map):**
    *   `[BE]` `[TEST-UNIT]` **(RED)** Create `planPerSourceDocument.test.ts`. Write a failing test that provides a list of source documents and asserts that the function returns a child job for each one.
    *   `[BE]` **(GREEN)** Create `planPerSourceDocument.ts`. Implement the simple logic to loop through the inputs and create a job for each.
    *   `[TEST-UNIT]` **(PROVE)** Prove the test passes.

*   `[✅]` 28.d. **Implement `planPerSourceGroup` Strategy (Reduce):**
    *   `[BE]` `[TEST-UNIT]` **(RED)** Create `planPerSourceGroup.test.ts`. Write a failing test.
        *   **Test Case:** Provide a list of intermediate artifacts (e.g., `pairwise_synthesis_chunk`) that share a common `source_contribution_id`.
        *   **Assertion:** Assert that the function groups these artifacts correctly and generates a single child job for each group, with all grouped `resource_id`s in the `inputs`.
    *   `[BE]` **(GREEN)** Create `planPerSourceGroup.ts`. Implement the logic to group documents by `source_contribution_id` and generate one job per group.
    *   `[TEST-UNIT]` **(PROVE)** Prove the test passes.

*   `[✅]` 28.e. **Implement `planAllToOne` Strategy (Reduce):**
    *   `[BE]` `[TEST-UNIT]` **(RED)** Create `planAllToOne.test.ts`. Write a failing test that provides a list of inputs and asserts that the function returns exactly one child job containing all input `resource_id`s.
    *   `[BE]` **(GREEN)** Create `planAllToOne.ts`. Implement the straightforward logic.
    *   `[TEST-UNIT]` **(PROVE)** Prove the test passes.

*   `[✅]` 28.f. **[COMMIT] `feat(worker): implement granularity strategy planners`**
    *   **Action:** Commit the completed, fully tested granularity strategy module.

#### 29. [BE] [REFACTOR] Enhance Planner for Multi-Step Recipe Execution

This step refactors the complex job worker to be driven by a formal, multi-step recipe defined in the database. The implementation maintains strict type safety from end to end by defining clear interfaces and using TypeScript's type guard system, completely avoiding type casting.

##### Phase 29.1: Establish the Type-Safe Foundation

Before modifying logic, we must define the new data structures that will drive the multi-step process.

*   `[✅]` 29.a. **Define Recipe and Step Interfaces:**
    *   `[BE]` **File:** `supabase/functions/dialectic-service/dialectic.interface.ts`.
    *   `[BE]` **Action:** Add new interfaces to represent the recipe structure stored in the `dialectic_stages.input_artifact_rules` JSONB column.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/dialectic-service/dialectic.interface.ts

        /**
         * Describes a single step within a multi-step job recipe.
         */
        export interface DialecticRecipeStep {
            step: number;
            name: string;
            prompt_template_name: string;
            inputs_required: {
                type: string;
                stage_slug?: string; // e.g., 'thesis' for antithesis inputs
            }[];
            granularity_strategy: 'per_source_document' | 'pairwise_by_origin' | 'per_source_group' | 'all_to_one';
            output_type: string; // e.g., 'pairwise_synthesis_chunk'
        }

        /**
         * Describes the complete recipe for a complex, multi-step stage.
         */
        export interface DialecticStageRecipe {
            processing_strategy: {
                type: 'task_isolation';
            };
            steps: DialecticRecipeStep[];
        }
        ```
    *   `[BE]` **File:** `supabase/functions/_shared/utils/type_guards.ts`.
    *   `[BE]` **Action:** Add a corresponding type guard to safely validate the recipe structure at runtime.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/_shared/utils/type_guards.ts
        export function isDialecticStageRecipe(value: unknown): value is DialecticStageRecipe {
            const recipe = value;
            return (
                recipe?.processing_strategy?.type === 'task_isolation' &&
                Array.isArray(recipe.steps) &&
                recipe.steps.every(
                    (step) =>
                        typeof step.step === 'number' &&
                        typeof step.prompt_template_name === 'string' &&
                        typeof step.granularity_strategy === 'string' &&
                        typeof step.output_type === 'string' &&
                        Array.isArray(step.inputs_required)
                )
            );
        }
        ```

*   `[✅]` 29.b. **Update Job Payload Types:**
    *   `[BE]` **File:** `supabase/functions/dialectic-service/dialectic.interface.ts`.
    *   `[BE]` **Action:** Introduce new, strictly-typed payloads for parent (`'plan'`) jobs and child (`'execute'`) jobs, along with a `step_info` tracker. Update the main `DialecticJobPayload` to be a discriminated union of all possible payload types.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/dialectic-service/dialectic.interface.ts

        /**
         * Tracks the progress of a multi-step job.
         */
        export interface DialecticStepInfo {
            current_step: number;
            total_steps: number;
        }

        /**
         * The base payload containing information common to all job types.
         */
        export interface DialecticBaseJobPayload extends Omit<GenerateContributionsPayload, 'selectedModelIds'> {
            model_id: string; // Individual model ID for this specific job
        }

        /**
         * The payload for a parent job that plans steps based on a recipe.
         */
        export interface DialecticPlanJobPayload extends DialecticBaseJobPayload {
            job_type: 'plan';
            step_info: DialecticStepInfo;
        }

        /**
         * The payload for a child job that executes a single model call.
         */
        export interface DialecticExecuteJobPayload extends DialecticBaseJobPayload {
            job_type: 'execute';
            step_info: DialecticStepInfo; // Pass down for context
            prompt_template_name: string;
            output_type: string; // The type of artifact this job will produce
            inputs: {
                // Key-value store for resource_ids needed by the prompt
                [key: string]: string; 
            };
        }
        
        // Update the main union type
        export type DialecticJobPayload =
            | DialecticSimpleJobPayload // Assuming this exists for non-complex jobs
            | DialecticPlanJobPayload
            | DialecticExecuteJobPayload
            | DialecticCombinationJobPayload;
        ```
    *   `[BE]` **File:** `supabase/functions/_shared/utils/type_guards.ts`.
    *   `[BE]` **Action:** Create type guards for the new payloads.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/_shared/utils/type_guards.ts
        export function isDialecticPlanJobPayload(payload: unknown): payload is DialecticPlanJobPayload {
            const p: DialecticPlanJobPayload = payload;
            return p?.job_type === 'plan' && typeof p.step_info?.current_step === 'number';
        }

        export function isDialecticExecuteJobPayload(payload: unknown): payload is DialecticExecuteJobPayload {
            const p = payload as DialecticExecuteJobPayload;
            return p?.job_type === 'execute' && typeof p.prompt_template_name === 'string' && typeof p.inputs === 'object';
        }
        ```

##### Phase 29.2: Implement the Recipe-Driven Logic

*   `[✅]` 29.c. **Refactor `processComplexJob` as the Orchestrator:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/processComplexJob.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** Refactor `processComplexJob` to be the master orchestrator. It is responsible for reading the job's `step_info`, fetching the stage recipe, determining the current step, and delegating to the planner.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/dialectic-worker/processComplexJob.ts
        export async function processComplexJob(
            dbClient: SupabaseClient<Database>,
            // The intersection type asserts this job has a plannable payload
            job: DialecticJobRow & { payload: DialecticJobPayload },
            // ... deps
        ): Promise<void> {
            // Use the type guard to safely narrow the payload
            if (!isDialecticPlanJobPayload(job.payload)) {
                // This is a logic error, the job router should not send other job types here.
                throw new Error(`Job ${job.id} has an invalid payload for complex processing.`);
            }
            
            // From here, `job.payload` is a strongly-typed `DialecticPlanJobPayload`
            const { step_info, stageSlug } = job.payload;
            deps.logger.info(`[processComplexJob] Processing step ${step_info.current_step}/${step_info.total_steps} for job ${job.id}`);

            // 1. Fetch the recipe and validate its structure with a type guard
            const { data: stageData } = await dbClient.from('dialectic_stages').select('input_artifact_rules').eq('slug', stageSlug!).single();
            if (!isDialecticStageRecipe(stageData?.input_artifact_rules)) {
                throw new Error(`Stage '${stageSlug}' has an invalid or missing recipe.`);
            }
            const recipe = stageData.input_artifact_rules;
            
            // 2. Determine the current step's recipe
            const currentRecipeStep = recipe.steps.find(s => s.step === step_info.current_step);
            if (!currentRecipeStep) {
                throw new Error(`Could not find recipe for step ${step_info.current_step}.`);
            }

            // 3. Delegate to the planner to create child jobs for this specific step
            const childJobsToInsert = await deps.planComplexStage(dbClient, job, deps, currentRecipeStep);
            
            // ... (rest of the logic to insert child jobs and update parent status to 'waiting_for_children')
        }
        ```
*   `[✅]` 29.d. **Refactor `task_isolator.ts` as the Step Planner:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/task_isolator.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** The `planComplexStage` function is refactored to be a pure "step planner". It no longer orchestrates but is instead called *by* the orchestrator (`processComplexJob`) to plan a single step based on the provided recipe.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/dialectic-worker/task_isolator.ts
        export async function planComplexStage(
            dbClient: SupabaseClient<Database>,
            parentJob: DialecticJobRow & { payload: DialecticPlanJobPayload },
            deps: IPlanComplexJobDeps,
            // The specific recipe for the current step is now passed in
            recipeStep: DialecticRecipeStep,
        ): Promise<ChildJobInsert[]> { // ChildJobInsert is the type for a new DB row
            
            // 1. Use recipeStep.inputs_required to query for source documents.
            const sourceDocuments = await findSourceDocuments(dbClient, parentJob.payload.projectId, recipeStep.inputs_required);

            // 2. Get the correct planner function using the strategy from the recipe.
            const planner = getGranularityPlanner(recipeStep.granularity_strategy);

            // 3. Execute the planner to get the strongly-typed child job payloads.
            const childJobPayloads: DialecticExecuteJobPayload[] = planner(sourceDocuments, parentJob.payload, recipeStep);

            // 4. Map to full job rows for DB insertion, maintaining type safety.
            const childJobsToInsert = childJobPayloads.map(payload => ({
                parent_job_id: parentJob.id,
                // ... other fields from parent ...
                status: 'pending',
                payload: payload, // `payload` is already a valid, typed `DialecticExecuteJobPayload`
            }));
            
            return childJobsToInsert;
        }
        ```
*   `[✅]` 29.e. **Ensure Original Prompt is Always Included:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/_shared/prompt-assembler.ts`.
    *   `[BE]` **Action:** The `gatherContext` utility must be updated to always fetch the project's original user prompt for any job belonging to a complex stage (e.g., `'synthesis'`). This prompt text must be passed to the prompt renderer as a distinct, top-level variable (`original_user_request`) to ensure it's available for injection into any step's prompt template.
*   `[✅]` 29.f. **Tag Intermediate Artifacts in the Executor:**
    *   `[BE]` **File:** `supabase/functions/dialectic-worker/executeModelCallAndSave.ts`.
    *   `[BE]` **Action:** When saving the output of a child job, the worker must use the `output_type` from the strongly-typed payload to tag the new artifact in `dialectic_project_resources`.
    *   **Implementation Detail:**
        ```typescript
        // In supabase/functions/dialectic-worker/executeModelCallAndSave.ts
        export async function executeModelCallAndSave(
            // The job here is a child job with a strongly-typed 'execute' payload
            job: DialecticJobRow & { payload: DialecticExecuteJobPayload },
            // ... other parameters
        ) {
            // ... logic to call the AI model ...
            const modelOutput = await deps.callUnifiedAIModel(...);

            // When saving the result, the output_type comes directly from the typed payload.
            await fileManager.uploadAndRegisterFile({
                // ... other context
                resourceTypeForDb: job.payload.output_type,
                description: `Intermediate artifact for ${job.id}, step ${job.payload.step_info.current_step}`,
            });
        }
        ```
*   `[✅]` 29.g. **Update Parent Job Orchestration Logic:**
    *   `[DB]` `[BE]` **File:** The `handle_job_completion()` PostgreSQL function and `supabase/functions/dialectic-worker/processComplexJob.ts`.
    *   `[BE]` **Action:** The state machine is orchestrated as follows:
        1.  When all child jobs for a step complete, the `handle_job_completion()` trigger wakes the parent job by setting its status to `'pending_next_step'`.
        2.  The `processComplexJob` worker picks up this parent job. Its first action is to check for this status.
        3.  If the status is `pending_next_step`, it increments `payload.step_info.current_step` and updates the job in the database.
        4.  It then proceeds with the planning logic. If `current_step > total_steps`, it marks the parent job as `'completed'`. Otherwise, it re-calls the planner for the new step.
*   `[✅]` 29.h. **Define Multi-Step Error Handling Strategy:**
    *   `[BE]` `[REFACTOR]` **Action:** If any child job (type `'execute'`) fails permanently, it must report its failure to the parent. The `handle_job_completion` trigger will detect this child failure and immediately set the parent job's `status` to `'failed'`, also marking `step_info.status` as `'failed'`. This fail-fast approach prevents the process from getting stuck waiting for a job that will never complete.

---

### Phase 11: [REFACTOR] Implement `_work` Directory for Intermediate Artifacts

This phase addresses a critical filename collision issue discovered during integration testing of multi-step stages (`synthesis`). It introduces a `_work` subdirectory to house intermediate artifacts, ensuring final, user-facing deliverables have clean, predictable paths while guaranteeing unique paths for all generated files.

#### 30. [BE] [ARCH] Implement `_work` Directory Strategy

*   `[✅]` 30.a. **Update Core Type Definitions:**
    *   `[TYPES]` **File:** `supabase/functions/_shared/types/file_manager.types.ts`.
    *   `[TYPES]` **Action:** Add a new optional boolean property, `isIntermediate?: boolean`, to the `PathContext` interface. This flag will signal to the path constructor that the file is a temporary or intermediate artifact.

*   `[✅]` 30.b. **Modify Path Constructor Logic:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/_shared/utils/path_constructor.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** Update the `constructStoragePath` function. When it builds the path for a `FileType` of `'model_contribution_main'`, it must check for the `isIntermediate` flag in the `PathContext`.
        *   If `isIntermediate` is `true`, it must insert the `_work/` segment into the storage path immediately after the stage directory (e.g., `.../3_synthesis/_work/`).
        *   If `isIntermediate` is `false` or undefined, the path should be constructed as before, placing the file in the stage's root.
    *   `[TEST-UNIT]` **(RED)** Update `path_constructor.test.ts` to include test cases for this new logic. Test both scenarios (`isIntermediate: true` and `isIntermediate: false`) to ensure the `_work` directory is added correctly and only when required.
    *   `[TEST-UNIT]` **(GREEN)** Prove the updated `path_constructor` passes all tests.

*   `[✅]` 30.c. **Update Planners to Signal Intermediate Artifacts:**
    *   `[BE]` `[REFACTOR]` **Files:** All relevant granularity strategy planners (`planPairwiseByOrigin.ts`, `planPerSourceGroup.ts`, `planAllToOne.ts`).
    *   `[BE]` `[REFACTOR]` **Action:** When these planners construct the `PathContext` for a child job's payload, they must now determine if the `output_type` is an intermediate artifact.
        *   The logic will be: if the `output_type` is `'pairwise_synthesis_chunk'` or `'reduced_synthesis'`, set `isIntermediate: true` in the `PathContext`.
        *   If the `output_type` is `'synthesis'` (the final deliverable), `isIntermediate` should be `false` or omitted.
    *   `[TEST-UNIT]` **(RED/GREEN)** Update the unit tests for each planner to assert that the `isIntermediate` flag is correctly set in the generated job payloads based on the `output_type` of the recipe step.

*   `[✅]` 30.d. **Update Documentation:**
    *   `[DOCS]` **File:** `docs/implementations/Current/Checklists/Current/AI Dialectic Implementation Plan Phase 2.md`.
    *   `[DOCS]` **Action:** Update the "File Structure for Supabase Storage and Export Tools" diagram and description to include the new `_work` subdirectory within the `synthesis` stage, explaining its purpose.

*   `[✅]` 30.e. **[COMMIT] `feat(worker): implement _work directory for intermediate artifacts`**

#### 31. [TEST-INT] Create the End-to-End Antithesis and Synthesis Pipeline Tests

**Goal:** To create a single, comprehensive integration test file that validates the entire multi-stage, multi-step asynchronous workflow. This test will simulate the process from the end of the `Thesis` stage through the planning and execution of the `Antithesis` stage, and finally through the multi-step "map-reduce" process of the `Synthesis` stage. It will validate the core mechanics of recipe-driven planning, child job execution, and database trigger-based orchestration.

*   `[✅]` 31.a. **Enhance Existing Integration Test File:**
    *   `[TEST-INT]` **File:** `supabase/integration_tests/services/dialectic_pipeline.integration.test.ts`.
    *   `[TEST-INT]` **Action:** This test will be extended. The existing logic that successfully completes the `Thesis` stage and prepares for `Antithesis` will serve as the foundation. We will add new, sequential test steps within the same `Deno.test` block to continue the workflow.

*   `[✅]` 31.b. **Test Setup and Seeding:**
    *   `[TEST-INT]` **Action:** The existing test setup is already seeding the necessary users, projects, and AI models. Ensure that the `dialectic_stages` table is seeded with the correct, detailed `input_artifact_rules` (recipes) for both the `antithesis` and `synthesis` stages, as defined in `A Computable Determinant for Task Isolation.md`.
        *   The `antithesis` recipe should be a single-step plan with a `granularity_strategy` of `'per_source_document'`.
        *   The `synthesis` recipe must be the formal, multi-step recipe with three steps using `'pairwise_by_origin'`, `'per_source_group'`, and `'all_to_one'` strategies, respectively.

*   `[✅]` 31.c. **Test Execution: Antithesis Stage (Single-Step Complex Job)**
    *   `[TEST-INT]` **Action:** Building on the state where `Thesis` is complete and `antithesis` is pending:
        1.  **Invoke Planner:** Call the `dialectic-service` to start the `antithesis` stage. This will create one parent `'plan'` job for each model.
        2.  **Execute Planner:** Call `executePendingDialecticJobs()`.
        3.  **Assert Planning:**
            *   Assert that the parent jobs transition to `'waiting_for_children'`.
            *   Assert that the correct number of child `'execute'` jobs are created. Given 2 `thesis` contributions and 2 models, this should result in 4 child jobs (`2 theses * 2 models`), each with a `parent_job_id`.
        4.  **Execute Child Jobs:** Call `executePendingDialecticJobs()` again to process the newly created child jobs.
        5.  **Assert Orchestration & Completion:**
            *   Assert that all child jobs are marked `'completed'`.
            *   Assert that the database trigger fires and updates the parent jobs to `'completed'`.
            *   Query the `dialectic_contributions` table and assert that exactly 4 `antithesis` contributions now exist.

*   `[✅]` 31.d. **Test Execution: Synthesis Stage (Multi-Step Map-Reduce Job)**
    *   `[TEST-INT]` **Action:** The test will now simulate the entire multi-step synthesis process:
        1.  **Submit Antithesis Feedback:** Invoke the `submitStageResponses` function to simulate user feedback on the `antithesis` contributions. Assert that the session status advances and the seed prompt for the `synthesis` stage is created.
        2.  **Invoke Synthesis Planner (Step 1):**
            *   Invoke the `dialectic-service` to start the `synthesis` stage. Assert the parent `'plan'` job is created (one per model).
            *   Call `executePendingDialecticJobs()`.
            *   Assert parent job is `'waiting_for_children'` and child jobs for **Step 1 (`pairwise_by_origin`)** are created. Given 2 `thesis` and 4 `antithesis` (2 per thesis), this should create 4 child jobs (`2 thesis * 2 antithesis/thesis`).
        3.  **Simulate Step 1 Completion & Wake Parent:**
            *   Call `executePendingDialecticJobs()` to complete the Step 1 child jobs.
            *   Poll the database to assert the trigger fires and the parent job's status becomes `'pending_next_step'`.
        4.  **Invoke Synthesis Planner (Step 2):**
            *   Call `executePendingDialecticJobs()` again. The worker will pick up the parent job, increment its `step_info.current_step` to 2, and re-delegate to the planner.
            *   Assert the parent job returns to `'waiting_for_children'` and child jobs for **Step 2 (`per_source_group`)** are created. Given 4 `pairwise_synthesis_chunk` artifacts grouped by 2 original theses, this should result in 2 child jobs.
        5.  **Simulate Step 2 Completion & Wake Parent:**
            *   Repeat the process: execute the Step 2 child jobs and assert the parent job returns to `'pending_next_step'`.
        6.  **Invoke Synthesis Planner (Step 3):**
            *   Call `executePendingDialecticJobs()` one last time. The worker will increment the step to 3.
            *   Assert the parent job returns to `'waiting_for_children'` and child jobs for **Step 3 (`all_to_one`)** are created. Given 2 `reduced_synthesis` artifacts, this will create 2 child jobs (one per model, each taking all reduced syntheses as input).
        7.  **Simulate Final Step Completion:**
            *   Execute the final child jobs.
            *   Assert that the database trigger now marks the parent job as `'completed'`, as `current_step` now equals `total_steps`.

*   `[✅]` 31.e. **Final Assertions:**
    *   `[TEST-INT]` **Action:** Query the `dialectic_generation_jobs` table and assert that all parent and child jobs for the `synthesis` stage are `'completed'`.
    *   `[TEST-INT]` **Action:** Query the `dialectic_contributions` table and storage. Verify that the correct number of intermediate artifacts (`pairwise_synthesis_chunk`, `reduced_synthesis`) and the final `synthesis` contributions were created correctly and are linked to the session.

---

### Phase 12: [ARCH] [REFACTOR] Implement Convergent Dialectic and Sophisticated RAG Pipeline

**Design Philosophy:** This phase addresses two critical insights. First, the dialectic process must converge towards a single output in later stages. Second, the RAG pipeline enabling this must be sophisticated enough to prevent the "averaging effect" and preserve unique, novel details.

#### 32. [BE] [DB] [REFACTOR] Implement a Dynamic, On-Demand RAG Service

This section refactors the RAG pipeline to be a dynamic, on-demand "context compression" service. Instead of being reflexively tied to specific stages, RAG will be invoked by any part of the system that prepares data for a model call whenever it detects that the proposed input context exceeds the model's token limit. This creates a more robust, efficient, and architecturally sound system.

*   `[✅]` 32.a. **Setup the Vector Database:**
    *   `[DB]` **Tool:** Supabase SQL Editor.
    *   `[DB]` **Action:** Enable the `vector` extension in your Supabase project (`create extension vector;`).
    *   `[DB]` **Action:** Create a new table, `dialectic_memory`, to store text chunks and their embeddings. It should include columns like `id` (UUID), `session_id` (FK to `dialectic_sessions`), `source_contribution_id` (FK to `dialectic_contributions`), `content` (text), `metadata` (JSONB), and `embedding` (vector(1536)) -- assuming OpenAI's `text-embedding-3-small`.

*   `[✅]` 32.b. **Implement the Indexing Service with Semantic Chunking:**
    *   `[BE]` **Recommendation:** Use a library like `langchain-js` (which has Deno support) to simplify text splitting and embedding calls.
    *   `[BE]` **File:** `supabase/functions/_shared/services/indexing_service.ts`.
    *   `[BE]` **Action:** Create a new service that:
        1.  Takes a document's text and metadata.
        2.  Uses a text splitter (e.g., `RecursiveCharacterTextSplitter`) configured for **semantic chunking**. The goal is to split documents at points of topical shift to create focused, potent vectors that preserve unique ideas rather than using naive fixed-size chunks.
        3.  Calls an embedding model API (e.g., OpenAI's `text-embedding-3-small`) for each chunk.
        4.  Saves the chunk's content, metadata, and the resulting embedding vector into the `dialectic_memory` table.

*   `[✅]` 32.c. **Refactor Indexing to be a "Just-in-Time" Process:**
    *   `[BE]` `[REFACTOR]` **Action:** The current approach of reflexively indexing all documents from certain stages is inefficient. Indexing should be performed dynamically, on-demand, only when a RAG operation is actually required.
    *   **Implementation - Step 1: Remove Reflexive Indexing:**
        *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-service/submitStageResponses.ts`.
        *   `[BE]` `[REFACTOR]` **Action:** Delete the entire logic block that triggers the `IndexingService` based on the current stage slug. Indexing should no longer be a part of the stage transition process.
    *   **Implementation - Step 2: Implement Just-in-Time Indexing in `RagService`:**
        *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/_shared/services/rag_service.ts`.
        *   `[BE]` `[REFACTOR]` **Action:** Enhance the `getContextForModel` method. Before this method executes its multi-query retrieval logic, it must first ensure that all source documents it needs to query have been indexed.
        *   `[BE]` **Logic:**
            1.  The service receives a list of source document IDs.
            2.  It queries the `dialectic_memory` table to see which chunks corresponding to these document IDs already exist.
            3.  For any document IDs that do *not* have corresponding chunks in the vector store, the `RagService` will invoke the `IndexingService` to chunk and embed them.
            4.  Only once all required documents are confirmed to be in the vector store will the `RagService` proceed with its retrieval, re-ranking, and assembly logic.

*   `[✅]` 32.d. **Create a Central, Reusable `RagService` with Advanced Retrieval:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/_shared/services/rag_service.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** Create a new, dedicated `RagService` to encapsulate all logic for retrieving and synthesizing context. Its primary method, `getContextForModel`, will accept a collection of source document texts/IDs and the target `AiModelExtendedConfig`.
    *   **Implementation - Step 1: Hybrid Search RPC:**
        *   `[DB]` **Action:** Create an RPC function in Supabase, e.g., `match_dialectic_chunks`. This function is critical and must support **hybrid search**. It will accept a query and return results based on a combination of vector similarity (`<->` operator) and traditional keyword matching (e.g., `to_tsvector`). This ensures both semantically relevant and literally exact information is retrieved, preventing important but non-standard terms from being missed by vector search alone.
    *   **Implementation - Step 2: Multi-Query, Re-ranking, and Assembly Logic:**
        *   `[BE]` **Action:** Inside the `getContextForModel` method, implement a sophisticated, multi-step retrieval process:
        1.  **Generate Multiple Queries:** Programmatically generate several queries to capture different "angles" of the required information. For example: a broad synthesis query, a query specifically asking for "novel or unique approaches", and another asking for "conflicting recommendations".
        2.  **Retrieve Superset:** Call the `match_dialectic_chunks` RPC for *each* generated query to gather a superset of potentially relevant chunks from the `dialectic_memory` table.
        3.  **Re-rank for Diversity:** Use a **re-ranking algorithm like Maximal Marginal Relevance (MMR)** on the combined result set. This is crucial for preventing the "averaging effect." MMR will select a final list of chunks that are both highly relevant to the queries and semantically diverse, ensuring that unique, outlier perspectives are not drowned out by more common, redundant themes.
        4.  **Assemble Final Prompt:** Create the final, compact prompt containing the re-ranked, diverse chunks. This string is the distilled, token-constrained context that will be returned by the service.

*   `[✅]` 32.e. **Refactor `task_isolator.ts` for Dynamic RAG-based Planning:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/task_isolator.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** Modify the `planComplexStage` function to be RAG-aware.
    *   **Logic:**
        1.  After gathering source documents, perform the token estimation check as defined in `Phase 9, Step 26.b`.
        2.  **If tokens are within limits:** Proceed with the existing job planning logic.
        3.  **If tokens exceed limits:**
            *   **Remove** the logic that creates prerequisite `'combine'` jobs.
            *   **Instead**, invoke the new `RagService` with the oversized collection of documents.
            *   Use the single, RAG-generated context string to create a single child job. This is more efficient and eliminates the need for complex prerequisite job orchestration.

*   `[✅]` 32.f. **Refactor `prompt-assembler.ts` for Correct, Granular, Dynamic RAG-based Assembly:**
    *   `[BE]` `[REFACTOR]` **Goal:** To refactor the `PromptAssembler` to dynamically invoke the `RagService` with a granular, complete set of individual source documents. This is a critical correction to ensure the RAG service can perform its intended function of semantic chunking, multi-query retrieval, and diversity re-ranking, preventing the "averaging effect" that would occur if all context were pre-combined into a single string.
    *   `[TEST-UNIT]` **(RED)** **Update `prompt-assembler.test.ts`:**
        *   **Action:** Add/update a `describe` block for "Dynamic Granular RAG Invocation".
        *   **Action:** Create a mock for the `RagService` that can be spied on.
        *   **Action:** Modify mocks for `gatherInputsForStage` to return an array of `SourceDocument` objects (a new internal type defined below), not a single string.
        *   **Test Case 1 (Context Under Limit):**
            *   **Setup:** Mock `gatherInputsForStage` to return a small array of `SourceDocument`s. Mock `countTokensForMessages` to return a value below the token limit.
            *   **Execution:** Call `gatherContext`.
            *   **Assertion:** Assert that `ragService.getContextForModel` was **NOT** called. Assert that the `dynamicContextVariables` are correctly formatted by combining the individual `SourceDocument` objects.
        *   **Test Case 2 (Context Over Limit):**
            *   **Setup:** Mock `gatherInputsForStage` to return a large array of `SourceDocument`s. Mock `countTokensForMessages` to return a value exceeding the `minTokenLimit`. Provide the mock `RagService`.
            *   **Execution:** Call `gatherContext`.
            *   **Assertion:** Assert that `ragService.getContextForModel` **WAS** called exactly once with an array of `IRagSourceDocument` objects, preserving the individuality of each source. Assert that the returned `dynamicContextVariables.prior_stage_ai_outputs` contains the compressed string from the mock RAG service.
    *   `[BE]` `[REFACTOR]` **(GREEN)** **Step 1: Refactor `gatherInputsForStage` to Return Individual Documents:**
        *   **File:** `supabase/functions/_shared/prompt-assembler.ts`.
        *   **Action:** Create a new internal interface, `SourceDocument`, to represent each distinct piece of content (contribution or feedback), including its `id`, `type`, `content`, and formatting `metadata`.
        *   **Action:** Change the return type of `gatherInputsForStage` from `Promise<{ priorStageContributions: string; priorStageFeedback: string }>` to `Promise<SourceDocument[]>`.
        *   **Action:** Modify the function's logic. Instead of concatenating content into strings, it will now create and return an array of `SourceDocument` objects.
    *   `[BE]` `[REFACTOR]` **(GREEN)** **Step 2: Implement Correct RAG Logic in `gatherContext`:**
        *   **File:** `supabase/functions/_shared/prompt-assembler.ts`.
        *   **Action:** Update `gatherContext` to receive the `SourceDocument[]` array.
        *   **Action:** Implement the token estimation logic by combining the content from the `SourceDocument` array for an accurate measurement.
        *   **Action:** Implement the conditional RAG logic:
            1.  **If `estimatedTokens > minTokenLimit`:**
                *   Map the `SourceDocument[]` to the `IRagSourceDocument[]` format (`{ id, content }`).
                *   Invoke `this.ragService.getContextForModel` with this granular array of documents.
                *   Use the compressed string from the RAG service result as `prior_stage_ai_outputs`.
            2.  **If `estimatedTokens <= minTokenLimit` (the "else" case):**
                *   Iterate through the `SourceDocument[]` array to correctly format the `prior_stage_ai_outputs` and `prior_stage_user_feedback` strings, preserving headers and original structure.
    *   `[BE]` `[REFACTOR]` **(GREEN)** **Step 3: Update `prompt-assembler.mock.ts`:**
        *   **File:** `supabase/functions/_shared/prompt-assembler.mock.ts`.
        *   **Action:** Update the `MockPromptAssembler` constructor and all spied method signatures (`assemble`, `gatherContext`) to match the new dependencies and parameters of the real `PromptAssembler` class, including `ragServiceDeps`, `modelConfigForTokenization`, and `minTokenLimit`.
    *   `[BE]` `[REFACTOR]` **(GREEN)** **Step 4: Verify Caller Service (`submitStageResponses.ts`):**
        *   **File:** `supabase/functions/dialectic-service/submitStageResponses.ts`.
        *   **Action:** Confirm that the instantiation of `PromptAssembler` and the call to `assembler.assemble` are correct and provide all necessary dependencies and parameters, which was already done correctly. No changes are expected here, but verification is key.
    *   `[TEST-UNIT]` **(PROVE)** Prove that all unit tests in `prompt-assembler.test.ts` now pass, validating both the RAG-enabled and non-RAG paths with granular data.

*   `[✅]` 32.g. **Confirm `executeModelCallAndSave.ts` as a Final Safeguard:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/executeModelCallAndSave.ts`.
    *   `[BE]` `[REFACTOR]` **Action:** The plan explicitly confirms that the token check in this executor function remains the final, fatal safeguard.
    *   **Logic:** If the token count of the fully rendered prompt still exceeds the model's limit, it signifies an upstream bug in token estimation or prompt rendering. The function **must** `throw new ContextWindowError`. It will **not** attempt a last-second RAG call, as this would hide upstream issues and lead to unpredictable behavior.

*   `[✅]` 32.h. **[REFACTOR] Unify Worker Dependency Injection:**
    *   `[BE]` `[REFACTOR]` **Goal:** To resolve a type mismatch in the main `processJob` router by consolidating the disparate `ProcessSimpleJobDeps` and `IPlanComplexJobDeps` interfaces into a single, unified dependency object. This will ensure type safety and provide all processors with the services they need.
    *   `[BE]` `[REFACTOR]` **Step 1: Unify Dependency Interfaces:**
        *   **File:** `supabase/functions/dialectic-service/dialectic.interface.ts`.
        *   **Action:** Locate the `ProcessSimpleJobDeps` interface. Rename it to `IDialecticJobDeps`.
        *   **Action:** Add the properties from `IPlanComplexJobDeps` (`ragService`, `fileManager`, `countTokens`, `getAiProviderConfig`) to the new `IDialecticJobDeps` interface. Make properties that are not used by all consumers optional (e.g., `ragService?: IRagService`).
        *   **File:** `supabase/functions/dialectic-worker/processComplexJob.ts`.
        *   **Action:** Delete the now-redundant `IPlanComplexJobDeps` interface definition.
    *   `[BE]` `[REFACTOR]` **Step 2: Update Worker Entry Point:**
        *   **File:** `supabase/functions/dialectic-worker/index.ts`.
        *   **Action:** In the main `Service` function, instantiate the new services required for complex jobs: `RagService` and `FileManager`.
        *   **Action:** Update the `deps` object to include these new service instances.
        *   **Action:** Update all type references from `ProcessSimpleJobDeps` to the new `IDialecticJobDeps`.
    *   `[BE]` `[REFACTOR]` **Step 3: Update Job Router and Processors:**
        *   **File:** `supabase/functions/dialectic-worker/processJob.ts`.
        *   **Action:** Change the `processJob` function signature to accept `deps: IDialecticJobDeps`.
        *   **Action:** In the `task_isolation` branch, the `complexDeps` object can now be correctly populated from the main `deps` object, resolving the original linter errors.
        *   **File:** `supabase/functions/dialectic-worker/processComplexJob.ts`.
        *   **Action:** Update the function signature to use `IDialecticJobDeps` instead of `IPlanComplexJobDeps`.
        *   **File:** `supabase/functions/dialectic-worker/processSimpleJob.ts`.
        *   **Action:** Update the function signature to use `IDialecticJobDeps`.
    *   `[TEST-UNIT]` `[TEST-INT]` **Step 4: Update All Tests:**
        *   **Action:** Systematically go through the list of test files that use the old dependency types (`executeModelCallAndSave.test.ts`, `index.test.ts`, `processJob.test.ts`, `processSimpleJob.test.ts`, `processComplexJob.test.ts`, `task_isolator.test.ts`, `dialectic_pipeline.integration.test.ts`).
        *   **Action:** For each test file, update the type imports to use the new `IDialecticJobDeps` interface.
        *   **Action:** Update all mock dependency objects (`mockDeps`) to include the new properties (`ragService`, `fileManager`, etc.), providing mock implementations or spies as needed to satisfy the updated interface.

#### 33. [BE] [REFACTOR] Implement Convergent Logic for Final Stages

*   `[ ]` 33.a. **Update `Parenthesis` and `Paralysis` Stage Recipes and Prompts:**
    *   `[DB]` `[PROMPT]` **Action:** The stage recipes and system prompts for `Parenthesis` and `Paralysis` will be updated to be convergent. The prompt will explicitly instruct the models to synthesize a single, unified document from the diverse context provided by the advanced RAG pipeline, which is sourced from *all* relevant documents from the prior stage.
*   `[ ]` 33.b. **Implement the Final "Advisor" Job:**
    *   `[BE]` **Action:** Create a new job type, `'advisor'`, and a corresponding `processAdvisorJob.ts` worker.
    *   `[BE]` **Action:** After the `Paralysis` stage completes, the `submitStageResponses` function will enqueue a single `advisor` job.
    *   `[BE]` **Action:** This job's purpose is not to create a new, single plan, but to aid the user's decision-making process. It will use the RAG pipeline to retrieve context from all `paralysis` documents (the final plans from each model) and instruct a high-capability model to produce a concise executive summary.
    *   `[BE]` **Output:** The summary should be a new `dialectic_contribution` of type `final_summary` and should highlight:
        *   **Key Differences & Philosophies:** e.g., "Plan A prioritizes microservices, while Plan B uses a modular monolith."
        *   **Strengths & Trade-offs:** e.g., "Plan A is more scalable but complex; Plan B is faster to start."
        *   **Points of Agreement:** e.g., "All plans recommend using PostgreSQL and React."
    *   `[BE]` **Action:** The final output presented to the user will be the `n` plans from the `Paralysis` stage, accompanied by this single `final_summary` to guide their selection.

#### 34. [TEST-INT] Create RAG-Powered Context Stress Test

*   `[ ]` 34.a. **Configure `dummy_adapter` for Stress Testing:**
    *   `[BE]` `[CONFIG]` **File:** `supabase/integration_tests/services/dialectic_pipeline.stress.test.ts`.
    *   `[BE]` **Action:** Create a new, dedicated test file. In the test setup, configure an instance of the `dummy_adapter.ts` to be used. Set its mode to `'echo'`, which guarantees that the output of each model call includes the full input, ensuring exponential context growth to realistically simulate real-world conditions.
*   `[ ]` 34.b. **Develop the Stress Test Case:**
    *   `[TEST-INT]` **Action:** Create a test that runs the dialectic from `Synthesis` through the final `Arbiter` job.
    *   **Assertions:**
        1.  **Verify RAG Activation:** Assert that the context-limiting logic (e.g., the `Tier 2 Orchestration` that creates `combine` jobs, or a new RAG-specific check) is correctly triggered when the echoed context from the `dummy_adapter` exceeds the model's configured `provider_max_input_tokens`.
        2.  **Verify RAG Efficacy:** Assert that the final prompts sent to the models remain within the context limits, proving the RAG pipeline successfully managed the oversized context.
        3.  **Verify Convergence:** Assert that the `Parenthesis`, `Paralysis`, and `Arbiter` jobs each produce the expected number of outputs (e.g., one final contribution for the `Arbiter` job).
*   `[ ]` 34.c. **[COMMIT] `docs(plan): add convergent RAG strategy`**
*   `[ ]` 34.d. **[COMMIT] `test(pipeline): implement RAG stress test`**



## Section 2.Z: Implementing Data-Driven AI Response Formatting via `expected_output_artifacts`

**Objective:** To standardize and control the structure of AI model responses by leveraging the `dialectic_stages.expected_output_artifacts` JSONB column. This column will store a JSON template defining the exact output format expected from the AI for each stage. The backend will wrap this template with a strong "meta-instruction" to guide the AI, parse the JSON response, and process the structured deliverables.

**Core Principles:**
*   **Declarative Formatting:** Define AI output structures in the database, not in code.
*   **Strong Guidance:** Use explicit meta-instructions to maximize AI compliance.
*   **Parsing Robustness:** Expect and parse a JSON object from the AI.
*   **Controlled Filenaming:** Use fixed filenames in the AI-requested template, then map them to dynamic, system-defined filenames upon processing.

---

*   `[ ] 2.Z.1 [DB/SEED]` **Define and Populate `expected_output_artifacts` Templates**
    *   `[ ] 2.Z.1.1 [ARCH/DESIGN]` **Finalize JSON Structure for Deliverables**
        *   Define a consistent master JSON structure template that can be adapted for each stage. This structure should include keys for all common deliverable types (e.g., `executive_summary`, `main_content_markdown`, `risk_assessment`, and an array for `files` like `[{ "template_filename": "fixed_prd.md", "content": "..."}]`).
    *   `[ ] 2.Z.1.2 [DB/MIGRATION]` **Create/Update Migration/Seeding Script for `expected_output_artifacts`**
        *   For each `dialectic_stages` record (Thesis, Antithesis, Synthesis, Parenthesis, Paralysis):
            *   Populate the `expected_output_artifacts` column with a stage-specific JSON object template. This template will instruct the AI on how to structure its entire response.
            *   **Example for Thesis Stage (Illustrative):**
                ```json
                {
                  "executive_summary": "placeholder for executive summary",
                  "detailed_implementation_strategy": "placeholder for implementation strategy",
                  "development_checklist": ["placeholder for step 1"],
                  "risk_assessment_and_mitigation": "placeholder for risk assessment",
                  "success_metrics": "placeholder for success metrics",
                  "files_to_generate": [
                    {
                      "template_filename": "thesis_product_requirements_document.md",
                      "content_placeholder": "complete markdown content for PRD here"
                    },
                    {
                      "template_filename": "thesis_implementation_plan_proposal.md",
                      "content_placeholder": "complete markdown content for implementation plan here"
                    }
                  ]
                }
                ```
            *   Ensure filenames within `files_to_generate` are fixed (e.g., `stage_specific_output_type.md`).
    *   `[ ] 2.Z.1.3 [DOCS]` Document the standard JSON structure and the purpose of `expected_output_artifacts` in the project's technical documentation.
    *   `[ ] 2.Z.1.4 [COMMIT]` `feat(db): define and seed expected_output_artifacts templates for dialectic stages`

*   `[ ] 2.Z.2 [BE/PROMPT]` **Design and Implement Meta-Instruction Wrapper**
    *   `[ ] 2.Z.2.1 [PROMPT]` **Craft the Meta-Instruction String**
        *   Develop a clear, forceful instruction block that will precede the JSON template from `expected_output_artifacts` in the prompt sent to the AI.
        *   **Example:**
            ```
            SYSTEM: Your entire response for this stage MUST be a single, valid JSON object. Strictly adhere to the JSON structure provided below under 'Expected JSON Output Structure:'. Populate all placeholder values (e.g., "placeholder for ...", "complete markdown content here") with your generated content. Do not include any conversational text, acknowledgments, apologies, or any other content outside of this JSON object. The JSON object must begin with '{' and end with '}'.

            Expected JSON Output Structure:
            ```
            *(This will be followed by the JSON template)*
            ```
            Ensure your response is ONLY the JSON object. End of instructions.
            ```
    *   `[ ] 2.Z.2.2 [BE]` In `dialectic-service` (e.g., within `callUnifiedAIModel` or a prompt assembly utility):
        *   Implement logic to fetch the `expected_output_artifacts` JSON for the current `DialecticStage`.
        *   If `expected_output_artifacts` is present and valid:
            *   Prepend the crafted meta-instruction.
            *   Append the stringified JSON from `expected_output_artifacts`.
            *   Append the concluding part of the meta-instruction ("Ensure your response is ONLY the JSON object. End of instructions.").
            *   This becomes part of the main user/assistant prompt content sent to the AI model.
    *   `[ ] 2.Z.2.3 [TEST-UNIT]` Write unit tests for the prompt assembly logic to verify correct construction of the meta-instruction and template inclusion. (RED then GREEN)
    *   `[ ] 2.Z.2.4 [COMMIT]` `feat(be): implement meta-instruction wrapper for JSON response formatting`

*   `[ ] 2.Z.3 [BE/SERVICE]` **Implement AI Response Parsing and Deliverable Processing**
    *   `[ ] 2.Z.3.1 [BE]` In `dialectic-service` (e.g., in `generateContributions.ts` or where `callUnifiedAIModel`'s response is handled):
        *   Attempt to `JSON.parse()` the AI's entire text response.
        *   If parsing fails:
            *   Log the error and the malformed response.
            *   Implement error handling (e.g., return a specific error to the user, potentially attempt a retry with a stronger instruction).
    *   `[ ] 2.Z.3.2 [BE]` If JSON parsing succeeds:
        *   Extract the various deliverables based on the known keys from the `expected_output_artifacts` template (e.g., `parsedResponse.executive_summary`, etc.).
        *   For each item in the `parsedResponse.files_to_generate` array (or similar key):
            *   Get the `template_filename` and `content`.
            *   **Implement Dynamic Filename Mapping:** Convert the `template_filename` (e.g., `"thesis_product_requirements_document.md"`) into the actual dynamic filename required by `FileManagerService` (e.g., incorporating `model_slug`, `stage_slug`, `iteration`, `attempt_count`). This logic will reside in `generateContributions.ts`.
            *   Determine the correct `FileType` for `FileManagerService` based on the `template_filename` or other metadata (e.g., 'contribution\_document\_prd', 'contribution\_document\_plan').
            *   Use `FileManagerService.uploadAndRegisterFile` to save the `content` with the dynamic filename, correct `FileType`, and other necessary context (`projectId`, `sessionId`, `model_id_used`, tokenomics data, etc.).
        *   Store other non-file deliverables (like `executive_summary`) appropriately. This might involve new columns on `dialectic_contributions` if they are distinct from the main Markdown file content, or they could be part of a primary "summary" artifact. *Decision: For now, assume these are fields within a primary structured contribution; if they need to be separate files, the JSON template and parsing must reflect that.*
    *   `[ ] 2.Z.3.3 [TEST-INT]` Write integration tests for `generateContributions.ts`: (RED then GREEN)
        *   Mock `callUnifiedAIModel` to return a stringified JSON adhering to a sample `expected_output_artifacts` template.
        *   Assert that the JSON is parsed correctly.
        *   Assert that `FileManagerService.uploadAndRegisterFile` is called for each file in the `files_to_generate` array with correctly mapped dynamic filenames and `FileType`.
        *   Test scenarios with malformed JSON responses from the AI.
    *   `[ ] 2.Z.3.4 [COMMIT]` `feat(be): implement JSON response parsing and dynamic file processing in dialectic-service`

*   `[ ] 2.Z.4 [REFACTOR]` **Review and Refine**
    *   `[ ] 2.Z.4.1 [PROMPT/BE]` Test the entire flow with actual AI models. Refine the meta-instruction and JSON templates in `expected_output_artifacts` based on observed AI compliance and any parsing issues.
    *   `[ ] 2.Z.4.2 [CODE]` Ensure all related code (prompt assembly, response parsing, error handling) is robust and well-documented.

*   `[ ] 2.Z.5 [DOCS]` **Update System Documentation**
    *   `[ ] 2.Z.5.1 [DOCS]` Document the new `expected_output_artifacts` column, its purpose, and the standard JSON structure.
    *   `[ ] 2.Z.5.2 [DOCS]` Document the prompt assembly logic, including the meta-instruction.
    *   `[ ] 2.Z.5.3 [DOCS]` Document the response parsing and dynamic filename mapping logic.
    *   `[ ] 2.Z.5.4 [COMMIT]` `docs: document data-driven AI response formatting mechanism`

---You're thinking ahead very effectively! Ensuring that the AI-generated implementation plans and checklists are well-structured, human-readable, and adhere to a consistent style is crucial for their practical use. Your refined legend and numbering scheme are excellent improvements.

This "Formatting and Style Guide" should indeed be part of the instructions provided to the AI. The best place for this is within the `prompt_text` of the `system_prompts` table, specifically for those system prompts associated with stages that are expected to produce these structured documents (e.g., the system prompt for the "Parenthesis" stage).

Let's extend "Section 2.Z" in your `AI Dialectic Implementation Plan Phase 2.md` to include these steps. I'll rename the section slightly to encompass both the JSON response structure and this content styling.

---

**Formatting and Style Guide for Implementation Plans & Checklists:**

When generating implementation plans, detailed checklists, or any hierarchically structured task lists, you MUST adhere to the following formatting and style guide precisely:

1.  **Overall Structure:**
    *   Organize all plans and checklists into clear, hierarchical sections.
    *   Start with high-level phases or major components and progressively detail sub-tasks and steps.

2.  **Task Status Legend:**
    *   Prefix EVERY actionable task item with one of the following status markers:
        *   `[ ]` : Unstarted task.
        *   `[✅]` : Completed task (use sparingly, as you are generating a plan for future work).
        *   `[🚧]` : Task is in progress or partially completed (use sparingly).
        *   `[⏸️]` : Task is paused or waiting for external input/clarification.
        *   `[❓]` : There is significant uncertainty about this task that needs resolution.
        *   `[🚫]` : Task is blocked by an unresolved issue or dependency.
    *   The status marker is mandatory for all list items that represent an actionable step.

3.  **Component Type Labels (Optional but Recommended):**
    *   If a task directly relates to a specific type of system component or development activity, include ONE of the following labels immediately after the status marker and before the task description.
    *   Use these labels judiciously where they add clarity.
    *   Available Labels: `[DB]`, `[RLS]`, `[BE]`, `[API]`, `[STORE]`, `[UI]`, `[CLI]`, `[IDE]`, `[TEST-UNIT]`, `[TEST-INT]`, `[TEST-E2E]`, `[DOCS]`, `[REFACTOR]`, `[PROMPT]`, `[CONFIG]`.
    *   Example: `[ ] [BE] Implement user authentication endpoint.`

4.  **Numbering, Lettering, and Indentation Scheme:**
    *   You MUST use the following scheme for hierarchical levels:
        *   **Level 1 (Main Headings/Phases):** `[ ] 1. Task Description`
        *   **Level 2 (Sub-tasks/Components):** `[ ] a. Task Description` (indented under Level 1)
        *   **Level 3 (Detailed Steps):** `[ ] i. Task Description` (indented under Level 2)
    *   Ensure proper Markdown indentation for nested lists to render correctly.
    *   For clarity, try to limit nesting to these three levels. If a fourth level is absolutely essential for a very specific detail, you may restart with `1.` (indented under `i.`), or use a simple unnumbered bullet `-` for very fine-grained sub-points. Avoid overly deep numerical nesting (e.g., 1.2.3.4.5.a.i).

5.  **Task Descriptions:**
    *   Keep task descriptions clear, actionable, and concise.
    *   Start task descriptions with a verb where appropriate.

6.  **Plan Development Principles:**
    *   **TDD (Test-Driven Development):** For any implementation tasks, explicitly include steps for writing tests *before* writing the implementation code. For example:
        *   `[ ] [TEST-UNIT] Write failing unit tests for the new service (RED).`
        *   `[ ] [BE] Implement the core logic for the new service (GREEN).`
        *   `[ ] [REFACTOR] Refactor the new service code and tests.`
    *   **Modularity:** Design components and tasks to be modular and reusable.
    *   **Dependencies:** If tasks have clear dependencies, you can note them, but the hierarchical structure should imply the primary flow.
    *   **Documentation:** Include explicit tasks for documentation (e.g., `[ ] [DOCS] Update the API documentation for the new endpoint.`).

**Example of Expected Output Format:**

```markdown
[ ] 1. [BE] Phase 1: Setup Core Backend Infrastructure
    [ ] a. [DB] Define database schema for user profiles.
    [ ] b. [TEST-UNIT] Write failing unit tests for profile creation (RED).
    [ ] c. [BE] Implement API endpoint for user profile creation (GREEN).
        [ ] i. [BE] Add input validation.
        [ ] ii. [BE] Implement database insertion logic.
    [ ] d. [DOCS] Document the user profile API endpoint.
[ ] 2. [UI] Phase 2: Develop User Interface
    [ ] a. [UI] Design wireframes for the registration page.
    [ ] b. [UI] Implement the registration form component.
```

By including such a guide in your system prompts, you are setting clear expectations for the AI, which should lead to more consistent, human-readable, and useful implementation plans and checklists. This aligns perfectly with making your overall system more robust and predictable.

## Section 2.Z: Implementing Data-Driven AI Response Formatting & Content Styling

**Objective:** To standardize and control both the *structure of AI model JSON responses* and the *formatting/style of detailed textual deliverables (like implementation plans)*. This involves using the `dialectic_stages.expected_output_artifacts` JSONB column for overall response structure and embedding a "Formatting and Style Guide" within relevant `system_prompts.prompt_text` for content styling.

**Core Principles:**
*   **Declarative Formatting:** Define AI output structures (JSON) and content styles (Markdown plans) in the database.
*   **Strong Guidance:** Use explicit meta-instructions and style guides to maximize AI compliance.
*   **Parsing Robustness:** Expect and parse a JSON object from the AI.
*   **Controlled Filenaming:** Use fixed filenames in the AI-requested template, then map them to dynamic, system-defined filenames upon processing.
*   **Content Usability:** Ensure generated plans/checklists are human-readable and consistently formatted.

---

*   `[ ] 2.Z.1 [PROMPT/DOCS]` **Develop the "Formatting and Style Guide" for Structured Documents**
    *   `[ ] 2.Z.1.1 [PROMPT]` Finalize the detailed text for the "Formatting and Style Guide." This guide should include:
        *   The refined Task Status Legend (e.g., `[ ] 1.`, `[ ] a.`, `[ ] i.`).
        *   Instructions for using Component Type Labels (e.g., `[BE]`, `[UI]`).
        *   Guidance on task description clarity, hierarchical structure, and limiting nesting depth.
        *   Emphasis on plan development principles like TDD.
        *   A clear example of the expected output format for a small plan.
    *   `[ ] 2.Z.1.2 [DOCS]` Store this finalized guide text. If it's extensive, consider placing it in a shared, version-controlled document referenced by system prompts, or as a constant in a shared backend module if it needs programmatic access. For direct use, it will be embedded into system prompt texts.

*   `[ ] 2.Z.2 [DB/SEED]` **Update `system_prompts` with Formatting and Style Guide**
    *   `[ ] 2.Z.2.1 [DB/PROMPT]` Identify all `system_prompts` records (e.g., the default system prompts for "Parenthesis", "Paralysis", or any custom stage that should produce detailed plans/checklists) that require this style guide.
    *   `[ ] 2.Z.2.2 [DB/MIGRATION]` Create or update a database migration/seeding script to modify the `prompt_text` of these identified `system_prompts`.
        *   Embed the full "Formatting and Style Guide" (from `2.Z.1.1`) into the `prompt_text`. This guide should be clearly delineated within the system prompt (e.g., under a heading like "**Formatting and Style Guide for Implementation Plans & Checklists:**").
        *   This ensures the AI receives these styling instructions as part of its core task directions for that stage.
    *   `[ ] 2.Z.2.3 [COMMIT]` `feat(db,prompt): integrate formatting/style guide into relevant system prompts`

*   `[ ] 2.Z.3 [DB/SEED]` **Define and Populate `expected_output_artifacts` JSON Templates**
    *   `[ ] 2.Z.3.1 [ARCH/DESIGN]` Finalize the master JSON structure template for AI responses (as previously discussed in the original 2.Z.1.1). This template dictates keys like `executive_summary`, `files_to_generate`, etc.
    *   `[ ] 2.Z.3.2 [DB/MIGRATION]` Ensure the migration/seeding script for `dialectic_stages.expected_output_artifacts` (from the original 2.Z.1.2) correctly populates this column for each stage with its specific JSON response template.
        *   The `content_placeholder` for any deliverable that is a structured plan/checklist (e.g., `"content_placeholder": "complete markdown content for implementation plan here, adhering to the provided Formatting and Style Guide"`) implicitly relies on the AI having received the style guide via the system prompt.
    *   `[ ] 2.Z.3.3 [DOCS]` Document the standard JSON structure and the purpose of `expected_output_artifacts`.
    *   `[ ] 2.Z.3.4 [COMMIT]` `feat(db): define and seed expected_output_artifacts JSON templates for dialectic stages` (Commit may be merged with 2.Z.2.3 if done in one migration).

*   `[ ] 2.Z.4 [BE/PROMPT]` **Implement Meta-Instruction Wrapper for JSON Response Structure**
    *   `[ ] 2.Z.4.1 [PROMPT]` Craft the "meta-instruction" string that explicitly tells the AI to respond ONLY in the provided JSON format (as in the original 2.Z.2.1). This meta-instruction will wrap the JSON template taken from `expected_output_artifacts`.
        *   **Refined Example considering SYSTEM prefix and EOF:**
            ```
            SYSTEM: Your entire response for this stage MUST be a single, valid JSON object. Strictly adhere to the JSON structure provided below under 'Expected JSON Output Structure:'. Populate all placeholder values (e.g., "placeholder for ...", "complete markdown content here") with your generated content. Do not include any conversational text, acknowledgments, apologies, or any other content outside of this JSON object. The JSON object must begin with '{' and end with '}'.

            Expected JSON Output Structure:
            [Insert JSON template from expected_output_artifacts here by the backend]

            CRITICAL REMINDER: Ensure your response is ONLY the JSON object detailed above. End of Instructions. END_OF_RESPONSE_FORMAT_INSTRUCTIONS.
            ```
    *   `[ ] 2.Z.4.2 [BE]` In `dialectic-service` (e.g., within a prompt assembly utility called by `generateContributions.ts` before `callUnifiedAIModel`):
        *   Fetch the `default_system_prompt_id` for the current `DialecticStage`.
        *   Fetch the `prompt_text` from `system_prompts` using this ID (this text now includes the "Formatting and Style Guide").
        *   Fetch the `expected_output_artifacts` JSON string for the current `DialecticStage`.
        *   If `expected_output_artifacts` is present:
            *   Construct the full user-facing part of the prompt by:
                1.  Taking the main task description/context for the stage.
                2.  Appending the meta-instruction (from `2.Z.4.1`).
                3.  Appending the `expected_output_artifacts` JSON string itself.
                4.  Appending the concluding part of the meta-instruction.
        *   The final prompt sent to the AI model will consist of:
            1.  The fetched system prompt content (which includes the style guide).
            2.  The assembled user-facing prompt (task + JSON output structure instructions).
    *   `[ ] 2.Z.4.3 [TEST-UNIT]` Write unit tests for the full prompt assembly logic, verifying correct inclusion and ordering of the system prompt (with style guide), task prompt, meta-instruction, and the JSON template. (RED then GREEN)
    *   `[ ] 2.Z.4.4 [COMMIT]` `feat(be): implement full prompt assembly including style guide and JSON meta-instructions`

*   `[ ] 2.Z.5 [BE/SERVICE]` **Implement AI JSON Response Parsing and Deliverable Processing**
    *   `(Sub-steps 2.Z.3.1 to 2.Z.3.3 from the original plan remain largely the same, now referred to as 2.Z.5.1 to 2.Z.5.3)`
    *   `[ ] 2.Z.5.1 [BE]` Attempt to `JSON.parse()` the AI's entire text response. Handle parsing failures.
    *   `[ ] 2.Z.5.2 [BE]` If JSON parsing succeeds:
        *   Extract deliverables based on keys from the `expected_output_artifacts` template.
        *   For items in `files_to_generate`:
            *   Implement dynamic filename mapping (fixed template filename to system's dynamic filename).
            *   Determine `FileType`.
            *   Use `FileManagerService.uploadAndRegisterFile` to save content. Ensure the content (which should be Markdown formatted according to the style guide) is passed correctly.
        *   Store other non-file deliverables.
    *   `[ ] 2.Z.5.3 [TEST-INT]` Write/update integration tests for `generateContributions.ts` to reflect this full flow. (RED then GREEN)
    *   `[ ] 2.Z.5.4 [COMMIT]` `feat(be): implement JSON response parsing and processing with styled content`

*   `[ ] 2.Z.6 [REFACTOR]` **Review, Test, and Refine**
    *   `[ ] 2.Z.6.1 [PROMPT/BE]` Test the entire flow with actual AI models. Refine the "Formatting and Style Guide" in `system_prompts`, the meta-instruction for JSON output, and the JSON templates in `expected_output_artifacts` based on AI compliance and quality of generated content/structure.
    *   `[ ] 2.Z.6.2 [CODE]` Ensure all related code is robust and well-documented.

*   `[ ] 2.Z.7 [DOCS]` **Update System Documentation**
    *   `(Sub-steps 2.Z.5.1 to 2.Z.5.3 from the original plan remain relevant, now 2.Z.7.1 to 2.Z.7.3)`
    *   `[ ] 2.Z.7.1 [DOCS]` Document `expected_output_artifacts` (purpose, JSON structure).
    *   `[ ] 2.Z.7.2 [DOCS]` Document the "Formatting and Style Guide" and its location/integration within system prompts.
    *   `[ ] 2.Z.7.3 [DOCS]` Document the full prompt assembly logic (system prompt + style guide + task + meta-instruction + JSON template).
    *   `[ ] 2.Z.7.4 [DOCS]` Document response parsing, dynamic filename mapping, and processing of styled content.
    *   `[ ] 2.Z.7.5 [COMMIT]` `docs: update documentation for data-driven AI response formatting and content styling`

---

**Understanding the Core Challenge for AI:**

*   **Gap Identification (Parenthesis):** This requires the AI to not just generate content, but to *analyze* existing content (the checklist from Synthesis) and identify what's *missing*. It needs to infer unstated prerequisites.
*   **Dependency-Driven Reordering (Paralysis):** This is even harder. It requires the AI to build a mental (or implicit) dependency graph of a potentially very long list of tasks and then re-linearize it. This is akin to a topological sort.

**General Prompting Strategies for Parenthesis & Paralysis:**

1.  **Clear Role and Context:**
    *   Assign a specific expert role to the AI (e.g., "You are a Senior Technical Architect and Project Planner responsible for ensuring the completeness and logical flow of implementation plans.").
    *   Clearly state the purpose of the current stage (Parenthesis or Paralysis).
    *   Provide the *entire* current checklist (from Synthesis for Parenthesis, from Parenthesis for Paralysis) as the primary input.

2.  **Explicit Instructions on *How* to Analyze:**
    *   Don't just say "find gaps." Guide its thought process.
    *   Don't just say "reorder." Explain the reordering principle.

3.  **Output Format Reinforcement:**
    *   Continuously remind it of your desired checklist formatting (your refined legend `[ ] 1.`, `[ ] a.`, `[ ] i.`, component labels `[BE]`, etc.).
    *   Remind it to produce the *entire* modified checklist as output, not just the changes.
    *   Reinforce the need for the final output to be wrapped in the JSON structure defined by `expected_output_artifacts`.

4.  **Leverage Strengths, Mitigate Weaknesses:**
    *   AI is good at pattern matching and local context. Your "first mention" rule for Paralysis is a good way to give it a concrete heuristic.
    *   AI struggles with long-term memory and global consistency across very long documents. Breaking down the analysis might help.

**Structuring the Prompt for the "Parenthesis" Stage (Gap Analysis & Elaboration):**

**Goal:** To take the checklist from Synthesis and add missing steps/sections.

```
SYSTEM: Your entire response for this stage MUST be a single, valid JSON object. Strictly adhere to the JSON structure provided below under 'Expected JSON Output Structure:'. Populate all placeholder values with your generated content. Do not include any conversational text, acknowledgments, apologies, or any other content outside of this JSON object. The JSON object must begin with '{' and end with '}'.

You are a meticulous Senior Software Architect and Technical Planner. Your current task is to review and enhance an existing software implementation plan to ensure its absolute completeness. This is the "Parenthesis" stage of a dialectic process.

**Input Implementation Plan/Checklist:**
(Your backend service will insert the full checklist from the Synthesis stage here)

**Your Task for the Parenthesis Stage (Gap Analysis and Elaboration):**

1.  **Thoroughly Review:** Carefully read the entire "Input Implementation Plan/Checklist" provided above.
2.  **Identify Missing Prerequisites & Gaps:** As you review, critically analyze the plan for any missing steps or components. Specifically look for:
    *   Tasks that refer to components, modules, functions, data stores, UI elements, API endpoints, or services that have not yet been defined OR whose creation/setup steps are not detailed *earlier* in the plan.
    *   Assumptions about the existence of foundational elements (e.g., project setup, core libraries, authentication context) without explicit checklist items for their establishment.
    *   Descriptions of interactions (e.g., "Component X calls API Y," "Store Z fetches data from Backend Service A") where any part of that interaction (X, Y, Z, A, or the specific endpoint/function) has not been adequately planned for.
    *   Steps that are too vague or high-level and require more detailed sub-tasks for a developer to implement effectively.
3.  **Generate and Insert Missing Sections/Steps:** For each identified gap or overly vague step:
    *   Generate a new, comprehensive set of checklist items required to design, implement, test, and document the missing element or to elaborate on the vague step.
    *   These new items MUST strictly follow the "Formatting and Style Guide for Implementation Plans & Checklists" (using `[ ] 1.`, `[ ] a.`, `[ ] i.` numbering, status markers `[ ]`, and component labels like `[BE]`, `[UI]`, etc., as previously defined).
    *   **Insertion Strategy:** Logically insert these new sections/steps into the plan. The ideal placement is *just before* the point where the missing element is first needed or used, or where the vague step needs detail. If it's a major new component, it might form its own new top-level section (e.g., a new `[ ] N. Define and Implement New Core Service Z`).
4.  **Maintain Original Content and Structure:** Preserve all existing, valid checklist items and their relative order where no gaps are being filled around them. Your goal is to *augment and complete* the plan, not to reorder it at this stage.
5.  **Output the Complete, Enhanced Plan:** Your final output must be the *entire, revised implementation plan*, incorporating all your additions and elaborations. This output will be the content for the primary checklist file defined in the 'Expected JSON Output Structure' below.

Expected JSON Output Structure:
(Your backend service will insert the JSON template from dialectic_stages.expected_output_artifacts for the Parenthesis stage here. This template will specify where the AI should place the full, revised checklist string.)

CRITICAL REMINDER: Ensure your response is ONLY the JSON object detailed above. End of Instructions. END_OF_RESPONSE_FORMAT_INSTRUCTIONS.
```

**Structuring the Prompt for the "Paralysis" Stage (Dependency-Driven Reordering):**

**Goal:** To take the (now more complete) checklist from Parenthesis and reorder it logically based on dependencies.

```
SYSTEM: Your entire response for this stage MUST be a single, valid JSON object. Strictly adhere to the JSON structure provided below under 'Expected JSON Output Structure:'. Populate all placeholder values with your generated content. Do not include any conversational text, acknowledgments, apologies, or any other content outside of this JSON object. The JSON object must begin with '{' and end with '}'.

You are an expert Project Planner and System Architect specializing in optimizing software development workflows by ensuring strict dependency ordering. Your current task is to take a detailed (but potentially unordered) implementation plan and resequence it into a perfectly logical, step-by-step, buildable order. This is the "Paralysis" stage of a dialectic process.

**Input Implementation Plan/Checklist:**
(Your backend service will insert the full checklist from the Parenthesis stage here)

**Your Task for the Paralysis Stage (Dependency-Driven Reordering):**

1.  **Deeply Analyze Dependencies:** Meticulously examine every task, sub-task, and component mentioned in the "Input Implementation Plan/Checklist." Identify all explicit and implicit dependencies. For example:
    *   A UI component displaying data depends on the API endpoint that provides the data.
    *   An API endpoint depends on the backend service logic that implements it.
    *   A backend service might depend on a database schema or another service.
    *   Store actions/selectors depend on API client methods being available.
    *   Tests for a feature depend on the feature itself being implemented.
2.  **Reorder Based on "First Mention, Full Implementation Prioritization":**
    *   Your primary goal is to reconstruct the *entire* checklist such that: When any component, module, function, data store, API, UI element, or service (let's call it 'Element X') is *first mentioned* as being needed, used by, or a prerequisite for another task in the plan, then ALL checklist items required to fully design, implement, test, and document 'Element X' MUST be placed *immediately before* that first mentioning task.
    *   This ensures that no task attempts to use or refer to an 'Element X' before all steps for 'Element X's' creation and readiness have been listed.
3.  **Maintain Granularity and Enforce Formatting:**
    *   Do not lose, merge, or alter the content of any individual task descriptions from the input plan. Preserve all detailed sub-tasks.
    *   The reordered plan MUST strictly adhere to the "Formatting and Style Guide for Implementation Plans & Checklists" (using `[ ] 1.`, `[ ] a.`, `[ ] i.` numbering, status markers `[ ]`, and component labels like `[BE]`, `[UI]`, etc., as previously defined). You will need to re-number and re-letter the *entire plan* according to its new logical sequence.
4.  **Handle Ordering Conflicts:** If you encounter what appear to be circular dependencies that cannot be easily resolved into a linear sequence (this should be rare), make the most logical ordering choice possible. If a true conflict persists, you may add a `[❓]` comment briefly noting the items involved in the potential circular dependency, but still present a linear plan.
5.  **Output the Complete, Reordered Plan:** Your final output must be the *entire, re-sequenced implementation plan*. This output will be the content for the primary checklist file defined in the 'Expected JSON Output Structure' below.

Expected JSON Output Structure:
(Your backend service will insert the JSON template from dialectic_stages.expected_output_artifacts for the Paralysis stage here. This template will specify where the AI should place the full, reordered checklist string.)

CRITICAL REMINDER: Ensure your response is ONLY the JSON object detailed above. End of Instructions. END_OF_RESPONSE_FORMAT_INSTRUCTIONS.
```

**Key Improvements and Why They Might Work:**

*   **Specificity of Analysis:** The prompts now guide *how* the AI should think about gaps and dependencies, rather than just stating the goal.
*   **"First Mention, Full Implementation Prioritization":** This is a strong, actionable heuristic for the reordering task, which AI can often follow better than abstract dependency mapping.
*   **Emphasis on Outputting the *Entire* Plan:** This is critical to avoid the AI just giving you diffs or fragments.
*   **Reinforcement of Formatting:** Consistent reminders about your checklist style guide.
*   **Acknowledging Your Workflow:** The prompt structure (SYSTEM block, then main task, then JSON structure request) is designed to work with your `expected_output_artifacts` strategy.

**Your Multi-Agent Approach:**

This is where your system can really shine. Even with these improved prompts:
*   **Parenthesis:** Different models might identify different (or overlapping) gaps. Synthesizing these will lead to a more complete plan than any single model might produce.
*   **Paralysis:** Different models might interpret "logical order" or the "first mention" rule slightly differently, especially for complex interdependencies. Comparing their reordered plans and synthesizing a final order (perhaps with some human oversight for tricky sections) will likely yield the most robust sequence.

You are essentially using the AI ensemble to overcome individual model limitations in deep, long-range planning. This is a very advanced and effective way to use current AI capabilities.


### Phase 13: Centralized Configuration Management

This phase introduces a centralized configuration system to manage dynamic parameters and feature flags, enhancing the system's flexibility and maintainability without requiring code deployments for simple adjustments.

#### 33. [DB] [BE] Implement the Configuration Store
*   `[ ]` 33.a. **Create `dialectic_configuration` Table:**
    *   `[DB]` **Action:** Create a new SQL migration for a `dialectic_configuration` table with a simple key-value structure (e.g., `config_key TEXT PRIMARY KEY`, `config_value JSONB`, `description TEXT`).
    *   `[DB]` **Action:** Populate this table with initial configuration values, such as `{"key": "job_default_max_retries", "value": {"value": 3}}`, `{"key": "rag_data_retention_days", "value": {"value": 30}}`, and `{"key": "antithesis_task_isolation_enabled", "value": {"value": true}}`.
*   `[ ]` 33.b. **Create a Configuration Service:**
    *   `[BE]` **Action:** In `supabase/functions/_shared/`, create a new `config_service.ts`. This service will be responsible for fetching configuration values from the database, caching them (e.g., in-memory with a short TTL), and providing a simple `getConfigValue(key)` interface.
#### 34. [BE] [REFACTOR] Refactor Services to Use the Configuration Store
*   `[ ]` 34.a. **Update Dialectic Worker:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-worker/index.ts`
    *   `[BE]` `[REFACTOR]` **Action:** Refactor the worker logic to fetch parameters like `max_retries` and feature flags (e.g., for task isolation) from the new `config_service` instead of using hardcoded values.
*   `[ ]` 34.b. **Update Job Enqueuer:**
    *   `[BE]` `[REFACTOR]` **File:** `supabase/functions/dialectic-service/generateContribution.ts`
    *   `[BE]` `[REFACTOR]` **Action:** Update the function to fetch the default `max_retries` from the `config_service` when creating a new job, while still allowing it to be overridden by a value in the request payload.
*   `[ ]` 34.c. **Update Data Lifecycle Script:**
    *   `[BE]` `[REFACTOR]` **Action:** Modify the scheduled SQL function for RAG data cleanup to retrieve the `rag_data_retention_days` value from the `dialectic_configuration` table, making the retention period dynamically adjustable.


*   [ ] Fix Clone so it works again. 
*   [ ] Fix Export so that it exports the entire project. 
*   [ ] Fix Delete to use the new path structuring
*   [X] Fix path_constructor so it does NOT append a filename to storage_path in "finalMainContentFilePath". 
    *    [X] For files that need filenames constructed, return the path and file name separately, not as a single string. 
*   [ ] Fix PromptParser to construct all stage prompts correctly
    *    [ ] Fill in all {variable} elements from the project details
    *    [ ] Append all prompt resources to the actual prompt sent 
*   [ ] Update all the prompts with the right content 
*   [ ] Add the sync/export button to the Paralysis stage   
*   [ ] Add a slice button to the Paralysis stage to take the selected plan, slice it according to an algorithm, then create a new project for each slice 
