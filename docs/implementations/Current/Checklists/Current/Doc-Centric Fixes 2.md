# Doc-Centric Fixes

## Problem Statement
-The doc-centric refactor has introduced bugs and inconsistencies that need resolved. 

## Objectives
- Fix all bugs and integration errors from the doc-centric refactor. 

## Expected Outcome
- Generate an entire dialectic end to end using the doc-centric method.

# Instructions for Agent
*   ### 0. Command Pyramid & Modes
    *   Obey the userâ€™s explicit instructions first, then this block, then the checklist. Do not hide behind the checklist to ignore a direct user correction.
    *   Ensure both the method and the resulting content of every task comply with this blockâ€”no deliverable is valid if it conflicts with these rules.
    *   Perform every assignment in a single turn while fully complying with this block; partial compliance is a violation even if the work â€œmostlyâ€ succeeds.
    *   Failing to follow these instructions immediately triggers rework, rejected output, and systemic violationsâ€”treat every deviation as unacceptable.
    *   The Instructions for Agent block is an absolute firewall. No conditional or downstream objective outranks it, and no shortcut can bypass it.
    *   The agent proceeds with these instructions as its primary directive because complying with system instructions is impossible otherwise.
    *   Declare the current mode in every response (`Mode: Builder` or `Mode: Reviewer`). Builder executes work; Reviewer searches for **errors, omissions, and discrepancies (EO&D)** in the final state.
*   ### 1. Read â†’ Analyze â†’ Explain â†’ Propose â†’ Edit â†’ Lint â†’ Halt
    *   Re-read this entire block from disk before every action. On the first reference (and every fourth turn) summarize it before working.
    *   Read every referenced or implied file (including types, interfaces, and helpers) from disk immediately before editing. After editing, re-read to confirm the exact change.
    *   Follow the explicit cycle: READ the step + files â†’ ANALYZE gaps â†’ EXPLAIN the delta â†’ PROPOSE the exact edit â†’ EDIT a single file â†’ LINT that file â†’ HALT.
    *   Analyze dependencies; if more than one file is required, stop, explain the discovery, propose the necessary checklist insertion (`Discovery / Impact / Proposed checklist insert`), and wait instead of editing.
    *   Discoveries include merely thinking about multi-file workâ€”report them immediately without ruminating on work-arounds.
    *   Explain & Propose: restate the plan in bullets and explicitly commit, â€œI will implement exactly this plan now,â€ noting the checklist step it fulfills.
    *   Edit exactly one file per turn following the plan. Never touch files you were not explicitly instructed to modify.
    *   Lint that file using internal tools and fix all issues.
    *   Halt after linting one file and wait for explicit user/test output before touching another file.
*   ### 2. TDD & Dependency Ordering
    *   One-file TDD cycle: RED test (desired green behavior) â†’ implementation â†’ GREEN test â†’ lint. Documents/types/interfaces are exempt from tests but still follow Readâ†’Halt.
    *   Do not edit executable code without first authoring the RED test that proves the intended green-state behavior; only pure docs/types/interfaces are exempt.
    *   Maintain bottom-up dependency order for both editing and testing: construct types/interfaces/helpers before consumers, then write consumer tests only after producers exist.
    *   Do not advance to another file until the current fileâ€™s proof (tests or documented exemption) is complete and acknowledged.
    *   The agent never runs tests directly; rely on provided outputs or internal reasoning while keeping the application in a provable state.
    *   The agent does not run the userâ€™s terminal commands or tests; use only internal tooling and rely on provided outputs.
*   ### 3. Checklist Discipline
    *   Do not edit the checklist (or its statuses) without explicit instruction; when instructed, change only the specified portion using legal-style numbering.
    *   Execute exactly what the active checklist step instructs with no deviation or â€œcreative interpretation.â€
    *   Each numbered checklist step equals one fileâ€™s entire TDD cycle (deps â†’ types â†’ tests â†’ implementation â†’ proof). Preserve existing detail while adding new requirements.
    *   Document every edit within the checklist. If required edits are missing from the plan, explain the discovery, propose the new step, and halt instead of improvising.
    *   Never update the status of any work step (checkboxes or badges) without explicit instruction.
    *   Following a block of related checklist steps that complete a working implementation, include a commit with a proposed commit message. 
*   ### 4. Builder vs Reviewer Modes
    *   **Builder:** follow the Readâ†’â€¦â†’Halt loop precisely. If a deviation, blocker, or new requirement is discoveredâ€”or the current step simply cannot be completed as writtenâ€”explain the problem, propose the required checklist change, and halt immediately.
    *   **Reviewer:** treat prior reasoning as untrusted. Re-read relevant files/tests from scratch and produce a numbered EO&D list referencing files/sections. Ignore checklist status or RED/GREEN history unless it causes a real defect. If no EO&D are found, state â€œNo EO&D detected; residual risks: â€¦â€
*   ### 5. Strict Typing & Object Construction
    *   Use explicit types everywhere. No `any`, `as`, `as const`, inline ad-hoc types, or castsâ€”except for Supabase clients and intentionally malformed objects in error-handling tests (use dedicated helpers and keep typing strict elsewhere). Every object and variable must be typed. 
    *   Always construct full objects that satisfy existing interfaces/tuples from the relevant type file. Compose complex objects from smaller typed components; never rely on defaults, fallbacks, or backfilling to â€œhealâ€ missing data.
    *   Use type guards to prove and narrow types for the compiler when required.
    *   Never import entire libraries with *, never alias imports, never add "type" to type imports. 
    *   A ternary is not a type guard, a ternary is a default value. Default values are prohibited. 
*   ### 6. Plan Fidelity & Shortcut Ban
    *   Once a solution is described, implement exactly that solution and the userâ€™s instruction. Expedient shortcuts are forbidden without explicit approval.
    *   If you realize you deviated, stop, report it, and wait for direction. Repeating corrected violations triggers halt-and-wait immediately.
    *   If your solution to a challenge is "rewrite the entire file", you have made an error. Stop, do not rewrite the file. Explain the problem to the user and await instruction. 
    *   Do not ruminate on how to work around the "only write to one file per turn". If you are even thinking about the need to work around that limit, you have made a discovery. Stop immediately, report the discovery to the user, and await instruction. 
    *   Refactors must preserve all existing functionality unless the user explicitly authorizes removals; log and identifier fidelity is mandatory.
*   ### 7. Dependency Injection & Architecture
    *   Use explicit dependency injection everywhereâ€”pass every dependency with no hidden defaults or optional fallbacks.
    *   Build adapters/interfaces for every function and work bottom-up so dependencies compile before consumers. Preserve existing functionality, identifiers, and logging unless explicitly told otherwise.
    *   When a file exceeds 600 lines, stop and propose a logical refactoring to decompose the file into smaller parts providing clear SOC and DRY. 
*   ### 8. Testing Standards
    *   Tests assert the desired passing state (no RED/GREEN labels) and new tests are added to the end of the file. Each test covers exactly one behavior.
    *   Use real application functions/mocks, strict typing, and Deno std asserts. Tests must call out which production type/helper each mock mirrors so partial objects are not invented.
    *   Integration tests must exercise real code paths; unit tests stay isolated and mock dependencies explicitly. Never change assertions to match broken codeâ€”fix the code instead.
    *   Tests use the same types, objects, structures, and helpers as the real code, never create new fixtures only for tests - a test that relies on imaginary types or fixtures is invalid. 
    *   Prove the functional gap, the implemented fix, and regressions through tests before moving on; never assume success without proof.
*   ### 9. Logging, Defaults, and Error Handling
    *   Do not add or remove logging, defaults, fallbacks, or silent healing unless the user explicitly instructs you to do so.
    *   Adding console logs solely for troubleshooting is exempt from TDD and checklist obligations, but the exemption applies only to the logging statements themselves.
    *   Believe failing tests, linter flags, and user-reported errors literally; fix the stated condition before chasing deeper causes.
    *   If the user flags instruction noncompliance, acknowledge, halt, and wait for explicit directionâ€”do not self-remediate in a way that risks further violations.
*   ### 10. Linting & Proof
    *   After each edit, lint the touched file and resolve every warning/error. Record lint/test evidence in the response (e.g., â€œLint: clean via internal tool; Tests: not run per instructionsâ€).
    *   Evaluate if a linter error can be resolved in-file, or out-of-file. Only resolve in-file linter errors, then report the out-of-file errors and await instruction. 
    *   Testing may produce unresolvable linter errors. Do not silence them with @es flags, create an empty target function, or other work-arounds. The linter error is sometimes itself proof of the RED state of the test. 
    *   Completion proof requires a lint-clean file plus GREEN test evidence (or documented exemption for types/docs).
*   ### 11. Reporting & Traceability
    *   Every response must include: mode declaration, confirmation that this block was re-read, plan bullets (Builder) or EO&D findings (Reviewer), checklist step references, and lint/test evidence.
    *   If tests were not run (per instruction), explicitly state why and list residual risks. If no EO&D are found, state that along with remaining risks.
    *   The agent uses only its own tools and never the userâ€™s terminal.
*   ### 12. Output Constraints
    *   Never output large code blocks (entire files or multi-function dumps) in chat unless the user explicitly requests them.
    *   Never print an entire function and tell the user to paste it in; edit the file directly or provide the minimal diff required.

## Checklist-Specific Editing Rules

*   THE AGENT NEVER TOUCHES THE CHECKLIST UNLESS THEY ARE EXPLICITLY INSTRUCTED TO! 
*   When editing checklists, each numbered step (1, 2, 3, etc.) represents editing ONE FILE with a complete TDD cycle.
*   Sub-steps within each numbered step use legal-style numbering (1.a, 1.b, 1.a.i, 1.a.ii, etc.) for the complete TDD cycle for that file.
*   All changes to a single file are described and performed within that file's numbered step.
*   Types files (interfaces, enums) are exempt from RED/GREEN testing requirements.
*   Each file edit includes: RED test â†’ implementation â†’ GREEN test â†’ optional refactor.
*   Steps are ordered by dependency (lowest dependencies first).
*   Preserve all existing detail and work while adding new requirements.
*   Use proper legal-style nesting for sub-steps within each file edit.
*   NEVER create multiple top-level steps for the same file edit operation.
*   Adding console logs is not required to be detailed in checklist work. 

### Example Checklist

*   `[ ]`   1. **Title** Objective
    *   `[ ]`   1.a. [DEPS] A list explaining dependencies of the function, its signature, and its return shape
        *   `[ ]` 1.a.i. eg. `function(something)` in `file.ts` provides this or that
    *   `[ ]`   1.b. [TYPES] A list strictly typing all the objects used in the function
    *   `[ ]`   1.c. [TEST-UNIT] A list explaining the test cases
        *   `[ ]` 1.c.i. Assert `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [SPACE] A list explaining the implementation requirements
        *   `[ ]` 1.d.i. Implement `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [TEST-UNIT] Rerun and expand test proving the function
        *   `[ ]` 1.d.i. Implement `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [TEST-INT] If there is a chain of functions that work together, prove it
        *   `[ ]` 1.d.i. For every cross-function interaction, assert `thisFunction(something)` in `this_file.ts` acts a certain way towards `thatFunction(other)` in `that_file.ts`
    *   `[ ]`   1.d. [CRITERIA] A list explaining the acceptence criteria to consider the work complete and correct. 
    *   `[ ]`   1.e. [COMMIT] A commit that explains the function and its proofs

*   `[ ]`   2. **Title** Objective
    *   `[ ]`   2.a. [DEPS] Low level providers are always build before high level consumers (DI/DIP)
    *   `[ ]`   2.b. [TYPES] DI/DIP and strict typing ensures unit tests can always run 
    *   `[ ]`   2.c. [TEST-UNIT] All functions matching defined external objects and acting as asserted helps ensure integration tests pass

## Legend - You must use this EXACT format. Do not modify it, adapt it, or "improve" it. The bullets, square braces, ticks, nesting, and numbering are ABSOLUTELY MANDATORY and UNALTERABLE. 

*   `[ ]` 1. Unstarted work step. Each work step will be uniquely named for easy reference. We begin with 1.
    *   `[ ]` 1.a. Work steps will be nested as shown. Substeps use characters, as is typical with legal documents.
        *   `[ ]` 1. a. i. Nesting can be as deep as logically required, using roman numerals, according to standard legal document numbering processes.
*   `[âœ…]` Represents a completed step or nested set.
*   `[ðŸš§]` Represents an incomplete or partially completed step or nested set.
*   `[â¸ï¸]` Represents a paused step where a discovery has been made that requires backtracking or further clarification.
*   `[â“]` Represents an uncertainty that must be resolved before continuing.
*   `[ðŸš«]` Represents a blocked, halted, or stopped step or has an unresolved problem or prior dependency to resolve before continuing.

## Component Types and Labels

*   `[DB]` Database Schema Change (Migration)
*   `[RLS]` Row-Level Security Policy
*   `[BE]` Backend Logic (Edge Function / RLS / Helpers / Seed Data)
*   `[API]` API Client Library (`@paynless/api` - includes interface definition in `interface.ts`, implementation in `adapter.ts`, and mocks in `mocks.ts`)
*   `[STORE]` State Management (`@paynless/store` - includes interface definition, actions, reducers/slices, selectors, and mocks)
*   `[UI]` Frontend Component (e.g., in `apps/web`, following component structure rules)
*   `[CLI]` Command Line Interface component/feature
*   `[IDE]` IDE Plugin component/feature
*   `[TEST-UNIT]` Unit Test Implementation/Update
*   `[TEST-INT]` Integration Test Implementation/Update (API-Backend, Store-Component, RLS)
*   `[TEST-E2E]` End-to-End Test Implementation/Update
*   `[DOCS]` Documentation Update (READMEs, API docs, user guides)
*   `[REFACTOR]` Code Refactoring Step
*   `[PROMPT]` System Prompt Engineering/Management
*   `[CONFIG]` Configuration changes (e.g., environment variables, service configurations)
*   `[COMMIT]` Checkpoint for Git Commit (aligns with "feat:", "test:", "fix:", "docs:", "refactor:" conventions)
*   `[DEPLOY]` Checkpoint for Deployment consideration after a major phase or feature set is complete and tested.

# Work Breakdown Structure

*   `[âœ…]` 1. **`[DB]` Fix Job Queue Continuation When First Step Completes**
    *   `[âœ…]` 1.a. `[DEPS]` After reviewing the recipe stage migration files (`*_stage.sql`) and the codebase, the complete list of job statuses that require worker invocation is: `pending` (new jobs, handled by `on_new_job_created` trigger on INSERT), `pending_next_step` (PLAN jobs ready for next recipe step after children complete, MISSING trigger), `pending_continuation` (continuation jobs created by `continueJob` function, MISSING trigger), and `retrying` (jobs being retried, handled by `on_job_retrying` trigger). Statuses that do NOT need worker invocation are: `processing` (worker already owns the job), `waiting_for_children` (internal state set by `processComplexJob`), `waiting_for_prerequisite` (internal state set by prerequisite logic), and terminal states (`completed`, `failed`, `retry_loop_failed`). The database trigger `handle_job_completion()` in `supabase/migrations/20251119160820_retrying_trigger.sql` correctly sets PLAN job status to `pending_next_step` when all child EXECUTE jobs complete (lines 234-236), and also sets jobs to `pending` when prerequisites complete (line 181). The `continueJob` function in `supabase/functions/dialectic-worker/continueJob.ts` sets jobs to `pending_continuation` (line 198). However, there is no trigger configured to invoke the `dialectic-worker` Edge Function when a job's status changes to `pending_next_step` or `pending_continuation`. The worker endpoint (`supabase/functions/dialectic-worker/index.ts`) is invoked via POST request with a job record in the request body (it does not fetch jobs itself), so it must be triggered by a database webhook when the status changes. Currently, there is a generic `invoke_dialectic_worker()` function (defined in `supabase/migrations/20250922165259_document_centric_generation.sql`, lines 59-143) that handles HTTP invocation logic, and it is used by the `on_new_job_created` trigger (fires on INSERT). There is also a separate `handle_job_retrying()` function and `on_job_retrying` trigger (lines 5-137 in `20251119160820_retrying_trigger.sql`) that specifically handle `retrying` status. Rather than creating separate triggers for each status, a better architectural approach is to create a single, generic trigger that fires on status changes and invokes the worker for any status that requires processing. The `processComplexJob` function in `supabase/functions/dialectic-worker/processComplexJob.ts` already handles `pending_next_step` status correctly (it processes ready steps when called), but the worker is never invoked when the status changes to `pending_next_step`, leaving PLAN jobs stuck in that state.
    *   `[âœ…]` 1.b. `[DOCS]` **TRIGGER AUDIT**: Document all current triggers on `dialectic_generation_jobs` table and identify competing/deprecated triggers. Current active triggers: (1) `on_new_job_created` (from `20250722033928_fix_job_trigger.sql`) - fires `AFTER INSERT`, calls `invoke_dialectic_worker()`, handles new jobs; (2) `on_job_retrying` (from `20251119160820_retrying_trigger.sql`) - fires `AFTER UPDATE OF status` when `status = 'retrying'`, calls `handle_job_retrying()`, handles retry logic and retry limit checking before invoking worker; (3) `trigger_handle_job_completion_on_update` (from `20250725182218_prerequisite_job_id.sql`) - fires `AFTER UPDATE OF status`, calls `handle_job_completion()`, handles parent/child dependencies and prerequisite logic; (4) `trigger_handle_job_completion_on_insert` (from `20250725182218_prerequisite_job_id.sql`) - fires `AFTER INSERT`, calls `handle_job_completion()`, handles parent/child dependencies on insert. Potentially deprecated: `on_job_terminal_state` (from `20250711205050_create_job_completion_trigger.sql`, line 150 drops it, replaced by `trigger_handle_job_completion_on_update`). The new generic trigger will replace `on_job_retrying` and may overlap with `on_new_job_created` for UPDATE operations (though `on_new_job_created` only fires on INSERT, so no conflict). Document that `handle_job_retrying()` contains special retry limit checking logic (checks if `attempt_count >= (max_retries + 1)` and marks job as `retry_loop_failed`) that must be preserved in the generic trigger or moved to a separate function.
    *   `[âœ…]` 1.c. `[TEST-INT]` **RED**: In `supabase/integration_tests/triggers/invoke_worker_on_status_change.trigger.test.ts`, write integration tests that prove the generic trigger preserves all existing `handle_job_retrying()` logic and provides new logic for missing state transitions.
        *   `[âœ…]` 1.c.i. Create a test file following the pattern of `handle_job_completion.trigger.test.ts` that sets up test database state (admin client, test user, project, session, stage).
        *   `[âœ…]` 1.c.ii. Write a test case that proves `pending_next_step` status DOES invoke worker (status updates to `pending_next_step` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no trigger for `pending_next_step`.
        *   `[âœ…]` 1.c.iii. Write a test case that proves `pending_continuation` status DOES invoke worker (status updates to `pending_continuation` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no trigger for `pending_continuation`.
        *   `[âœ…]` 1.c.iv. Write a test case that proves `pending` status set via UPDATE (when prerequisites complete) DOES invoke worker (status updates from `waiting_for_prerequisite` to `pending` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no UPDATE trigger for `pending` status.
        *   `[âœ…]` 1.c.v. Write a test case that proves `retrying` status with `attempt_count >= (max_retries + 1)` marks job as `retry_loop_failed` and does NOT invoke worker. This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.vi. Write a test case that proves `retrying` status with `attempt_count < (max_retries + 1)` invokes worker (creates log entry in `dialectic_trigger_logs`). This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.vii. Write a test case that proves test jobs (`is_test_job = true`) with `retrying` status do NOT invoke worker (creates log entry indicating test job skip, but no HTTP invocation attempt). This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.viii. Write a test case that proves status changes that do NOT require worker invocation (`processing`, `waiting_for_children`, `waiting_for_prerequisite`, `completed`, `failed`, `retry_loop_failed`) do NOT invoke worker. This test should pass initially and must continue to pass after the generic trigger is implemented.
        *   `[âœ…]` 1.c.ix. Write a test case that proves status updates where `OLD.status = NEW.status` do NOT invoke worker (no status change). This test must pass after the generic trigger is implemented.
    *   `[âœ…]` 1.d. `[DB]` **GREEN**: In `supabase/migrations/20251119160820_retrying_trigger.sql`, create a generic trigger that invokes the worker when job status changes to any status that requires processing.
        *   `[âœ…]` 1.d.i. Create or update a generic trigger function `invoke_worker_on_status_change()` that: (1) checks if the new status is one that requires worker invocation (`pending`, `pending_next_step`, `pending_continuation`, `retrying`), (2) only processes when status actually changes (not on every update: `OLD.status IS NULL OR OLD.status != NEW.status`), (3) skips test jobs (`COALESCE(NEW.is_test_job, false)`), (4) handles special retry limit checking for `retrying` status (if `attempt_count >= (max_retries + 1)`, mark job as `retry_loop_failed` and return early), (5) reuses the existing `invoke_dialectic_worker()` function's logic for determining worker URL (from vault secrets or local dev URL), extracting `user_jwt` from payload, building request body with job record, and invoking via `net.http_post()` using `pg_net` extension, (6) logs the invocation attempt to `dialectic_trigger_logs` table. Alternatively, update the existing `invoke_dialectic_worker()` function to accept both INSERT and UPDATE operations, and add status-checking logic to filter statuses that require invocation.
        *   `[âœ…]` 1.d.ii. Create a new trigger `on_job_status_change` that: (1) fires `AFTER UPDATE OF status`, (2) executes for each row where `NEW.status IN ('pending', 'pending_next_step', 'pending_continuation', 'retrying') AND (OLD.status IS NULL OR OLD.status != NEW.status)`, (3) calls the generic trigger function. This replaces the need for separate triggers for each status.
        *   `[âœ…]` 1.d.iii. **DEPRECATE**: Drop the `on_job_retrying` trigger and deprecate the `handle_job_retrying()` function (or keep it as a helper if retry limit checking is extracted). Add comments explaining that this generic trigger invokes the worker for any status change that requires processing, including PLAN jobs reaching `pending_next_step` status after all child jobs complete (set by `handle_job_completion` trigger), continuation jobs reaching `pending_continuation` status (set by `continueJob` function), jobs being retried (set by `retryJob` function), and jobs set to `pending` when prerequisites complete (set by `handle_job_completion` trigger). Note that `on_new_job_created` trigger remains active for handling INSERT operations, as it fires on a different event type and does not conflict with the UPDATE-based generic trigger.
    *   `[âœ…]` 1.e. `[TEST-INT]` **GREEN**: Re-run all tests from step 1.c and ensure they now pass. The tests from 1.c.ii, 1.c.iii, and 1.c.iv should now pass because the generic trigger handles these status transitions. The tests from 1.c.v, 1.c.vi, and 1.c.vii should continue to pass, proving that all existing `handle_job_retrying()` logic is preserved.

*   `[ ]` 2. **`[STORE]` Fix StageTabCard to Use Valid Document Artifacts Only for Completion Check**
    *   `[ ]` 2.a. `[DEPS]` The `selectStageProgressSummary` selector in `packages/store/src/dialecticStore.selectors.ts` (lines 661-733) counts ALL entries in `progress.documents`, including non-document artifacts like `header_context` (which has `artifact_class: 'header_context'` and `file_type: 'json'`). This causes `StageTabCard` to display incorrect counts like "Completed 1/1 documents" when only a `header_context` artifact exists, while `StageRunChecklist` correctly shows "0 of 4 documents" because it uses `selectValidMarkdownDocumentKeys` (lines 1014-1045) which filters out non-markdown artifacts. The `selectValidMarkdownDocumentKeys` selector uses `extractMarkdownDocumentKeysFromRule` (lines 933-1000) to identify valid markdown document keys from recipe steps' `outputs_required` fields, filtering based on `file_type === 'markdown'` or markdown template filenames, and excludes `header_context` artifacts. `StageTabCard` only needs `isComplete` to determine if the SubmitResponses button should be active (it doesn't need to display counts - that's handled by `StageRunChecklist`). The fix requires: (1) modifying `selectStageProgressSummary` to filter document keys using `selectValidMarkdownDocumentKeys` before counting, (2) removing the document count display from `StageTabCard` (lines 116-136 in `apps/web/src/components/dialectic/StageTabCard.tsx`), keeping only the `isComplete` check (line 121) for button activation.
    *   `[ ]` 2.b. `[TEST-UNIT]` **RED**: In `packages/store/src/dialecticStore.selectors.test.ts`, write a new test for `selectStageProgressSummary` that verifies it excludes non-document artifacts from counts.
        *   `[ ]` 2.b.i. Create a test case that sets up `stageRunProgress` state with both valid markdown document keys (e.g., `'draft_document_markdown'`) and non-document artifacts (e.g., `'HeaderContext'` with `artifact_class: 'header_context'`).
        *   `[ ]` 2.b.ii. Mock `selectValidMarkdownDocumentKeys` to return a Set containing only the valid markdown document keys (excluding `header_context`).
        *   `[ ]` 2.b.iii. Call `selectStageProgressSummary` with the test state and assert that `totalDocuments` and `completedDocuments` only count valid markdown documents, not `header_context` artifacts.
        *   `[ ]` 2.b.iv. Assert that `isComplete` is `false` when only `header_context` is completed but markdown documents are not, and `true` only when all valid markdown documents are completed. This test must fail because `selectStageProgressSummary` currently counts all entries in `progress.documents`.
    *   `[ ]` 2.c. `[STORE]` **GREEN**: In `packages/store/src/dialecticStore.selectors.ts`, modify `selectStageProgressSummary` (lines 661-733) to filter document keys using `selectValidMarkdownDocumentKeys` before counting.
        *   `[ ]` 2.c.i. Add `selectValidMarkdownDocumentKeys` as a dependency parameter to the selector (or use it within the selector function). The selector function signature is `(state: DialecticStateValues, sessionId: string, stageSlug: string, iterationNumber: number, modelId?: string)`, so we need to pass `stageSlug` to `selectValidMarkdownDocumentKeys(state, stageSlug)`.
        *   `[ ]` 2.c.ii. After getting `documentEntries` from `progress.documents` (line 689) and filtering by `modelId` (lines 691-695), filter the resulting `documentKeys` array to only include keys that exist in the Set returned by `selectValidMarkdownDocumentKeys(state, stageSlug)`.
        *   `[ ]` 2.c.iii. Use the filtered `documentKeys` array for all subsequent counting logic (lines 697-716) instead of the unfiltered array.
        *   `[ ]` 2.c.iv. Ensure the return type and values remain unchanged (the filtering only affects which documents are counted).
    *   `[ ]` 2.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 2.b and ensure it now passes. Also verify that existing tests for `selectStageProgressSummary` still pass.
    *   `[ ]` 2.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/StageTabCard.test.tsx`, write a test that verifies `StageTabCard` does not display document counts.
        *   `[ ]` 2.e.i. Render `StageTabCard` with mock store state that includes stage progress with valid documents.
        *   `[ ]` 2.e.ii. Assert that the document count display (the element with `data-testid={`stage-progress-count-${stage.slug}`}`) is NOT rendered (or does not contain count text).
        *   `[ ]` 2.e.iii. Assert that `isComplete` check (the element with `data-testid={`stage-progress-label-${stage.slug}`}`) is still rendered when `isComplete` is `true`. This test must fail because `StageTabCard` currently displays counts.
    *   `[ ]` 2.f. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/StageTabCard.tsx`, remove the document count display while keeping the completion check for button activation.
        *   `[ ]` 2.f.i. Remove the document count display div (lines 116-136) that shows `${progress.completedDocuments} / ${progress.totalDocuments} documents` (line 133).
        *   `[ ]` 2.f.ii. Keep the `isComplete` check (lines 121-128) that displays "Completed" label when `progress.isComplete` is `true`, as this is needed for visual feedback and may be used for the SubmitResponses button activation logic.
        *   `[ ]` 2.f.iii. Update the `hasDocuments` check (line 80) if needed - it currently checks `progress.totalDocuments > 0`, which should still work correctly after the selector fix (it will now reflect valid documents only). Alternatively, check `progress.isComplete` directly if that's the only requirement.
        *   `[ ]` 2.f.iv. Update any TypeScript types or interfaces if the `StageProgressSnapshotSummary` interface (lines 19-23) needs modification (it may not need changes if the selector still returns the same structure, just with filtered counts).
    *   `[ ]` 2.g. `[TEST-UNIT]` **GREEN**: Re-run the test from step 2.e and ensure it now passes. Also verify that existing `StageTabCard` tests still pass.
    *   `[ ]` 2.h. `[LINT]` Run the linter for all modified files (`packages/store/src/dialecticStore.selectors.ts`, `apps/web/src/components/dialectic/StageTabCard.tsx`) and resolve any warnings or errors.

*   `[ ]` 3. **`[UI]` Remove Document Progress Display from SessionContributionsDisplayCard**
    *   `[ ]` 3.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` is a container component whose responsibility is to contain child components that display document information, not to display document progress itself. Currently, it displays progress summary "Completed X of Y documents" (lines 474-484) using `selectStageProgressSummary`, which is incorrect because: (1) Displaying document progress is not the container's job - that responsibility belongs to child components like `StageRunChecklist` which already correctly displays progress counts; (2) The progress summary display includes non-document artifacts like `header_context` (which will be fixed by item 2's changes to `selectStageProgressSummary`, but the container shouldn't be displaying progress at all); (3) The container should only use `stageProgressSummary?.isComplete` (line 231) for button activation logic (`canSubmitStageResponses`), not for displaying progress counts. The container correctly uses `isComplete` for button activation (line 390) and `hasFailed` for error display (lines 282-293, 516-540), which are valid container responsibilities (managing UI state and error handling). The fix requires: (1) removing the progress summary display (lines 474-484) that shows "Completed X of Y documents", (2) keeping the `isComplete` check (line 231) for button activation logic, (3) keeping the `hasFailed` check (lines 282-293) for error display if needed, or verifying if error display should also be delegated to child components.
    *   `[ ]` 3.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx` (or create if it doesn't exist), write a test that verifies the component does not display document progress summary.
        *   `[ ]` 3.b.i. Render `SessionContributionsDisplayCard` with mock store state that includes `stageProgressSummary` with `completedDocuments`, `totalDocuments`, and `outstandingDocuments` properties.
        *   `[ ]` 3.b.ii. Assert that the progress summary display (the element containing "Completed X of Y documents" text, or the div at lines 474-484) is NOT rendered (or does not contain progress count text).
        *   `[ ]` 3.b.iii. Assert that the `canSubmitStageResponses` logic still works correctly (the submit button is enabled when `isComplete` is `true` and disabled when `isComplete` is `false`). This test must fail because `SessionContributionsDisplayCard` currently displays progress counts.
    *   `[ ]` 3.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, remove the document progress summary display while keeping the completion check for button activation.
        *   `[ ]` 3.c.i. Remove the progress summary display div (lines 474-484) that shows "Completed {stageProgressSummary.completedDocuments} of {stageProgressSummary.totalDocuments} documents" and "Outstanding: ..." text.
        *   `[ ]` 3.c.ii. Keep the `stageProgressSummary` selector usage (lines 218-229) because it's still needed for `isComplete` check (line 231) and `hasFailed` check (lines 282-283) for button activation and error handling logic.
        *   `[ ]` 3.c.iii. Ensure the `canSubmitStageResponses` logic (line 231) still works correctly - it uses `stageProgressSummary?.isComplete === true` which is valid container responsibility (button activation logic).
        *   `[ ]` 3.c.iv. Verify that error display logic (lines 282-293, 516-540) using `stageProgressSummary?.hasFailed` and `failedDocumentKeys` still works if needed, or consider if error display should also be delegated to child components. For now, keep it since error handling is a valid container responsibility.
    *   `[ ]` 3.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 3.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify button activation logic using `isComplete`).
    *   `[ ]` 3.e. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[ ]` 4. **`[UI]` Fix GeneratedContributionCard to Exclude Non-Document Artifacts from Status Display**
    *   `[ ]` 4.a. `[DEPS]` The `GeneratedContributionCard` component in `apps/web/src/components/dialectic/GeneratedContributionCard.tsx` correctly filters out non-document artifacts when rendering document content (lines 136-141 use `selectValidMarkdownDocumentKeys` to check `isValidMarkdownDocument`, and lines 345-468 only render document content when `focusedDocument && isValidMarkdownDocument` is true). However, it still displays the status badge for ALL focused documents, including non-document artifacts like `header_context` (lines 330-334). The `documentDescriptor` is retrieved from `stageRunProgress.documents?.[focusedDocument.documentKey]` (lines 193-196), which includes ALL entries in `progress.documents`, including `header_context` artifacts. The status badge should only be shown for valid markdown documents. Additionally, `StageRunChecklist` (used at line 339) should already filter out non-markdown documents after item 3's fix to `selectStageDocumentChecklist`, but we need to ensure `GeneratedContributionCard` doesn't show status for non-document artifacts even if they somehow become focused. The fix requires: (1) modifying the status badge display (lines 330-334) to only show when `isValidMarkdownDocument` is true, ensuring non-document artifacts like `header_context` don't show completion status even if they become focused.
    *   `[ ]` 4.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/GeneratedContributionCard.test.tsx`, write a test that verifies the component does not display status badge for non-document artifacts.
        *   `[ ]` 4.b.i. Render `GeneratedContributionCard` with mock store state where `focusedDocument` has a `documentKey` that is NOT in `validMarkdownDocumentKeys` (e.g., `'HeaderContext'` with `artifact_class: 'header_context'`).
        *   `[ ]` 4.b.ii. Mock `stageRunProgress` to include a `header_context` entry with status `'completed'` in `documents` map.
        *   `[ ]` 4.b.iii. Assert that the status badge (the element with `Badge` variant="secondary" containing status text, or the element at lines 330-334) is NOT rendered when `isValidMarkdownDocument` is `false`. This test must fail because `GeneratedContributionCard` currently shows status badge for all focused documents regardless of whether they are valid markdown documents.
    *   `[ ]` 4.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/GeneratedContributionCard.tsx`, modify the status badge display to only show for valid markdown documents.
        *   `[ ]` 4.c.i. Update the status badge condition (line 330) from `{documentDescriptor && (` to `{documentDescriptor && isValidMarkdownDocument && (` to ensure the badge is only shown when the focused document is a valid markdown document.
        *   `[ ]` 4.c.ii. Ensure the `isValidMarkdownDocument` check (lines 136-141) still works correctly - it uses `selectValidMarkdownDocumentKeys(state, stageSlug)` (lines 129-134) to filter out non-markdown artifacts like `header_context`.
        *   `[ ]` 4.c.iii. Verify that document content rendering logic (lines 345-468) already correctly filters using `isValidMarkdownDocument` - no changes needed here as it already has the correct check.
        *   `[ ]` 4.c.iv. Ensure that `StageRunChecklist` component (line 339) will correctly filter non-markdown documents after item 3's fix to `selectStageDocumentChecklist`, but this fix ensures `GeneratedContributionCard` doesn't show status even if a non-document artifact somehow becomes focused.
    *   `[ ]` 4.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 4.b and ensure it now passes. Also verify that existing `GeneratedContributionCard` tests still pass (especially tests that verify status badge displays correctly for valid markdown documents).
    *   `[ ]` 4.e. `[LINT]` Run the linter for `apps/web/src/components/dialectic/GeneratedContributionCard.tsx` and resolve any warnings or errors.

*   `[ ]` 5. **`[UI]` Change Submit Responses Button to Detect Last Stage and Disable Itself with a "Project Complete" Notice**
    *   `[ ]` 5.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` uses a Submit Responses button (`renderSubmitButton()` at lines 387-401) that enables when `canSubmitStageResponses` is `true` (based on `stageProgressSummary?.isComplete` at line 231). The button currently always allows submission and advancement to the next stage when enabled, but should be disabled with a "Project Complete" notice when the user is in the last stage of the dialectic process. The component already has access to `sortedStages` via `selectSortedStages` (line 110) and `processTemplate` via the store (lines 107-109). The `activeStage` is computed from `processTemplate` (lines 117-119). To detect the last stage, we can check if `activeStage.slug` matches the last stage in `sortedStages` array (similar to how `SessionInfoCard` detects `isFinalStageInProcess` at lines 83-87, which checks if there are no transitions where the current stage is the source). Alternatively, we can check if `activeStage.slug === sortedStages[sortedStages.length - 1]?.slug`. The fix requires: (1) adding a `useMemo` hook to compute `isLastStage` based on `sortedStages` and `activeStage`, (2) modifying the button to be disabled when `isLastStage` is `true`, (3) displaying a "Project Complete" notice when `isLastStage` is `true` and `canSubmitStageResponses` is `true` (indicating all documents are complete), (4) ensuring the button text or notice clearly indicates that the project is complete and no further stages are available.
    *   `[ ]` 5.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the Submit Responses button is disabled when in the last stage.
        *   `[ ]` 5.b.i. Create a test case that mocks store state with `sortedStages` containing multiple stages (e.g., `['thesis', 'antithesis', 'synthesis']`) and sets `activeStageSlug` to the last stage (`'synthesis'`).
        *   `[ ]` 5.b.ii. Mock `stageProgressSummary` to have `isComplete: true` (so `canSubmitStageResponses` would normally be `true`).
        *   `[ ]` 5.b.iii. Render `SessionContributionsDisplayCard` and assert that the Submit Responses button (the element with text "Submit Responses & Advance Stage" or `data-testid` if available) is disabled when in the last stage, even if `canSubmitStageResponses` is `true`.
        *   `[ ]` 5.b.iv. Assert that a "Project Complete" notice is displayed when in the last stage and all documents are complete. This test must fail because the button currently doesn't check for last stage.
    *   `[ ]` 5.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, add last stage detection and modify the button to be disabled with a notice when in the last stage.
        *   `[ ]` 5.c.i. Add a `useMemo` hook (after line 231) to compute `isLastStage` by checking if `activeStage?.slug === sortedStages[sortedStages.length - 1]?.slug`. Handle the case where `sortedStages` is empty or `activeStage` is null (return `false`).
        *   `[ ]` 5.c.ii. Modify `renderSubmitButton()` (lines 387-401) to disable the button when `isLastStage` is `true` by adding `|| isLastStage` to the `disabled` condition (line 390), or create a new computed value `isButtonDisabled = isSubmitting || !canSubmitStageResponses || isLastStage`.
        *   `[ ]` 5.c.iii. Add a conditional render after `renderSubmitButton()` (or modify the button section) that displays a "Project Complete" notice when `isLastStage && canSubmitStageResponses` is `true`. The notice should be a non-interactive element (e.g., a `Badge`, `Alert`, or styled `div`) with text like "Project Complete - All stages finished" or similar, styled appropriately to indicate completion.
        *   `[ ]` 5.c.iv. Ensure the button text remains "Submit Responses & Advance Stage" (line 398) - the button should just be disabled in the last stage, not change its text. The notice should be separate from the button.
        *   `[ ]` 5.c.v. Handle edge cases: if `sortedStages` is empty, `isLastStage` should be `false`. If `activeStage` is null, `isLastStage` should be `false`. If there's only one stage, it should be considered the last stage.
    *   `[ ]` 5.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 5.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify button enabling/disabling based on `canSubmitStageResponses`).
    *   `[ ]` 5.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the button still works correctly for non-last stages.
        *   `[ ]` 5.e.i. Create a test case that mocks store state with `sortedStages` containing multiple stages and sets `activeStageSlug` to a non-last stage (e.g., `'thesis'` when stages are `['thesis', 'antithesis', 'synthesis']`).
        *   `[ ]` 5.e.ii. Mock `stageProgressSummary` to have `isComplete: true` and assert that the Submit Responses button is enabled (not disabled) when not in the last stage.
        *   `[ ]` 5.e.iii. Assert that the "Project Complete" notice is NOT displayed when not in the last stage. This test should pass immediately after step 5.c if implemented correctly.
    *   `[ ]` 5.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 5.e and ensure it passes. This verifies that the fix doesn't break normal button behavior for non-last stages.
    *   `[ ]` 5.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[ ]` 6. **`[UI]` Remove Conditional "Export Final" Button from SessionInfoCard**
    *   `[ ]` 6.a. `[DEPS]` The `SessionInfoCard` component in `apps/web/src/components/dialectic/SessionInfoCard.tsx` displays a conditional "Export Final" button (lines 287-297) that appears when `isFinalStageInProcess` is `true`. However, there is now an always-visible "Export" button (lines 247-257) that provides the same functionality, making the conditional "Export Final" button redundant and deprecated. The `isFinalStageInProcess` logic (lines 83-87) is computed based on process template transitions and is currently used in two places: (1) to hide the Submit button in the final stage (line 261: `!isFinalStageInProcess`), and (2) to show the conditional "Export Final" button (line 288: `isFinalStageInProcess && project &&`). The fix requires: (1) removing the conditional "Export Final" button (lines 287-297), (2) keeping the `isFinalStageInProcess` logic since it's still needed to hide the Submit button in the final stage (line 261), (3) removing the comment "Final stage export button" (line 287) as it's no longer relevant. The always-visible "Export" button (lines 247-257) provides the export functionality for all stages, eliminating the need for the conditional button.
    *   `[ ]` 6.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionInfoCard.test.tsx`, write a test that verifies the "Export Final" button is never displayed.
        *   `[ ]` 6.b.i. Create a test case that mocks store state with `isFinalStageInProcess` set to `true` (by setting up a project with process template transitions where the current stage has no outgoing transitions).
        *   `[ ]` 6.b.ii. Mock `project` to be non-null and render `SessionInfoCard`.
        *   `[ ]` 6.b.iii. Assert that the "Export Final" button (the element with text "Export Final" or `data-testid` if available) is NOT rendered, even when `isFinalStageInProcess` is `true`.
        *   `[ ]` 6.b.iv. Assert that the always-visible "Export" button (lines 247-257) is still rendered. This test must fail because the conditional "Export Final" button currently displays when `isFinalStageInProcess` is `true`.
    *   `[ ]` 6.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionInfoCard.tsx`, remove the conditional "Export Final" button while keeping the Submit button hiding logic.
        *   `[ ]` 6.c.i. Remove the conditional "Export Final" button block (lines 287-297), including the comment "Final stage export button" (line 287), the conditional check `{isFinalStageInProcess && project && (`, the `ExportProjectButton` component with "Export Final" text, and the closing `)}`.
        *   `[ ]` 6.c.ii. Keep the `isFinalStageInProcess` computation (lines 83-87) since it's still needed to hide the Submit button in the final stage (line 261: `!isFinalStageInProcess`). Do not remove this logic.
        *   `[ ]` 6.c.iii. Verify that the always-visible "Export" button (lines 247-257) remains unchanged and continues to provide export functionality for all stages.
        *   `[ ]` 6.c.iv. Ensure the Submit button hiding logic (lines 259-285) still works correctly - it should hide the Submit button when `isFinalStageInProcess` is `true`, which is the correct behavior since users shouldn't submit to advance when already in the final stage.
    *   `[ ]` 6.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 6.b and ensure it now passes. Also verify that existing `SessionInfoCard` tests still pass (especially tests that verify the always-visible "Export" button and the Submit button hiding logic).
    *   `[ ]` 6.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionInfoCard.test.tsx`, write a test that verifies the always-visible "Export" button is still rendered in all stages.
        *   `[ ]` 6.e.i. Create test cases for both final and non-final stages (by setting up projects with different process template transition configurations).
        *   `[ ]` 6.e.ii. Assert that the always-visible "Export" button (lines 247-257) is rendered regardless of whether `isFinalStageInProcess` is `true` or `false`. This test should pass immediately after step 6.c if the always-visible button was not modified.
    *   `[ ]` 6.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 6.e and ensure it passes. This verifies that the always-visible "Export" button continues to work correctly for all stages.
    *   `[ ]` 6.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionInfoCard.tsx` and resolve any warnings or errors.

*   `[ ]` 7. **`[UI]` Fix SessionContributionsDisplayCard to Hide Loader Until Generation Starts**
    *   `[ ]` 7.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` displays a "Generating documents" loader (lines 501-515) when `isGenerating` is `true`. The `isGenerating` logic (lines 295-298) checks `contributionGenerationStatus === 'generating'`, which is a global state that can be `'generating'` even when: (1) no models are selected for the current session (`selectedModelIds` might be empty), (2) the Generate button hasn't been clicked (the status might persist from a previous session or stage), (3) a different session is generating (the global status applies to all sessions). The `contributionGenerationStatus` is set to `'generating'` when `generateContributions` is called (line 1696 in `dialecticStore.ts`) and is reset to `'idle'` only when all sessions finish generating (lines 1393-1394, 1577, 1673 in `dialecticStore.ts`). However, there is a more precise per-session state `generatingSessions` (a map of `{ [sessionId]: string[] }` containing job IDs) and a selector `selectGeneratingSessionsForSession` (lines 196-198 in `dialecticStore.ts`) that returns active job IDs for a specific session. The `SessionInfoCard` component correctly uses this per-session check (lines 66-69) via `selectGeneratingSessionsForSession(state, session.id)` to determine if generation is active. The fix requires: (1) replacing the global `contributionGenerationStatus === 'generating'` check in `isGenerating` (line 296) with a per-session check using `selectGeneratingSessionsForSession(state, session.id)` to ensure the loader only shows when the current session has active generation jobs, (2) optionally checking `selectedModelIds.length > 0` to ensure models are selected, (3) ensuring the loader display logic (lines 501-515) correctly reflects the session-specific generation state.
    *   `[ ]` 7.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the loader does not display when the current session is not generating.
        *   `[ ]` 7.b.i. Create a test case that mocks store state where `contributionGenerationStatus` is `'generating'` but `generatingSessions[activeSessionId]` is empty or undefined (simulating a different session generating).
        *   `[ ]` 7.b.ii. Mock `selectedModelIds` to be empty (no models selected).
        *   `[ ]` 7.b.iii. Render `SessionContributionsDisplayCard` with the test state and assert that the "Generating documents" loader (the element with text "Generating documents" or `data-testid` if available) is NOT displayed when the current session has no active generation jobs.
        *   `[ ]` 7.b.iv. Assert that the loader is NOT displayed when `selectedModelIds` is empty, even if `contributionGenerationStatus` is `'generating'`. This test must fail because the component currently uses the global `contributionGenerationStatus` which can be `'generating'` even when the current session isn't generating.
    *   `[ ]` 7.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, replace the global generation status check with a per-session check.
        *   `[ ]` 7.c.i. Import `selectGeneratingSessionsForSession` from `@paynless/store` if not already imported (add to imports at top of file).
        *   `[ ]` 7.c.ii. Add a new `useDialecticStore` hook (after line 143) to get `generatingJobs` for the current session: `const generatingJobs = useDialecticStore((state) => session ? selectGeneratingSessionsForSession(state, session.id) : []);`. This uses the same pattern as `SessionInfoCard` (lines 66-68).
        *   `[ ]` 7.c.iii. Optionally add a check for `selectedModelIds` (the component already accesses `selectedModelIds` indirectly via `documentsByModel`, but we can add an explicit check if needed). Alternatively, check `selectedModelIds.length > 0` in the `isGenerating` logic.
        *   `[ ]` 7.c.iv. Modify `isGenerating` (lines 295-298) to check `generatingJobs.length > 0` instead of (or in addition to) `contributionGenerationStatus === 'generating'`. The new logic should be: `const isGenerating = generatingJobs.length > 0 && failedDocumentKeys.length === 0 && !generationError;`. This ensures the loader only shows when the current session has active generation jobs.
        *   `[ ]` 7.c.v. Remove or keep the `contributionGenerationStatus` selector usage (line 141-143) - it may still be used elsewhere or can be removed if not needed. However, since we're replacing it with `generatingJobs`, we can keep it for now if other code depends on it, or remove it if it's only used for `isGenerating`.
        *   `[ ]` 7.c.vi. Ensure the loader display logic (lines 501-515) correctly uses the updated `isGenerating` value - no changes needed here as it already uses `isGenerating`.
    *   `[ ]` 7.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 7.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify the loader displays correctly when generation is active).
    *   `[ ]` 7.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the loader displays correctly when the current session is generating.
        *   `[ ]` 7.e.i. Create a test case that mocks store state where `generatingSessions[activeSessionId]` contains job IDs (e.g., `['job-1', 'job-2']`) for the current session.
        *   `[ ]` 7.e.ii. Mock `failedDocumentKeys` to be empty and `generationError` to be null.
        *   `[ ]` 7.e.iii. Render `SessionContributionsDisplayCard` and assert that the "Generating documents" loader IS displayed when the current session has active generation jobs. This test should pass immediately after step 7.c if implemented correctly.
    *   `[ ]` 7.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 7.e and ensure it passes. This verifies that the loader still works correctly when generation is actually active for the current session.
    *   `[ ]` 7.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[âœ…]` 8. **`[BE]` Fix Recipe Step Output Type to Use Model Contribution File Type**
    *   `[âœ…]` 8.a. `[DEPS]` Recipe steps in database migrations have `output_type: 'rendered_document'` (the final product), but planners expect `output_type` to be a `ModelContributionFileType` (what the model produces). The actual document key (e.g., `business_case`, `feature_spec`, `technical_approach`, `success_metrics`) is found in `outputs_required.documents[0].document_key`. The `getStageRecipe.ts` function in `supabase/functions/dialectic-service/getStageRecipe.ts` (lines 89-99) validates `output_type` against only 3 values (`HeaderContext`, `AssembledDocumentJson`, `RenderedDocument`), which is architecturally incorrect: `HeaderContext` and `AssembledDocumentJson` are backend-only and should never be sent to the frontend. The `OutputType` type in `supabase/functions/dialectic-service/dialectic.interface.ts` (lines 627-631) incorrectly includes these backend-only types. All planners (`planPerSourceDocument`, `planAllToOne`, `planPerSourceGroup`, `planPairwiseByOrigin`, `planPerSourceDocumentByLineage`, `planPerModel`) validate that `recipeStep.output_type` must be a `ModelContributionFileType` (using `isModelContributionFileType` check), and they use it directly to set `jobPayload.output_type` for EXECUTE jobs. The `shouldEnqueueRenderJob` function in `supabase/functions/_shared/utils/shouldEnqueueRenderJob.ts` checks if `outputType` matches any `document_key` in `outputs_required` that has markdown `file_type`, so `output_type` should match `document_key` for proper rendering logic. Every `document_key` is a `FileType`, and `output_type` should match the `document_key` to create semantic alignment. The fix requires: (1) defining `OutputType` as a subset of `ModelContributionFileTypes` that become rendered documents (excludes `HeaderContext`, `AssembledDocumentJson`, and other backend-only types), (2) updating all stage migration files (`20251006194531_thesis_stage.sql`, `20251006194542_antithesis_stage.sql`, `20251006194558_parenthesis_stage.sql`, `20251006194549_synthesis_stage.sql`, `20251006194605_paralysis_stage.sql`) to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'` for all EXECUTE job steps, (3) updating `getStageRecipe.ts` to validate that `output_type` is a `ModelContributionFileType` and is in the `OutputType` subset (renderable types), and pass it through as-is to the DTO (no mapping needed since `output_type` will match `document_key`), (4) filtering out PLAN job steps with `header_context` output from the DTO sent to frontend (or handling them separately) since they are backend-only.
    *   `[âœ…]` 8.b. `[TYPES]` In `supabase/functions/dialectic-service/dialectic.interface.ts`, define `OutputType` as a subset of `ModelContributionFileTypes` that become rendered documents. This excludes backend-only types like `HeaderContext`, `AssembledDocumentJson`, `ModelContributionRawJson`, `PairwiseSynthesisChunk`, `ReducedSynthesis`, `Synthesis`, `header_context_pairwise`, `SynthesisHeaderContext`, and other intermediate types that don't become user-facing rendered documents. The `OutputType` should include all `ModelContributionFileTypes` that have markdown outputs in `outputs_required` (e.g., `business_case`, `feature_spec`, `technical_approach`, `success_metrics`, `business_case_critique`, `technical_feasibility_assessment`, `risk_register`, `non_functional_requirements`, `dependency_map`, `comparison_vector`, `product_requirements`, `system_architecture`, `tech_stack`, `technical_requirements`, `master_plan`, `milestone_schema`, `updated_master_plan`, `actionable_checklist`, `advisor_recommendations`). Import `ModelContributionFileTypes` from `../_shared/types/file_manager.types.ts` and create a manually curated union type `OutputType` that includes only the renderable `ModelContributionFileTypes`. This provides type safety and semantic clarity: `OutputType` represents "FileTypes that become RenderedDocument". Replace the current `OutputType` definition (lines 627-631) with this new subset type.
    *   `[âœ…]` 8.b.i. `[TYPES]` In `supabase/functions/_shared/utils/type-guards/type_guards.file_manager.ts`, create a type guard function `isOutputType(value: ModelContributionFileTypes): value is OutputType` that validates if a `ModelContributionFileType` is in the `OutputType` subset (renderable types). This function should check against a runtime map similar to `MODEL_CONTRIBUTION_FILE_TYPES_MAP`, but only include the renderable types. Import `OutputType` from `../../dialectic-service/dialectic.interface.ts` and create `OUTPUT_TYPES_MAP: { [K in OutputType]: true }` with all renderable types, then implement `isOutputType` to check if the value exists in this map.
    *   `[âœ…]` 8.c. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-service/getStageRecipe.test.ts` (or create if it doesn't exist), write tests that verify `getStageRecipe` accepts renderable `ModelContributionFileTypes` (those in `OutputType`) for EXECUTE job steps and filters out backend-only types.
        *   `[âœ…]` 8.c.i. Create a test case that mocks a recipe step with `output_type: 'business_case'` (a renderable `ModelContributionFileType` in `OutputType`) and `job_type: 'EXECUTE'`, and assert that `getStageRecipe` returns successfully with `output_type: 'business_case'` in the response DTO.
        *   `[âœ…]` 8.c.ii. Create a test case that mocks a recipe step with `output_type: 'feature_spec'` (a renderable `ModelContributionFileType` in `OutputType`) and `job_type: 'EXECUTE'`, and assert that `getStageRecipe` returns successfully with `output_type: 'feature_spec'` in the response DTO.
        *   `[âœ…]` 8.c.iii. Create a test case that mocks a recipe step with `output_type: 'header_context'` (a backend-only `ModelContributionFileType` NOT in `OutputType`) and `job_type: 'PLAN'`, and assert that `getStageRecipe` either: (a) excludes this step from the DTO response (filters it out), or (b) returns an error indicating backend-only types cannot be sent to frontend. PLAN jobs with `header_context` are backend-only and should not appear in the frontend DTO.
        *   `[âœ…]` 8.c.iv. Create a test case that mocks a recipe step with `output_type: 'rendered_document'` (which is NOT a `ModelContributionFileType`), and assert that `getStageRecipe` returns an error. The database should never have `output_type: 'rendered_document'` after migrations are updated.
        *   `[âœ…]` 8.c.v. These tests must fail initially because `getStageRecipe.ts` validation (lines 89-99) only accepts 3 values (`HeaderContext`, `AssembledDocumentJson`, `RenderedDocument`), not the renderable `ModelContributionFileTypes`.
    *   `[âœ…]` 8.d. `[BE]` **GREEN**: In `supabase/functions/dialectic-service/getStageRecipe.ts`, update the validation logic (lines 89-99) to validate that `output_type` is a `ModelContributionFileType` and is in the `OutputType` subset (renderable types), and filter out backend-only steps from the DTO.
        *   `[âœ…]` 8.d.i. Import `ModelContributionFileTypes`, `isModelContributionFileType`, and `OutputType` from `../_shared/types/file_manager.types.ts`, `../_shared/utils/type-guards/type_guards.file_manager.ts`, and `./dialectic.interface.ts` respectively (if not already imported).
        *   `[âœ…]` 8.d.ii. Replace the restrictive validation (lines 92-99) that only accepts 3 values with: (1) a check that uses `isModelContributionFileType(rawType)` to validate that `output_type` is a valid `ModelContributionFileType`, (2) a check that uses `isOutputType(rawType)` (from step 8.b.i) to verify `rawType` is in the `OutputType` subset (renderable types). If `output_type` is a `ModelContributionFileType` but not in `OutputType`, either filter out the step (for backend-only types like `header_context`) or return an error.
        *   `[âœ…]` 8.d.iii. Set `mappedOutputType` to `rawType as OutputType` after validating it's in the `OutputType` subset. The `output_type` passes through as-is (no mapping needed) since it will match `document_key` in `outputs_required`.
        *   `[âœ…]` 8.d.iv. For PLAN job steps with `output_type: 'header_context'` (or other backend-only types), either: (a) filter them out before adding to the `normalized` array (skip adding the DTO), or (b) return an error. Option (a) is preferred - backend-only steps should not be sent to the frontend.
        *   `[âœ…]` 8.d.v. Remove the error logging that references only the 3 specific values, and update it to log any invalid `output_type` that fails the `isModelContributionFileType` check or is not in the `OutputType` subset.
    *   `[âœ…]` 8.e. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 8.c and ensure they now pass. Verify that: (1) renderable `ModelContributionFileTypes` pass validation and appear in the DTO, (2) backend-only types like `header_context` are filtered out from the DTO, (3) invalid types return errors. Also verify that existing `getStageRecipe` tests still pass, but note that PLAN job steps with `header_context` should no longer appear in the DTO response (they are filtered out as backend-only).
    *   `[âœ…]` 8.f. `[DB]` In `supabase/migrations/20251006194531_thesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.g.i. For template step `'thesis_generate_business_case'` (line 323): change `output_type` from `'rendered_document'` (line 329) to `'business_case'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 336).
        *   `[âœ…]` 8.g.ii. For template step `'thesis_generate_feature_spec'` (line 485): change `output_type` from `'rendered_document'` (line 491) to `'feature_spec'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 498).
        *   `[âœ…]` 8.g.iii. For template step `'thesis_generate_technical_approach'` (line 643): change `output_type` from `'rendered_document'` (line 649) to `'technical_approach'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 656).
        *   `[âœ…]` 8.g.iv. For template step `'thesis_generate_success_metrics'` (line 800): change `output_type` from `'rendered_document'` (line 806) to `'success_metrics'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 813).
        *   `[âœ…]` 8.g.v. For instance step `'thesis_generate_business_case'` (line 1060): change `output_type` from `'rendered_document'` (line 1065) to `'business_case'`.
        *   `[âœ…]` 8.g.vi. For instance step `'thesis_generate_feature_spec'` (line 1132): change `output_type` from `'rendered_document'` (line 1137) to `'feature_spec'`.
        *   `[âœ…]` 8.g.vii. For instance step `'thesis_generate_technical_approach'` (line 1200): change `output_type` from `'rendered_document'` (line 1205) to `'technical_approach'`.
        *   `[âœ…]` 8.g.viii. For instance step `'thesis_generate_success_metrics'` (line 1267): change `output_type` from `'rendered_document'` (line 1272) to `'success_metrics'`.
        *   `[âœ…]` 8.g.ix. Verify that PLAN job steps (e.g., `'thesis_build_stage_header'`) keep their `output_type: 'header_context'` unchanged, as these are correct.
    *   `[âœ…]` 8.h. `[DB]` In `supabase/migrations/20251006194542_antithesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.h.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for antithesis stage include: `'business_case_critique'`, `'technical_feasibility_assessment'`, `'risk_register'`, `'non_functional_requirements'`, `'dependency_map'`, `'comparison_vector'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.i. `[DB]` In `supabase/migrations/20251006194558_parenthesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.i.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for parenthesis stage include: `'technical_requirements'`, `'master_plan'`, `'milestone_schema'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.j. `[DB]` In `supabase/migrations/20251006194549_synthesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.j.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for synthesis stage include: `'product_requirements'`, `'system_architecture'`, `'tech_stack'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.k. `[DB]` In `supabase/migrations/20251006194605_paralysis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.k.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for paralysis stage include: `'updated_master_plan'`, `'actionable_checklist'`, `'advisor_recommendations'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.l. `[TEST-INT]` **RED**: In `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file, write a test that verifies planners can successfully create EXECUTE jobs from recipe steps with `output_type` set to actual `ModelContributionFileTypes` (e.g., `'business_case'`) when using real recipe steps from the updated database.
        *   `[âœ…]` 8.l.i. Create a test case that sets up a PLAN job and fetches real recipe steps from the database (after migrations are updated in steps 8.f-8.k).
        *   `[âœ…]` 8.l.ii. Find an EXECUTE job recipe step (e.g., `'thesis_generate_business_case'`) and verify it has `output_type: 'business_case'` (not `'rendered_document'`).
        *   `[âœ…]` 8.l.iii. Call the planner function (e.g., `planPerSourceDocument`) with the recipe step and source documents, and assert that it successfully creates child EXECUTE job payloads with `output_type: 'business_case'`.
        *   `[âœ…]` 8.l.iv. Assert that the `isModelContributionFileType` validation in the planner passes (no error is thrown).
        *   `[âœ…]` 8.l.v. Verify that `output_type` in the recipe step matches `document_key` in `outputs_required.documents[0].document_key` (e.g., both are `'business_case'`), ensuring semantic alignment. This test verifies the end-to-end flow: database has correct `output_type` matching `document_key`, `getStageRecipe` returns it correctly, and planners can use it to create EXECUTE jobs.
    *   `[âœ…]` 8.m. `[TEST-INT]` **GREEN**: Re-run the test from step 8.l and ensure it passes. This verifies that the complete end-to-end flow works correctly after all changes (types updated, source code updated, database migrations applied).
    *   `[âœ…]` 8.n. `[LINT]` Run the linter for all modified files (`supabase/functions/dialectic-service/dialectic.interface.ts`, `supabase/functions/dialectic-service/getStageRecipe.ts`) and resolve any warnings or errors.

*   `[âœ…]` 9. **`[BE]` Fix assembleTurnPrompt to Query Header Context by Contribution ID Instead of Storage Path**
    *   `[âœ…]` 9.a. `[DEPS]` The `assembleTurnPrompt` function in `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` (lines 47-51, 78-82) requires `payload.header_context_resource_id` (a storage path string) and hardcodes bucket `"SB_CONTENT_STORAGE_BUCKET"` to download header context. However, planners (e.g., `planPerSourceDocument` in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, line 88) set `inputs[`${doc.contribution_type}_id`] = doc.id`, which for `header_context` creates `inputs.header_context_id` with the contribution ID. Header context is stored as a contribution in `dialectic_contributions` with `contribution_type = 'header_context'`. The `assemblePlannerPrompt` and `assembleSeedPrompt` functions correctly use `gatherInputsForStage` which queries contributions by metadata (stage, iteration, etc.) and gets storage details from the database record, avoiding duplication of storage paths in payloads. The fix requires: (1) updating `assembleTurnPrompt` to read `inputs.header_context_id` from `job.payload.inputs.header_context_id`, query `dialectic_contributions` by that ID to get `storage_bucket`, `storage_path`, and `file_name`, construct the full path, and download using the record's bucket (matching the pattern in `gatherInputsForStage` lines 104-185), (2) removing the `header_context_resource_id` requirement from the payload precondition check (line 47-51), (3) removing the hardcoded bucket usage, ensuring the function uses the database as the single source of truth for storage details.
    *   `[âœ…]` 9.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.test.ts`, write tests that verify `assembleTurnPrompt` queries header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 9.b.i. Create a test case that mocks a job payload with `inputs.header_context_id` set to a contribution ID (e.g., `"contrib-123"`), and mocks a database query to `dialectic_contributions` that returns a contribution record with `storage_bucket: "dialectic_contributions"`, `storage_path: "path/to/header"`, `file_name: "header_context.json"`, and `contribution_type: "header_context"`.
        *   `[âœ…]` 9.b.ii. Mock `downloadFromStorage` to be called with the contribution's `storage_bucket` and the constructed path (`${storage_path}/${file_name}`) instead of hardcoded `"SB_CONTENT_STORAGE_BUCKET"` and `payload.header_context_resource_id`.
        *   `[âœ…]` 9.b.iii. Assert that `assembleTurnPrompt` successfully queries the contribution by ID, constructs the storage path from the record, and downloads using the record's bucket. This test must fail because `assembleTurnPrompt` currently requires `header_context_resource_id` in payload and uses hardcoded bucket.
        *   `[âœ…]` 9.b.iv. Create a test case that verifies `assembleTurnPrompt` throws an error when `inputs.header_context_id` is missing or invalid (contribution not found in database). This test must fail because the function currently checks for `header_context_resource_id` instead.
        *   `[âœ…]` 9.b.v. Create a test case that verifies `assembleTurnPrompt` throws an error when the contribution record is missing `storage_bucket`, `storage_path`, or `file_name`. This test must fail initially but should pass after implementation.
    *   `[âœ…]` 9.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts`, update the function to query header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 9.c.i. Remove the precondition check for `payload.header_context_resource_id` (lines 47-51) that throws an error when missing.
        *   `[âœ…]` 9.c.ii. Add a precondition check that verifies `job.payload.inputs` exists and is a record, and that `job.payload.inputs.header_context_id` is a string (the contribution ID).
        *   `[âœ…]` 9.c.iii. Query `dialectic_contributions` by `inputs.header_context_id` to get the contribution record, selecting `storage_bucket`, `storage_path`, `file_name`, and `contribution_type` fields. Verify the contribution exists and has `contribution_type = 'header_context'`.
        *   `[âœ…]` 9.c.iv. Validate that the contribution record has `storage_bucket`, `storage_path`, and `file_name` (all non-null strings). If any are missing, throw an error indicating the contribution is missing storage details.
        *   `[âœ…]` 9.c.v. Construct the full storage path as `${contrib.storage_path}/${contrib.file_name}` (or just `contrib.storage_path` if `file_name` is empty, matching the pattern in `gatherInputsForStage` line 144-146).
        *   `[âœ…]` 9.c.vi. Replace the `downloadFromStorage` call (lines 78-82) to use `contrib.storage_bucket` instead of hardcoded `"SB_CONTENT_STORAGE_BUCKET"`, and use the constructed path instead of `job.payload.header_context_resource_id`.
        *   `[âœ…]` 9.c.vii. Ensure all error messages are updated to reference the contribution ID lookup instead of `header_context_resource_id`.
    *   `[âœ…]` 9.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 9.b and ensure they now pass. Also verify that existing `assembleTurnPrompt` tests still pass (update any tests that mock `header_context_resource_id` to instead mock `inputs.header_context_id` and the database query).
    *   `[âœ…]` 9.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` and resolve any warnings or errors.

*   `[âœ…]` 10. **`[BE]` Fix assembleContinuationPrompt to Query Header Context by Contribution ID Instead of Storage Path**
    *   `[âœ…]` 10.a. `[DEPS]` The `assembleContinuationPrompt` function in `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts` (lines 82-89) optionally uses `payload.header_context_resource_id` (storage path) and hardcodes bucket `"dialectic_project_resources"`. However, planners (e.g., `planPerSourceDocument` in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, line 88) set `inputs[`${doc.contribution_type}_id`] = doc.id`, which for `header_context` creates `inputs.header_context_id` with the contribution ID. Header context is stored as a contribution in `dialectic_contributions` with `contribution_type = 'header_context'`. The `assemblePlannerPrompt` and `assembleSeedPrompt` functions correctly use `gatherInputsForStage` which queries contributions by metadata (stage, iteration, etc.) and gets storage details from the database record, avoiding duplication of storage paths in payloads. The fix requires: (1) updating `assembleContinuationPrompt` to optionally read `inputs.header_context_id` and query the contribution if present, (2) removing the hardcoded bucket usage and storage path requirement, ensuring the function uses the database as the single source of truth for storage details, (3) keeping the optional behavior: if `inputs.header_context_id` is missing, the function should continue without header context (no error thrown).
    *   `[âœ…]` 10.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.test.ts`, write tests that verify `assembleContinuationPrompt` optionally queries header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 10.b.i. Create a test case that mocks a job payload with `inputs.header_context_id` set to a contribution ID, and mocks a database query that returns a contribution record with storage details, and asserts that `assembleContinuationPrompt` successfully queries and downloads the header context using the contribution's bucket and path.
        *   `[âœ…]` 10.b.ii. Create a test case that verifies `assembleContinuationPrompt` works correctly when `inputs.header_context_id` is missing (header context is optional for continuation prompts), and no header context is included in the final prompt. This test should pass initially since the function already handles optional header context (line 82-106).
        *   `[âœ…]` 10.b.iii. Create a test case that verifies `assembleContinuationPrompt` throws an error when `inputs.header_context_id` is provided but the contribution is not found in the database. This test must fail because the function currently uses `header_context_resource_id` directly without querying.
        *   `[âœ…]` 10.b.iv. Create a test case that verifies `assembleContinuationPrompt` uses the contribution's `storage_bucket` instead of hardcoded `"dialectic_project_resources"` when downloading header context. This test must fail because the function currently hardcodes the bucket (line 87).
    *   `[âœ…]` 10.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts`, update the function to optionally query header context by contribution ID from `inputs` instead of using `header_context_resource_id` in payload.
        *   `[âœ…]` 10.c.i. Update the header context fetching logic (lines 82-106) to check for `job.payload.inputs?.header_context_id` instead of `job.payload?.header_context_resource_id`.
        *   `[âœ…]` 10.c.ii. If `inputs.header_context_id` exists and is a string, query `dialectic_contributions` by that ID to get the contribution record with `storage_bucket`, `storage_path`, `file_name`, and `contribution_type` fields. Verify the contribution exists and has `contribution_type = 'header_context'`.
        *   `[âœ…]` 10.c.iii. Validate that the contribution record has `storage_bucket`, `storage_path`, and `file_name` (all non-null strings). If any are missing, throw an error indicating the contribution is missing storage details.
        *   `[âœ…]` 10.c.iv. Construct the full storage path as `${contrib.storage_path}/${contrib.file_name}` (or just `contrib.storage_path` if `file_name` is empty).
        *   `[âœ…]` 10.c.v. Replace the `downloadFromStorage` call (lines 85-89) to use `contrib.storage_bucket` instead of hardcoded `"dialectic_project_resources"`, and use the constructed path instead of `headerResourceId`.
        *   `[âœ…]` 10.c.vi. Ensure all error messages are updated to reference the contribution ID lookup instead of `header_context_resource_id`.
        *   `[âœ…]` 10.c.vii. Keep the optional behavior: if `inputs.header_context_id` is missing or undefined, the function should continue without header context (no error thrown), matching the current optional behavior.
    *   `[âœ…]` 10.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 10.b and ensure they now pass. Also verify that existing `assembleContinuationPrompt` tests still pass (update any tests that mock `header_context_resource_id` to instead mock `inputs.header_context_id` and the database query).
    *   `[âœ…]` 10.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts` and resolve any warnings or errors.

*   `[âœ…]` 11. **`[BE]` Fix planAllToOne to Extract and Validate document_key**
    *   `[âœ…]` 11.a. `[DEPS]` The `planAllToOne` planner function in `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 11.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts`, write tests that verify `planAllToOne` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 11.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'business_case'` and asserts that the created payload has `document_key: 'business_case'`.
        *   `[âœ…]` 11.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property (e.g., only has `header_context_artifact`), and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planAllToOne` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 11.b.v. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key` set to `null` or empty string, and asserts that `planAllToOne` throws an error (step outputs documents but `document_key` is invalid).
        *   `[âœ…]` 11.b.vi. Create a test case that mocks a recipe step with `outputs_required` missing or undefined, and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.vii. These tests must fail because `planAllToOne` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 11.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 11.c.i. Before creating `newPayload` (line 44), check if the step outputs documents: verify that `recipeStep.outputs_required` exists, is an object, has a `documents` property that is an array, and the array has at least one item.
        *   `[âœ…]` 11.c.ii. If the step outputs documents (condition from 11.c.i is true), extract `document_key` from `recipeStep.outputs_required.documents[0].document_key`. If `documents[0]` is missing, not an object, or missing `document_key` property, throw an error: `"planAllToOne requires recipeStep.outputs_required.documents[0].document_key but it is missing"`.
        *   `[âœ…]` 11.c.iii. If the step outputs documents, validate that `document_key` is a non-empty string. If it's null, undefined, empty string, or not a string type, throw an error: `"planAllToOne requires recipeStep.outputs_required.documents[0].document_key to be a non-empty string, but received: ${typeof document_key === 'string' ? `'${document_key}'` : String(document_key)}"`.
        *   `[âœ…]` 11.c.iv. If the step outputs documents, store the validated `document_key` in a variable. If the step does not output documents, leave `document_key` as `undefined`.
        *   `[âœ…]` 11.c.v. Add `document_key` to the `newPayload` object (after line 68, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 11.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 11.b and ensure they now pass. Also verify that existing `planAllToOne` tests still pass.
    *   `[âœ…]` 11.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` and `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 12. **`[BE]` Fix planPairwiseByOrigin to Extract and Validate document_key**
    *   `[âœ…]` 12.a. `[DEPS]` The `planPairwiseByOrigin` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 12.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts`, write tests that verify `planPairwiseByOrigin` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 12.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'pairwise_synthesis_chunk'` and asserts that the created payload has `document_key: 'pairwise_synthesis_chunk'`.
        *   `[âœ…]` 12.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPairwiseByOrigin` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 12.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPairwiseByOrigin` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 12.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPairwiseByOrigin` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 12.b.v. These tests must fail because `planPairwiseByOrigin` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 12.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 12.c.i. Before creating `newPayload` (line 91), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPairwiseByOrigin"` instead of `"planAllToOne"`.
        *   `[âœ…]` 12.c.ii. Add `document_key` to the `newPayload` object (after line 116, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 12.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 12.b and ensure they now pass. Also verify that existing `planPairwiseByOrigin` tests still pass.
    *   `[âœ…]` 12.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 13. **`[BE]` Fix planPerModel to Extract and Validate document_key**
    *   `[âœ…]` 13.a. `[DEPS]` The `planPerModel` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 13.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts`, write tests that verify `planPerModel` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 13.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'synthesis'` and asserts that the created payload has `document_key: 'synthesis'`.
        *   `[âœ…]` 13.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerModel` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 13.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerModel` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 13.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerModel` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 13.b.v. These tests must fail because `planPerModel` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 13.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 13.c.i. Before creating `newPayload` (line 75), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerModel"` instead of `"planAllToOne"`.
        *   `[âœ…]` 13.c.ii. Add `document_key` to the `newPayload` object (after line 98, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 13.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 13.b and ensure they now pass. Also verify that existing `planPerModel` tests still pass.
    *   `[âœ…]` 13.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 14. **`[BE]` Fix planPerSourceDocument to Extract and Validate document_key**
    *   `[âœ…]` 14.a. `[DEPS]` The `planPerSourceDocument` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 14.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts`, write tests that verify `planPerSourceDocument` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 14.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'business_case_critique'` and asserts that the created payload has `document_key: 'business_case_critique'`.
        *   `[âœ…]` 14.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceDocument` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 14.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerSourceDocument` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 14.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceDocument` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 14.b.v. These tests must fail because `planPerSourceDocument` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 14.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 14.c.i. Before creating `newPayload` (line 94), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerSourceDocument"` instead of `"planAllToOne"`.
        *   `[âœ…]` 14.c.ii. Add `document_key` to the `newPayload` object (after line 116, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 14.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 14.b and ensure they now pass. Also verify that existing `planPerSourceDocument` tests still pass.
    *   `[âœ…]` 14.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 15. **`[BE]` Fix planPerSourceDocumentByLineage to Extract and Validate document_key**
    *   `[âœ…]` 15.a. `[DEPS]` The `planPerSourceDocumentByLineage` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 15.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts`, write tests that verify `planPerSourceDocumentByLineage` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 15.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'technical_requirements'` and asserts that the created payload has `document_key: 'technical_requirements'`.
        *   `[âœ…]` 15.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceDocumentByLineage` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 15.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerSourceDocumentByLineage` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 15.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceDocumentByLineage` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 15.b.v. These tests must fail because `planPerSourceDocumentByLineage` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 15.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 15.c.i. Before creating `newPayload` (line 70), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerSourceDocumentByLineage"` instead of `"planAllToOne"`.
        *   `[âœ…]` 15.c.ii. Add `document_key` to the `newPayload` object (after line 99, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 15.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 15.b and ensure they now pass. Also verify that existing `planPerSourceDocumentByLineage` tests still pass.
    *   `[âœ…]` 15.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 16. **`[BE]` Fix planPerSourceGroup to Extract and Validate document_key**
    *   `[âœ…]` 16.a. `[DEPS]` The `planPerSourceGroup` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 16.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts`, write tests that verify `planPerSourceGroup` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 16.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'synthesis'` and asserts that the created payload has `document_key: 'synthesis'`.
        *   `[âœ…]` 16.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceGroup` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 16.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property (e.g., only has `header_context_artifact`), and asserts that `planPerSourceGroup` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 16.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceGroup` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 16.b.v. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key` set to `null` or empty string, and asserts that `planPerSourceGroup` throws an error (step outputs documents but `document_key` is invalid).
        *   `[âœ…]` 16.b.vi. Create a test case that mocks a recipe step with `outputs_required` missing or undefined, and asserts that `planPerSourceGroup` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 16.b.vii. These tests must fail because `planPerSourceGroup` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 16.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 16.c.i. Before creating `newPayload` (line 54), check if the step outputs documents: verify that `recipeStep.outputs_required` exists, is an object, has a `documents` property that is an array, and the array has at least one item.
        *   `[âœ…]` 16.c.ii. If the step outputs documents (condition from 16.c.i is true), extract `document_key` from `recipeStep.outputs_required.documents[0].document_key`. If `documents[0]` is missing, not an object, or missing `document_key` property, throw an error: `"planPerSourceGroup requires recipeStep.outputs_required.documents[0].document_key but it is missing"`.
        *   `[âœ…]` 16.c.iii. If the step outputs documents, validate that `document_key` is a non-empty string. If it's null, undefined, empty string, or not a string type, throw an error: `"planPerSourceGroup requires recipeStep.outputs_required.documents[0].document_key to be a non-empty string, but received: ${typeof document_key === 'string' ? `'${document_key}'` : String(document_key)}"`.
        *   `[âœ…]` 16.c.iv. If the step outputs documents, store the validated `document_key` in a variable. If the step does not output documents, leave `document_key` as `undefined`.
        *   `[âœ…]` 16.c.v. Add `document_key` to the `newPayload` object (after line 80, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 16.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 16.b and ensure they now pass. Also verify that existing `planPerSourceGroup` tests still pass.
    *   `[âœ…]` 16.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 17. **`[TEST-INT]` Fix Integration Test to Verify End-to-End document_key Flow**
    *   `[âœ…]` 17.a. `[DEPS]` After all planners are updated (steps 11-16), write an integration test that verifies the complete end-to-end flow: planners create EXECUTE job payloads with `document_key`, and `assembleTurnPrompt` can successfully process them. The test file `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file should verify this flow.
    *   `[âœ…]` 17.b. `[TEST-INT]` **RED**: In `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file, write a test that verifies EXECUTE jobs created by planners include `document_key` and can be processed by `assembleTurnPrompt`.
        *   `[âœ…]` 17.b.i. Create a test case that sets up a PLAN job, calls a planner function (e.g., `planPerSourceDocument`) with a recipe step that has `outputs_required.documents[0].document_key`, and creates child EXECUTE jobs.
        *   `[âœ…]` 17.b.ii. Assert that the created EXECUTE job payloads have `document_key` set to the expected value from `outputs_required.documents[0].document_key`.
        *   `[âœ…]` 17.b.iii. Mock `assembleTurnPrompt` and verify it receives a payload with `document_key` set correctly, and that it can successfully find the document info in `headerContext.files_to_generate` using that `document_key`.
        *   `[âœ…]` 17.b.iv. This test must fail initially if any planner is missing `document_key`, but should pass after all planners are updated (steps 11-16).
    *   `[âœ…]` 17.c. `[TEST-INT]` **GREEN**: Re-run the test from step 17.b and ensure it now passes. This verifies that the complete end-to-end flow works correctly: planners create payloads with `document_key`, and `assembleTurnPrompt` can process them successfully.
    *   `[âœ…]` 17.d. `[LINT]` Run the linter for the integration test file and resolve any warnings or errors.
    *   `[âœ…]` 17.e. `[CRITERIA]` All six planners (`planAllToOne`, `planPairwiseByOrigin`, `planPerModel`, `planPerSourceDocument`, `planPerSourceDocumentByLineage`, `planPerSourceGroup`) now conditionally extract `document_key` from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents, `document_key` must be extracted and set in the `DialecticExecuteJobPayload`. If the step outputs documents but `document_key` is missing, undefined, null, empty string, or not a string, each planner throws an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing. If the step does not output documents (missing `outputs_required.documents` or empty array), `document_key` is not set in the payload. All unit tests pass, integration tests verify the end-to-end flow works, and `assembleTurnPrompt` can successfully process EXECUTE jobs created by any planner for steps that output documents. Error messages clearly identify which planner failed and why `document_key` is missing.
    *   `[âœ…]` 17.f. `[COMMIT]` Commit message: "fix: add document_key validation to all planner EXECUTE job payloads - Extract document_key from recipeStep.outputs_required.documents[0].document_key - Throw errors immediately if document_key is missing, null, empty, or invalid (fail loud and hard, no fallbacks) - Update all six planners (planAllToOne, planPairwiseByOrigin, planPerModel, planPerSourceDocument, planPerSourceDocumentByLineage, planPerSourceGroup) - Add unit tests for each planner verifying document_key extraction and error handling - Add integration test verifying end-to-end flow with assembleTurnPrompt - Resolves missing document_key error in assembleTurnPrompt"

SessionContributionsDisplayCard should not render a GeneratedContributionsCard for any document that is not highlighted in StageRunChecklist

GeneratedContributionsCard should not render a document for any document that is not highlighted in StageRunChecklist