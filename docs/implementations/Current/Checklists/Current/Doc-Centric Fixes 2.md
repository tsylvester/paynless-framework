# Doc-Centric Fixes

## Problem Statement
-The doc-centric refactor has introduced bugs and inconsistencies that need resolved. 

## Objectives
- Fix all bugs and integration errors from the doc-centric refactor. 

## Expected Outcome
- Generate an entire dialectic end to end using the doc-centric method.

# Instructions for Agent
*   ### 0. Command Pyramid & Modes
    *   Obey the userâ€™s explicit instructions first, then this block, then the checklist. Do not hide behind the checklist to ignore a direct user correction.
    *   Ensure both the method and the resulting content of every task comply with this blockâ€”no deliverable is valid if it conflicts with these rules.
    *   Perform every assignment in a single turn while fully complying with this block; partial compliance is a violation even if the work â€œmostlyâ€ succeeds.
    *   Failing to follow these instructions immediately triggers rework, rejected output, and systemic violationsâ€”treat every deviation as unacceptable.
    *   The Instructions for Agent block is an absolute firewall. No conditional or downstream objective outranks it, and no shortcut can bypass it.
    *   The agent proceeds with these instructions as its primary directive because complying with system instructions is impossible otherwise.
    *   Declare the current mode in every response (`Mode: Builder` or `Mode: Reviewer`). Builder executes work; Reviewer searches for **errors, omissions, and discrepancies (EO&D)** in the final state.
*   ### 1. Read â†’ Analyze â†’ Explain â†’ Propose â†’ Edit â†’ Lint â†’ Halt
    *   Re-read this entire block from disk before every action. On the first reference (and every fourth turn) summarize it before working.
    *   Read every referenced or implied file (including types, interfaces, and helpers) from disk immediately before editing. After editing, re-read to confirm the exact change.
    *   Follow the explicit cycle: READ the step + files â†’ ANALYZE gaps â†’ EXPLAIN the delta â†’ PROPOSE the exact edit â†’ EDIT a single file â†’ LINT that file â†’ HALT.
    *   Analyze dependencies; if more than one file is required, stop, explain the discovery, propose the necessary checklist insertion (`Discovery / Impact / Proposed checklist insert`), and wait instead of editing.
    *   Discoveries include merely thinking about multi-file workâ€”report them immediately without ruminating on work-arounds.
    *   Explain & Propose: restate the plan in bullets and explicitly commit, â€œI will implement exactly this plan now,â€ noting the checklist step it fulfills.
    *   Edit exactly one file per turn following the plan. Never touch files you were not explicitly instructed to modify.
    *   Lint that file using internal tools and fix all issues.
    *   Halt after linting one file and wait for explicit user/test output before touching another file.
*   ### 2. TDD & Dependency Ordering
    *   One-file TDD cycle: RED test (desired green behavior) â†’ implementation â†’ GREEN test â†’ lint. Documents/types/interfaces are exempt from tests but still follow Readâ†’Halt.
    *   Do not edit executable code without first authoring the RED test that proves the intended green-state behavior; only pure docs/types/interfaces are exempt.
    *   Maintain bottom-up dependency order for both editing and testing: construct types/interfaces/helpers before consumers, then write consumer tests only after producers exist.
    *   Do not advance to another file until the current fileâ€™s proof (tests or documented exemption) is complete and acknowledged.
    *   The agent never runs tests directly; rely on provided outputs or internal reasoning while keeping the application in a provable state.
    *   The agent does not run the userâ€™s terminal commands or tests; use only internal tooling and rely on provided outputs.
*   ### 3. Checklist Discipline
    *   Do not edit the checklist (or its statuses) without explicit instruction; when instructed, change only the specified portion using legal-style numbering.
    *   Execute exactly what the active checklist step instructs with no deviation or â€œcreative interpretation.â€
    *   Each numbered checklist step equals one fileâ€™s entire TDD cycle (deps â†’ types â†’ tests â†’ implementation â†’ proof). Preserve existing detail while adding new requirements.
    *   Document every edit within the checklist. If required edits are missing from the plan, explain the discovery, propose the new step, and halt instead of improvising.
    *   Never update the status of any work step (checkboxes or badges) without explicit instruction.
    *   Following a block of related checklist steps that complete a working implementation, include a commit with a proposed commit message. 
*   ### 4. Builder vs Reviewer Modes
    *   **Builder:** follow the Readâ†’â€¦â†’Halt loop precisely. If a deviation, blocker, or new requirement is discoveredâ€”or the current step simply cannot be completed as writtenâ€”explain the problem, propose the required checklist change, and halt immediately.
    *   **Reviewer:** treat prior reasoning as untrusted. Re-read relevant files/tests from scratch and produce a numbered EO&D list referencing files/sections. Ignore checklist status or RED/GREEN history unless it causes a real defect. If no EO&D are found, state â€œNo EO&D detected; residual risks: â€¦â€
*   ### 5. Strict Typing & Object Construction
    *   Use explicit types everywhere. No `any`, `as`, `as const`, inline ad-hoc types, or castsâ€”except for Supabase clients and intentionally malformed objects in error-handling tests (use dedicated helpers and keep typing strict elsewhere). Every object and variable must be typed. 
    *   Always construct full objects that satisfy existing interfaces/tuples from the relevant type file. Compose complex objects from smaller typed components; never rely on defaults, fallbacks, or backfilling to â€œhealâ€ missing data.
    *   Use type guards to prove and narrow types for the compiler when required.
    *   Never import entire libraries with *, never alias imports, never add "type" to type imports. 
    *   A ternary is not a type guard, a ternary is a default value. Default values are prohibited. 
*   ### 6. Plan Fidelity & Shortcut Ban
    *   Once a solution is described, implement exactly that solution and the userâ€™s instruction. Expedient shortcuts are forbidden without explicit approval.
    *   If you realize you deviated, stop, report it, and wait for direction. Repeating corrected violations triggers halt-and-wait immediately.
    *   If your solution to a challenge is "rewrite the entire file", you have made an error. Stop, do not rewrite the file. Explain the problem to the user and await instruction. 
    *   Do not ruminate on how to work around the "only write to one file per turn". If you are even thinking about the need to work around that limit, you have made a discovery. Stop immediately, report the discovery to the user, and await instruction. 
    *   Refactors must preserve all existing functionality unless the user explicitly authorizes removals; log and identifier fidelity is mandatory.
*   ### 7. Dependency Injection & Architecture
    *   Use explicit dependency injection everywhereâ€”pass every dependency with no hidden defaults or optional fallbacks.
    *   Build adapters/interfaces for every function and work bottom-up so dependencies compile before consumers. Preserve existing functionality, identifiers, and logging unless explicitly told otherwise.
    *   When a file exceeds 600 lines, stop and propose a logical refactoring to decompose the file into smaller parts providing clear SOC and DRY. 
*   ### 8. Testing Standards
    *   Tests assert the desired passing state (no RED/GREEN labels) and new tests are added to the end of the file. Each test covers exactly one behavior.
    *   Use real application functions/mocks, strict typing, and Deno std asserts. Tests must call out which production type/helper each mock mirrors so partial objects are not invented.
    *   Integration tests must exercise real code paths; unit tests stay isolated and mock dependencies explicitly. Never change assertions to match broken codeâ€”fix the code instead.
    *   Tests use the same types, objects, structures, and helpers as the real code, never create new fixtures only for tests - a test that relies on imaginary types or fixtures is invalid. 
    *   Prove the functional gap, the implemented fix, and regressions through tests before moving on; never assume success without proof.
*   ### 9. Logging, Defaults, and Error Handling
    *   Do not add or remove logging, defaults, fallbacks, or silent healing unless the user explicitly instructs you to do so.
    *   Adding console logs solely for troubleshooting is exempt from TDD and checklist obligations, but the exemption applies only to the logging statements themselves.
    *   Believe failing tests, linter flags, and user-reported errors literally; fix the stated condition before chasing deeper causes.
    *   If the user flags instruction noncompliance, acknowledge, halt, and wait for explicit directionâ€”do not self-remediate in a way that risks further violations.
*   ### 10. Linting & Proof
    *   After each edit, lint the touched file and resolve every warning/error. Record lint/test evidence in the response (e.g., â€œLint: clean via internal tool; Tests: not run per instructionsâ€).
    *   Evaluate if a linter error can be resolved in-file, or out-of-file. Only resolve in-file linter errors, then report the out-of-file errors and await instruction. 
    *   Testing may produce unresolvable linter errors. Do not silence them with @es flags, create an empty target function, or other work-arounds. The linter error is sometimes itself proof of the RED state of the test. 
    *   Completion proof requires a lint-clean file plus GREEN test evidence (or documented exemption for types/docs).
*   ### 11. Reporting & Traceability
    *   Every response must include: mode declaration, confirmation that this block was re-read, plan bullets (Builder) or EO&D findings (Reviewer), checklist step references, and lint/test evidence.
    *   If tests were not run (per instruction), explicitly state why and list residual risks. If no EO&D are found, state that along with remaining risks.
    *   The agent uses only its own tools and never the userâ€™s terminal.
*   ### 12. Output Constraints
    *   Never output large code blocks (entire files or multi-function dumps) in chat unless the user explicitly requests them.
    *   Never print an entire function and tell the user to paste it in; edit the file directly or provide the minimal diff required.

## Checklist-Specific Editing Rules

*   THE AGENT NEVER TOUCHES THE CHECKLIST UNLESS THEY ARE EXPLICITLY INSTRUCTED TO! 
*   When editing checklists, each numbered step (1, 2, 3, etc.) represents editing ONE FILE with a complete TDD cycle.
*   Sub-steps within each numbered step use legal-style numbering (1.a, 1.b, 1.a.i, 1.a.ii, etc.) for the complete TDD cycle for that file.
*   All changes to a single file are described and performed within that file's numbered step.
*   Types files (interfaces, enums) are exempt from RED/GREEN testing requirements.
*   Each file edit includes: RED test â†’ implementation â†’ GREEN test â†’ optional refactor.
*   Steps are ordered by dependency (lowest dependencies first).
*   Preserve all existing detail and work while adding new requirements.
*   Use proper legal-style nesting for sub-steps within each file edit.
*   NEVER create multiple top-level steps for the same file edit operation.
*   Adding console logs is not required to be detailed in checklist work. 

### Example Checklist

*   `[ ]`   1. **Title** Objective
    *   `[ ]`   1.a. [DEPS] A list explaining dependencies of the function, its signature, and its return shape
        *   `[ ]` 1.a.i. eg. `function(something)` in `file.ts` provides this or that
    *   `[ ]`   1.b. [TYPES] A list strictly typing all the objects used in the function
    *   `[ ]`   1.c. [TEST-UNIT] A list explaining the test cases
        *   `[ ]` 1.c.i. Assert `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [SPACE] A list explaining the implementation requirements
        *   `[ ]` 1.d.i. Implement `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [TEST-UNIT] Rerun and expand test proving the function
        *   `[ ]` 1.d.i. Implement `function(something)` in `file.ts` acts a certain way 
    *   `[ ]`   1.d. [TEST-INT] If there is a chain of functions that work together, prove it
        *   `[ ]` 1.d.i. For every cross-function interaction, assert `thisFunction(something)` in `this_file.ts` acts a certain way towards `thatFunction(other)` in `that_file.ts`
    *   `[ ]`   1.d. [CRITERIA] A list explaining the acceptence criteria to consider the work complete and correct. 
    *   `[ ]`   1.e. [COMMIT] A commit that explains the function and its proofs

*   `[ ]`   2. **Title** Objective
    *   `[ ]`   2.a. [DEPS] Low level providers are always build before high level consumers (DI/DIP)
    *   `[ ]`   2.b. [TYPES] DI/DIP and strict typing ensures unit tests can always run 
    *   `[ ]`   2.c. [TEST-UNIT] All functions matching defined external objects and acting as asserted helps ensure integration tests pass

## Legend - You must use this EXACT format. Do not modify it, adapt it, or "improve" it. The bullets, square braces, ticks, nesting, and numbering are ABSOLUTELY MANDATORY and UNALTERABLE. 

*   `[ ]` 1. Unstarted work step. Each work step will be uniquely named for easy reference. We begin with 1.
    *   `[ ]` 1.a. Work steps will be nested as shown. Substeps use characters, as is typical with legal documents.
        *   `[ ]` 1. a. i. Nesting can be as deep as logically required, using roman numerals, according to standard legal document numbering processes.
*   `[âœ…]` Represents a completed step or nested set.
*   `[ðŸš§]` Represents an incomplete or partially completed step or nested set.
*   `[â¸ï¸]` Represents a paused step where a discovery has been made that requires backtracking or further clarification.
*   `[â“]` Represents an uncertainty that must be resolved before continuing.
*   `[ðŸš«]` Represents a blocked, halted, or stopped step or has an unresolved problem or prior dependency to resolve before continuing.

## Component Types and Labels

*   `[DB]` Database Schema Change (Migration)
*   `[RLS]` Row-Level Security Policy
*   `[BE]` Backend Logic (Edge Function / RLS / Helpers / Seed Data)
*   `[API]` API Client Library (`@paynless/api` - includes interface definition in `interface.ts`, implementation in `adapter.ts`, and mocks in `mocks.ts`)
*   `[STORE]` State Management (`@paynless/store` - includes interface definition, actions, reducers/slices, selectors, and mocks)
*   `[UI]` Frontend Component (e.g., in `apps/web`, following component structure rules)
*   `[CLI]` Command Line Interface component/feature
*   `[IDE]` IDE Plugin component/feature
*   `[TEST-UNIT]` Unit Test Implementation/Update
*   `[TEST-INT]` Integration Test Implementation/Update (API-Backend, Store-Component, RLS)
*   `[TEST-E2E]` End-to-End Test Implementation/Update
*   `[DOCS]` Documentation Update (READMEs, API docs, user guides)
*   `[REFACTOR]` Code Refactoring Step
*   `[PROMPT]` System Prompt Engineering/Management
*   `[CONFIG]` Configuration changes (e.g., environment variables, service configurations)
*   `[COMMIT]` Checkpoint for Git Commit (aligns with "feat:", "test:", "fix:", "docs:", "refactor:" conventions)
*   `[DEPLOY]` Checkpoint for Deployment consideration after a major phase or feature set is complete and tested.

# Work Breakdown Structure

*   `[âœ…]` 1. **`[DB]` Fix Job Queue Continuation When First Step Completes**
    *   `[âœ…]` 1.a. `[DEPS]` After reviewing the recipe stage migration files (`*_stage.sql`) and the codebase, the complete list of job statuses that require worker invocation is: `pending` (new jobs, handled by `on_new_job_created` trigger on INSERT), `pending_next_step` (PLAN jobs ready for next recipe step after children complete, MISSING trigger), `pending_continuation` (continuation jobs created by `continueJob` function, MISSING trigger), and `retrying` (jobs being retried, handled by `on_job_retrying` trigger). Statuses that do NOT need worker invocation are: `processing` (worker already owns the job), `waiting_for_children` (internal state set by `processComplexJob`), `waiting_for_prerequisite` (internal state set by prerequisite logic), and terminal states (`completed`, `failed`, `retry_loop_failed`). The database trigger `handle_job_completion()` in `supabase/migrations/20251119160820_retrying_trigger.sql` correctly sets PLAN job status to `pending_next_step` when all child EXECUTE jobs complete (lines 234-236), and also sets jobs to `pending` when prerequisites complete (line 181). The `continueJob` function in `supabase/functions/dialectic-worker/continueJob.ts` sets jobs to `pending_continuation` (line 198). However, there is no trigger configured to invoke the `dialectic-worker` Edge Function when a job's status changes to `pending_next_step` or `pending_continuation`. The worker endpoint (`supabase/functions/dialectic-worker/index.ts`) is invoked via POST request with a job record in the request body (it does not fetch jobs itself), so it must be triggered by a database webhook when the status changes. Currently, there is a generic `invoke_dialectic_worker()` function (defined in `supabase/migrations/20250922165259_document_centric_generation.sql`, lines 59-143) that handles HTTP invocation logic, and it is used by the `on_new_job_created` trigger (fires on INSERT). There is also a separate `handle_job_retrying()` function and `on_job_retrying` trigger (lines 5-137 in `20251119160820_retrying_trigger.sql`) that specifically handle `retrying` status. Rather than creating separate triggers for each status, a better architectural approach is to create a single, generic trigger that fires on status changes and invokes the worker for any status that requires processing. The `processComplexJob` function in `supabase/functions/dialectic-worker/processComplexJob.ts` already handles `pending_next_step` status correctly (it processes ready steps when called), but the worker is never invoked when the status changes to `pending_next_step`, leaving PLAN jobs stuck in that state.
    *   `[âœ…]` 1.b. `[DOCS]` **TRIGGER AUDIT**: Document all current triggers on `dialectic_generation_jobs` table and identify competing/deprecated triggers. Current active triggers: (1) `on_new_job_created` (from `20250722033928_fix_job_trigger.sql`) - fires `AFTER INSERT`, calls `invoke_dialectic_worker()`, handles new jobs; (2) `on_job_retrying` (from `20251119160820_retrying_trigger.sql`) - fires `AFTER UPDATE OF status` when `status = 'retrying'`, calls `handle_job_retrying()`, handles retry logic and retry limit checking before invoking worker; (3) `trigger_handle_job_completion_on_update` (from `20250725182218_prerequisite_job_id.sql`) - fires `AFTER UPDATE OF status`, calls `handle_job_completion()`, handles parent/child dependencies and prerequisite logic; (4) `trigger_handle_job_completion_on_insert` (from `20250725182218_prerequisite_job_id.sql`) - fires `AFTER INSERT`, calls `handle_job_completion()`, handles parent/child dependencies on insert. Potentially deprecated: `on_job_terminal_state` (from `20250711205050_create_job_completion_trigger.sql`, line 150 drops it, replaced by `trigger_handle_job_completion_on_update`). The new generic trigger will replace `on_job_retrying` and may overlap with `on_new_job_created` for UPDATE operations (though `on_new_job_created` only fires on INSERT, so no conflict). Document that `handle_job_retrying()` contains special retry limit checking logic (checks if `attempt_count >= (max_retries + 1)` and marks job as `retry_loop_failed`) that must be preserved in the generic trigger or moved to a separate function.
    *   `[âœ…]` 1.c. `[TEST-INT]` **RED**: In `supabase/integration_tests/triggers/invoke_worker_on_status_change.trigger.test.ts`, write integration tests that prove the generic trigger preserves all existing `handle_job_retrying()` logic and provides new logic for missing state transitions.
        *   `[âœ…]` 1.c.i. Create a test file following the pattern of `handle_job_completion.trigger.test.ts` that sets up test database state (admin client, test user, project, session, stage).
        *   `[âœ…]` 1.c.ii. Write a test case that proves `pending_next_step` status DOES invoke worker (status updates to `pending_next_step` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no trigger for `pending_next_step`.
        *   `[âœ…]` 1.c.iii. Write a test case that proves `pending_continuation` status DOES invoke worker (status updates to `pending_continuation` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no trigger for `pending_continuation`.
        *   `[âœ…]` 1.c.iv. Write a test case that proves `pending` status set via UPDATE (when prerequisites complete) DOES invoke worker (status updates from `waiting_for_prerequisite` to `pending` and creates log entry in `dialectic_trigger_logs` indicating HTTP invocation attempt). This test must fail because there is currently no UPDATE trigger for `pending` status.
        *   `[âœ…]` 1.c.v. Write a test case that proves `retrying` status with `attempt_count >= (max_retries + 1)` marks job as `retry_loop_failed` and does NOT invoke worker. This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.vi. Write a test case that proves `retrying` status with `attempt_count < (max_retries + 1)` invokes worker (creates log entry in `dialectic_trigger_logs`). This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.vii. Write a test case that proves test jobs (`is_test_job = true`) with `retrying` status do NOT invoke worker (creates log entry indicating test job skip, but no HTTP invocation attempt). This test should pass initially (existing `on_job_retrying` trigger handles this), but must continue to pass after the generic trigger replaces it.
        *   `[âœ…]` 1.c.viii. Write a test case that proves status changes that do NOT require worker invocation (`processing`, `waiting_for_children`, `waiting_for_prerequisite`, `completed`, `failed`, `retry_loop_failed`) do NOT invoke worker. This test should pass initially and must continue to pass after the generic trigger is implemented.
        *   `[âœ…]` 1.c.ix. Write a test case that proves status updates where `OLD.status = NEW.status` do NOT invoke worker (no status change). This test must pass after the generic trigger is implemented.
    *   `[âœ…]` 1.d. `[DB]` **GREEN**: In `supabase/migrations/20251119160820_retrying_trigger.sql`, create a generic trigger that invokes the worker when job status changes to any status that requires processing.
        *   `[âœ…]` 1.d.i. Create or update a generic trigger function `invoke_worker_on_status_change()` that: (1) checks if the new status is one that requires worker invocation (`pending`, `pending_next_step`, `pending_continuation`, `retrying`), (2) only processes when status actually changes (not on every update: `OLD.status IS NULL OR OLD.status != NEW.status`), (3) skips test jobs (`COALESCE(NEW.is_test_job, false)`), (4) handles special retry limit checking for `retrying` status (if `attempt_count >= (max_retries + 1)`, mark job as `retry_loop_failed` and return early), (5) reuses the existing `invoke_dialectic_worker()` function's logic for determining worker URL (from vault secrets or local dev URL), extracting `user_jwt` from payload, building request body with job record, and invoking via `net.http_post()` using `pg_net` extension, (6) logs the invocation attempt to `dialectic_trigger_logs` table. Alternatively, update the existing `invoke_dialectic_worker()` function to accept both INSERT and UPDATE operations, and add status-checking logic to filter statuses that require invocation.
        *   `[âœ…]` 1.d.ii. Create a new trigger `on_job_status_change` that: (1) fires `AFTER UPDATE OF status`, (2) executes for each row where `NEW.status IN ('pending', 'pending_next_step', 'pending_continuation', 'retrying') AND (OLD.status IS NULL OR OLD.status != NEW.status)`, (3) calls the generic trigger function. This replaces the need for separate triggers for each status.
        *   `[âœ…]` 1.d.iii. **DEPRECATE**: Drop the `on_job_retrying` trigger and deprecate the `handle_job_retrying()` function (or keep it as a helper if retry limit checking is extracted). Add comments explaining that this generic trigger invokes the worker for any status change that requires processing, including PLAN jobs reaching `pending_next_step` status after all child jobs complete (set by `handle_job_completion` trigger), continuation jobs reaching `pending_continuation` status (set by `continueJob` function), jobs being retried (set by `retryJob` function), and jobs set to `pending` when prerequisites complete (set by `handle_job_completion` trigger). Note that `on_new_job_created` trigger remains active for handling INSERT operations, as it fires on a different event type and does not conflict with the UPDATE-based generic trigger.
    *   `[âœ…]` 1.e. `[TEST-INT]` **GREEN**: Re-run all tests from step 1.c and ensure they now pass. The tests from 1.c.ii, 1.c.iii, and 1.c.iv should now pass because the generic trigger handles these status transitions. The tests from 1.c.v, 1.c.vi, and 1.c.vii should continue to pass, proving that all existing `handle_job_retrying()` logic is preserved.

*   `[ ]` 2. **`[STORE]` Fix StageTabCard to Use Valid Document Artifacts Only for Completion Check**
    *   `[ ]` 2.a. `[DEPS]` The `selectStageProgressSummary` selector in `packages/store/src/dialecticStore.selectors.ts` (lines 661-733) counts ALL entries in `progress.documents`, including non-document artifacts like `header_context` (which has `artifact_class: 'header_context'` and `file_type: 'json'`). This causes `StageTabCard` to display incorrect counts like "Completed 1/1 documents" when only a `header_context` artifact exists, while `StageRunChecklist` correctly shows "0 of 4 documents" because it uses `selectValidMarkdownDocumentKeys` (lines 1014-1045) which filters out non-markdown artifacts. The `selectValidMarkdownDocumentKeys` selector uses `extractMarkdownDocumentKeysFromRule` (lines 933-1000) to identify valid markdown document keys from recipe steps' `outputs_required` fields, filtering based on `file_type === 'markdown'` or markdown template filenames, and excludes `header_context` artifacts. `StageTabCard` only needs `isComplete` to determine if the SubmitResponses button should be active (it doesn't need to display counts - that's handled by `StageRunChecklist`). The fix requires: (1) modifying `selectStageProgressSummary` to filter document keys using `selectValidMarkdownDocumentKeys` before counting, (2) removing the document count display from `StageTabCard` (lines 116-136 in `apps/web/src/components/dialectic/StageTabCard.tsx`), keeping only the `isComplete` check (line 121) for button activation.
    *   `[ ]` 2.b. `[TEST-UNIT]` **RED**: In `packages/store/src/dialecticStore.selectors.test.ts`, write a new test for `selectStageProgressSummary` that verifies it excludes non-document artifacts from counts.
        *   `[ ]` 2.b.i. Create a test case that sets up `stageRunProgress` state with both valid markdown document keys (e.g., `'draft_document_markdown'`) and non-document artifacts (e.g., `'HeaderContext'` with `artifact_class: 'header_context'`).
        *   `[ ]` 2.b.ii. Mock `selectValidMarkdownDocumentKeys` to return a Set containing only the valid markdown document keys (excluding `header_context`).
        *   `[ ]` 2.b.iii. Call `selectStageProgressSummary` with the test state and assert that `totalDocuments` and `completedDocuments` only count valid markdown documents, not `header_context` artifacts.
        *   `[ ]` 2.b.iv. Assert that `isComplete` is `false` when only `header_context` is completed but markdown documents are not, and `true` only when all valid markdown documents are completed. This test must fail because `selectStageProgressSummary` currently counts all entries in `progress.documents`.
    *   `[ ]` 2.c. `[STORE]` **GREEN**: In `packages/store/src/dialecticStore.selectors.ts`, modify `selectStageProgressSummary` (lines 661-733) to filter document keys using `selectValidMarkdownDocumentKeys` before counting.
        *   `[ ]` 2.c.i. Add `selectValidMarkdownDocumentKeys` as a dependency parameter to the selector (or use it within the selector function). The selector function signature is `(state: DialecticStateValues, sessionId: string, stageSlug: string, iterationNumber: number, modelId?: string)`, so we need to pass `stageSlug` to `selectValidMarkdownDocumentKeys(state, stageSlug)`.
        *   `[ ]` 2.c.ii. After getting `documentEntries` from `progress.documents` (line 689) and filtering by `modelId` (lines 691-695), filter the resulting `documentKeys` array to only include keys that exist in the Set returned by `selectValidMarkdownDocumentKeys(state, stageSlug)`.
        *   `[ ]` 2.c.iii. Use the filtered `documentKeys` array for all subsequent counting logic (lines 697-716) instead of the unfiltered array.
        *   `[ ]` 2.c.iv. Ensure the return type and values remain unchanged (the filtering only affects which documents are counted).
    *   `[ ]` 2.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 2.b and ensure it now passes. Also verify that existing tests for `selectStageProgressSummary` still pass.
    *   `[ ]` 2.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/StageTabCard.test.tsx`, write a test that verifies `StageTabCard` does not display document counts.
        *   `[ ]` 2.e.i. Render `StageTabCard` with mock store state that includes stage progress with valid documents.
        *   `[ ]` 2.e.ii. Assert that the document count display (the element with `data-testid={`stage-progress-count-${stage.slug}`}`) is NOT rendered (or does not contain count text).
        *   `[ ]` 2.e.iii. Assert that `isComplete` check (the element with `data-testid={`stage-progress-label-${stage.slug}`}`) is still rendered when `isComplete` is `true`. This test must fail because `StageTabCard` currently displays counts.
    *   `[ ]` 2.f. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/StageTabCard.tsx`, remove the document count display while keeping the completion check for button activation.
        *   `[ ]` 2.f.i. Remove the document count display div (lines 116-136) that shows `${progress.completedDocuments} / ${progress.totalDocuments} documents` (line 133).
        *   `[ ]` 2.f.ii. Keep the `isComplete` check (lines 121-128) that displays "Completed" label when `progress.isComplete` is `true`, as this is needed for visual feedback and may be used for the SubmitResponses button activation logic.
        *   `[ ]` 2.f.iii. Update the `hasDocuments` check (line 80) if needed - it currently checks `progress.totalDocuments > 0`, which should still work correctly after the selector fix (it will now reflect valid documents only). Alternatively, check `progress.isComplete` directly if that's the only requirement.
        *   `[ ]` 2.f.iv. Update any TypeScript types or interfaces if the `StageProgressSnapshotSummary` interface (lines 19-23) needs modification (it may not need changes if the selector still returns the same structure, just with filtered counts).
    *   `[ ]` 2.g. `[TEST-UNIT]` **GREEN**: Re-run the test from step 2.e and ensure it now passes. Also verify that existing `StageTabCard` tests still pass.
    *   `[ ]` 2.h. `[LINT]` Run the linter for all modified files (`packages/store/src/dialecticStore.selectors.ts`, `apps/web/src/components/dialectic/StageTabCard.tsx`) and resolve any warnings or errors.

*   `[ ]` 3. **`[UI]` Remove Document Progress Display from SessionContributionsDisplayCard**
    *   `[ ]` 3.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` is a container component whose responsibility is to contain child components that display document information, not to display document progress itself. Currently, it displays progress summary "Completed X of Y documents" (lines 474-484) using `selectStageProgressSummary`, which is incorrect because: (1) Displaying document progress is not the container's job - that responsibility belongs to child components like `StageRunChecklist` which already correctly displays progress counts; (2) The progress summary display includes non-document artifacts like `header_context` (which will be fixed by item 2's changes to `selectStageProgressSummary`, but the container shouldn't be displaying progress at all); (3) The container should only use `stageProgressSummary?.isComplete` (line 231) for button activation logic (`canSubmitStageResponses`), not for displaying progress counts. The container correctly uses `isComplete` for button activation (line 390) and `hasFailed` for error display (lines 282-293, 516-540), which are valid container responsibilities (managing UI state and error handling). The fix requires: (1) removing the progress summary display (lines 474-484) that shows "Completed X of Y documents", (2) keeping the `isComplete` check (line 231) for button activation logic, (3) keeping the `hasFailed` check (lines 282-293) for error display if needed, or verifying if error display should also be delegated to child components.
    *   `[ ]` 3.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx` (or create if it doesn't exist), write a test that verifies the component does not display document progress summary.
        *   `[ ]` 3.b.i. Render `SessionContributionsDisplayCard` with mock store state that includes `stageProgressSummary` with `completedDocuments`, `totalDocuments`, and `outstandingDocuments` properties.
        *   `[ ]` 3.b.ii. Assert that the progress summary display (the element containing "Completed X of Y documents" text, or the div at lines 474-484) is NOT rendered (or does not contain progress count text).
        *   `[ ]` 3.b.iii. Assert that the `canSubmitStageResponses` logic still works correctly (the submit button is enabled when `isComplete` is `true` and disabled when `isComplete` is `false`). This test must fail because `SessionContributionsDisplayCard` currently displays progress counts.
    *   `[ ]` 3.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, remove the document progress summary display while keeping the completion check for button activation.
        *   `[ ]` 3.c.i. Remove the progress summary display div (lines 474-484) that shows "Completed {stageProgressSummary.completedDocuments} of {stageProgressSummary.totalDocuments} documents" and "Outstanding: ..." text.
        *   `[ ]` 3.c.ii. Keep the `stageProgressSummary` selector usage (lines 218-229) because it's still needed for `isComplete` check (line 231) and `hasFailed` check (lines 282-283) for button activation and error handling logic.
        *   `[ ]` 3.c.iii. Ensure the `canSubmitStageResponses` logic (line 231) still works correctly - it uses `stageProgressSummary?.isComplete === true` which is valid container responsibility (button activation logic).
        *   `[ ]` 3.c.iv. Verify that error display logic (lines 282-293, 516-540) using `stageProgressSummary?.hasFailed` and `failedDocumentKeys` still works if needed, or consider if error display should also be delegated to child components. For now, keep it since error handling is a valid container responsibility.
    *   `[ ]` 3.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 3.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify button activation logic using `isComplete`).
    *   `[ ]` 3.e. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[ ]` 4. **`[UI]` Fix GeneratedContributionCard to Exclude Non-Document Artifacts from Status Display**
    *   `[ ]` 4.a. `[DEPS]` The `GeneratedContributionCard` component in `apps/web/src/components/dialectic/GeneratedContributionCard.tsx` correctly filters out non-document artifacts when rendering document content (lines 136-141 use `selectValidMarkdownDocumentKeys` to check `isValidMarkdownDocument`, and lines 345-468 only render document content when `focusedDocument && isValidMarkdownDocument` is true). However, it still displays the status badge for ALL focused documents, including non-document artifacts like `header_context` (lines 330-334). The `documentDescriptor` is retrieved from `stageRunProgress.documents?.[focusedDocument.documentKey]` (lines 193-196), which includes ALL entries in `progress.documents`, including `header_context` artifacts. The status badge should only be shown for valid markdown documents. Additionally, `StageRunChecklist` (used at line 339) should already filter out non-markdown documents after item 3's fix to `selectStageDocumentChecklist`, but we need to ensure `GeneratedContributionCard` doesn't show status for non-document artifacts even if they somehow become focused. The fix requires: (1) modifying the status badge display (lines 330-334) to only show when `isValidMarkdownDocument` is true, ensuring non-document artifacts like `header_context` don't show completion status even if they become focused.
    *   `[ ]` 4.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/GeneratedContributionCard.test.tsx`, write a test that verifies the component does not display status badge for non-document artifacts.
        *   `[ ]` 4.b.i. Render `GeneratedContributionCard` with mock store state where `focusedDocument` has a `documentKey` that is NOT in `validMarkdownDocumentKeys` (e.g., `'HeaderContext'` with `artifact_class: 'header_context'`).
        *   `[ ]` 4.b.ii. Mock `stageRunProgress` to include a `header_context` entry with status `'completed'` in `documents` map.
        *   `[ ]` 4.b.iii. Assert that the status badge (the element with `Badge` variant="secondary" containing status text, or the element at lines 330-334) is NOT rendered when `isValidMarkdownDocument` is `false`. This test must fail because `GeneratedContributionCard` currently shows status badge for all focused documents regardless of whether they are valid markdown documents.
    *   `[ ]` 4.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/GeneratedContributionCard.tsx`, modify the status badge display to only show for valid markdown documents.
        *   `[ ]` 4.c.i. Update the status badge condition (line 330) from `{documentDescriptor && (` to `{documentDescriptor && isValidMarkdownDocument && (` to ensure the badge is only shown when the focused document is a valid markdown document.
        *   `[ ]` 4.c.ii. Ensure the `isValidMarkdownDocument` check (lines 136-141) still works correctly - it uses `selectValidMarkdownDocumentKeys(state, stageSlug)` (lines 129-134) to filter out non-markdown artifacts like `header_context`.
        *   `[ ]` 4.c.iii. Verify that document content rendering logic (lines 345-468) already correctly filters using `isValidMarkdownDocument` - no changes needed here as it already has the correct check.
        *   `[ ]` 4.c.iv. Ensure that `StageRunChecklist` component (line 339) will correctly filter non-markdown documents after item 3's fix to `selectStageDocumentChecklist`, but this fix ensures `GeneratedContributionCard` doesn't show status even if a non-document artifact somehow becomes focused.
    *   `[ ]` 4.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 4.b and ensure it now passes. Also verify that existing `GeneratedContributionCard` tests still pass (especially tests that verify status badge displays correctly for valid markdown documents).
    *   `[ ]` 4.e. `[LINT]` Run the linter for `apps/web/src/components/dialectic/GeneratedContributionCard.tsx` and resolve any warnings or errors.

*   `[ ]` 5. **`[UI]` Change Submit Responses Button to Detect Last Stage and Disable Itself with a "Project Complete" Notice**
    *   `[ ]` 5.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` uses a Submit Responses button (`renderSubmitButton()` at lines 387-401) that enables when `canSubmitStageResponses` is `true` (based on `stageProgressSummary?.isComplete` at line 231). The button currently always allows submission and advancement to the next stage when enabled, but should be disabled with a "Project Complete" notice when the user is in the last stage of the dialectic process. The component already has access to `sortedStages` via `selectSortedStages` (line 110) and `processTemplate` via the store (lines 107-109). The `activeStage` is computed from `processTemplate` (lines 117-119). To detect the last stage, we can check if `activeStage.slug` matches the last stage in `sortedStages` array (similar to how `SessionInfoCard` detects `isFinalStageInProcess` at lines 83-87, which checks if there are no transitions where the current stage is the source). Alternatively, we can check if `activeStage.slug === sortedStages[sortedStages.length - 1]?.slug`. The fix requires: (1) adding a `useMemo` hook to compute `isLastStage` based on `sortedStages` and `activeStage`, (2) modifying the button to be disabled when `isLastStage` is `true`, (3) displaying a "Project Complete" notice when `isLastStage` is `true` and `canSubmitStageResponses` is `true` (indicating all documents are complete), (4) ensuring the button text or notice clearly indicates that the project is complete and no further stages are available.
    *   `[ ]` 5.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the Submit Responses button is disabled when in the last stage.
        *   `[ ]` 5.b.i. Create a test case that mocks store state with `sortedStages` containing multiple stages (e.g., `['thesis', 'antithesis', 'synthesis']`) and sets `activeStageSlug` to the last stage (`'synthesis'`).
        *   `[ ]` 5.b.ii. Mock `stageProgressSummary` to have `isComplete: true` (so `canSubmitStageResponses` would normally be `true`).
        *   `[ ]` 5.b.iii. Render `SessionContributionsDisplayCard` and assert that the Submit Responses button (the element with text "Submit Responses & Advance Stage" or `data-testid` if available) is disabled when in the last stage, even if `canSubmitStageResponses` is `true`.
        *   `[ ]` 5.b.iv. Assert that a "Project Complete" notice is displayed when in the last stage and all documents are complete. This test must fail because the button currently doesn't check for last stage.
    *   `[ ]` 5.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, add last stage detection and modify the button to be disabled with a notice when in the last stage.
        *   `[ ]` 5.c.i. Add a `useMemo` hook (after line 231) to compute `isLastStage` by checking if `activeStage?.slug === sortedStages[sortedStages.length - 1]?.slug`. Handle the case where `sortedStages` is empty or `activeStage` is null (return `false`).
        *   `[ ]` 5.c.ii. Modify `renderSubmitButton()` (lines 387-401) to disable the button when `isLastStage` is `true` by adding `|| isLastStage` to the `disabled` condition (line 390), or create a new computed value `isButtonDisabled = isSubmitting || !canSubmitStageResponses || isLastStage`.
        *   `[ ]` 5.c.iii. Add a conditional render after `renderSubmitButton()` (or modify the button section) that displays a "Project Complete" notice when `isLastStage && canSubmitStageResponses` is `true`. The notice should be a non-interactive element (e.g., a `Badge`, `Alert`, or styled `div`) with text like "Project Complete - All stages finished" or similar, styled appropriately to indicate completion.
        *   `[ ]` 5.c.iv. Ensure the button text remains "Submit Responses & Advance Stage" (line 398) - the button should just be disabled in the last stage, not change its text. The notice should be separate from the button.
        *   `[ ]` 5.c.v. Handle edge cases: if `sortedStages` is empty, `isLastStage` should be `false`. If `activeStage` is null, `isLastStage` should be `false`. If there's only one stage, it should be considered the last stage.
    *   `[ ]` 5.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 5.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify button enabling/disabling based on `canSubmitStageResponses`).
    *   `[ ]` 5.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the button still works correctly for non-last stages.
        *   `[ ]` 5.e.i. Create a test case that mocks store state with `sortedStages` containing multiple stages and sets `activeStageSlug` to a non-last stage (e.g., `'thesis'` when stages are `['thesis', 'antithesis', 'synthesis']`).
        *   `[ ]` 5.e.ii. Mock `stageProgressSummary` to have `isComplete: true` and assert that the Submit Responses button is enabled (not disabled) when not in the last stage.
        *   `[ ]` 5.e.iii. Assert that the "Project Complete" notice is NOT displayed when not in the last stage. This test should pass immediately after step 5.c if implemented correctly.
    *   `[ ]` 5.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 5.e and ensure it passes. This verifies that the fix doesn't break normal button behavior for non-last stages.
    *   `[ ]` 5.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[ ]` 6. **`[UI]` Remove Conditional "Export Final" Button from SessionInfoCard**
    *   `[ ]` 6.a. `[DEPS]` The `SessionInfoCard` component in `apps/web/src/components/dialectic/SessionInfoCard.tsx` displays a conditional "Export Final" button (lines 287-297) that appears when `isFinalStageInProcess` is `true`. However, there is now an always-visible "Export" button (lines 247-257) that provides the same functionality, making the conditional "Export Final" button redundant and deprecated. The `isFinalStageInProcess` logic (lines 83-87) is computed based on process template transitions and is currently used in two places: (1) to hide the Submit button in the final stage (line 261: `!isFinalStageInProcess`), and (2) to show the conditional "Export Final" button (line 288: `isFinalStageInProcess && project &&`). The fix requires: (1) removing the conditional "Export Final" button (lines 287-297), (2) keeping the `isFinalStageInProcess` logic since it's still needed to hide the Submit button in the final stage (line 261), (3) removing the comment "Final stage export button" (line 287) as it's no longer relevant. The always-visible "Export" button (lines 247-257) provides the export functionality for all stages, eliminating the need for the conditional button.
    *   `[ ]` 6.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionInfoCard.test.tsx`, write a test that verifies the "Export Final" button is never displayed.
        *   `[ ]` 6.b.i. Create a test case that mocks store state with `isFinalStageInProcess` set to `true` (by setting up a project with process template transitions where the current stage has no outgoing transitions).
        *   `[ ]` 6.b.ii. Mock `project` to be non-null and render `SessionInfoCard`.
        *   `[ ]` 6.b.iii. Assert that the "Export Final" button (the element with text "Export Final" or `data-testid` if available) is NOT rendered, even when `isFinalStageInProcess` is `true`.
        *   `[ ]` 6.b.iv. Assert that the always-visible "Export" button (lines 247-257) is still rendered. This test must fail because the conditional "Export Final" button currently displays when `isFinalStageInProcess` is `true`.
    *   `[ ]` 6.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionInfoCard.tsx`, remove the conditional "Export Final" button while keeping the Submit button hiding logic.
        *   `[ ]` 6.c.i. Remove the conditional "Export Final" button block (lines 287-297), including the comment "Final stage export button" (line 287), the conditional check `{isFinalStageInProcess && project && (`, the `ExportProjectButton` component with "Export Final" text, and the closing `)}`.
        *   `[ ]` 6.c.ii. Keep the `isFinalStageInProcess` computation (lines 83-87) since it's still needed to hide the Submit button in the final stage (line 261: `!isFinalStageInProcess`). Do not remove this logic.
        *   `[ ]` 6.c.iii. Verify that the always-visible "Export" button (lines 247-257) remains unchanged and continues to provide export functionality for all stages.
        *   `[ ]` 6.c.iv. Ensure the Submit button hiding logic (lines 259-285) still works correctly - it should hide the Submit button when `isFinalStageInProcess` is `true`, which is the correct behavior since users shouldn't submit to advance when already in the final stage.
    *   `[ ]` 6.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 6.b and ensure it now passes. Also verify that existing `SessionInfoCard` tests still pass (especially tests that verify the always-visible "Export" button and the Submit button hiding logic).
    *   `[ ]` 6.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionInfoCard.test.tsx`, write a test that verifies the always-visible "Export" button is still rendered in all stages.
        *   `[ ]` 6.e.i. Create test cases for both final and non-final stages (by setting up projects with different process template transition configurations).
        *   `[ ]` 6.e.ii. Assert that the always-visible "Export" button (lines 247-257) is rendered regardless of whether `isFinalStageInProcess` is `true` or `false`. This test should pass immediately after step 6.c if the always-visible button was not modified.
    *   `[ ]` 6.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 6.e and ensure it passes. This verifies that the always-visible "Export" button continues to work correctly for all stages.
    *   `[ ]` 6.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionInfoCard.tsx` and resolve any warnings or errors.

*   `[ ]` 7. **`[UI]` Fix SessionContributionsDisplayCard to Hide Loader Until Generation Starts**
    *   `[ ]` 7.a. `[DEPS]` The `SessionContributionsDisplayCard` component in `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` displays a "Generating documents" loader (lines 501-515) when `isGenerating` is `true`. The `isGenerating` logic (lines 295-298) checks `contributionGenerationStatus === 'generating'`, which is a global state that can be `'generating'` even when: (1) no models are selected for the current session (`selectedModelIds` might be empty), (2) the Generate button hasn't been clicked (the status might persist from a previous session or stage), (3) a different session is generating (the global status applies to all sessions). The `contributionGenerationStatus` is set to `'generating'` when `generateContributions` is called (line 1696 in `dialecticStore.ts`) and is reset to `'idle'` only when all sessions finish generating (lines 1393-1394, 1577, 1673 in `dialecticStore.ts`). However, there is a more precise per-session state `generatingSessions` (a map of `{ [sessionId]: string[] }` containing job IDs) and a selector `selectGeneratingSessionsForSession` (lines 196-198 in `dialecticStore.ts`) that returns active job IDs for a specific session. The `SessionInfoCard` component correctly uses this per-session check (lines 66-69) via `selectGeneratingSessionsForSession(state, session.id)` to determine if generation is active. The fix requires: (1) replacing the global `contributionGenerationStatus === 'generating'` check in `isGenerating` (line 296) with a per-session check using `selectGeneratingSessionsForSession(state, session.id)` to ensure the loader only shows when the current session has active generation jobs, (2) optionally checking `selectedModelIds.length > 0` to ensure models are selected, (3) ensuring the loader display logic (lines 501-515) correctly reflects the session-specific generation state.
    *   `[ ]` 7.b. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the loader does not display when the current session is not generating.
        *   `[ ]` 7.b.i. Create a test case that mocks store state where `contributionGenerationStatus` is `'generating'` but `generatingSessions[activeSessionId]` is empty or undefined (simulating a different session generating).
        *   `[ ]` 7.b.ii. Mock `selectedModelIds` to be empty (no models selected).
        *   `[ ]` 7.b.iii. Render `SessionContributionsDisplayCard` with the test state and assert that the "Generating documents" loader (the element with text "Generating documents" or `data-testid` if available) is NOT displayed when the current session has no active generation jobs.
        *   `[ ]` 7.b.iv. Assert that the loader is NOT displayed when `selectedModelIds` is empty, even if `contributionGenerationStatus` is `'generating'`. This test must fail because the component currently uses the global `contributionGenerationStatus` which can be `'generating'` even when the current session isn't generating.
    *   `[ ]` 7.c. `[UI]` **GREEN**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx`, replace the global generation status check with a per-session check.
        *   `[ ]` 7.c.i. Import `selectGeneratingSessionsForSession` from `@paynless/store` if not already imported (add to imports at top of file).
        *   `[ ]` 7.c.ii. Add a new `useDialecticStore` hook (after line 143) to get `generatingJobs` for the current session: `const generatingJobs = useDialecticStore((state) => session ? selectGeneratingSessionsForSession(state, session.id) : []);`. This uses the same pattern as `SessionInfoCard` (lines 66-68).
        *   `[ ]` 7.c.iii. Optionally add a check for `selectedModelIds` (the component already accesses `selectedModelIds` indirectly via `documentsByModel`, but we can add an explicit check if needed). Alternatively, check `selectedModelIds.length > 0` in the `isGenerating` logic.
        *   `[ ]` 7.c.iv. Modify `isGenerating` (lines 295-298) to check `generatingJobs.length > 0` instead of (or in addition to) `contributionGenerationStatus === 'generating'`. The new logic should be: `const isGenerating = generatingJobs.length > 0 && failedDocumentKeys.length === 0 && !generationError;`. This ensures the loader only shows when the current session has active generation jobs.
        *   `[ ]` 7.c.v. Remove or keep the `contributionGenerationStatus` selector usage (line 141-143) - it may still be used elsewhere or can be removed if not needed. However, since we're replacing it with `generatingJobs`, we can keep it for now if other code depends on it, or remove it if it's only used for `isGenerating`.
        *   `[ ]` 7.c.vi. Ensure the loader display logic (lines 501-515) correctly uses the updated `isGenerating` value - no changes needed here as it already uses `isGenerating`.
    *   `[ ]` 7.d. `[TEST-UNIT]` **GREEN**: Re-run the test from step 7.b and ensure it now passes. Also verify that existing `SessionContributionsDisplayCard` tests still pass (especially tests that verify the loader displays correctly when generation is active).
    *   `[ ]` 7.e. `[TEST-UNIT]` **RED**: In `apps/web/src/components/dialectic/SessionContributionsDisplayCard.test.tsx`, write a test that verifies the loader displays correctly when the current session is generating.
        *   `[ ]` 7.e.i. Create a test case that mocks store state where `generatingSessions[activeSessionId]` contains job IDs (e.g., `['job-1', 'job-2']`) for the current session.
        *   `[ ]` 7.e.ii. Mock `failedDocumentKeys` to be empty and `generationError` to be null.
        *   `[ ]` 7.e.iii. Render `SessionContributionsDisplayCard` and assert that the "Generating documents" loader IS displayed when the current session has active generation jobs. This test should pass immediately after step 7.c if implemented correctly.
    *   `[ ]` 7.f. `[TEST-UNIT]` **GREEN**: Re-run the test from step 7.e and ensure it passes. This verifies that the loader still works correctly when generation is actually active for the current session.
    *   `[ ]` 7.g. `[LINT]` Run the linter for `apps/web/src/components/dialectic/SessionContributionsDisplayCard.tsx` and resolve any warnings or errors.

*   `[âœ…]` 8. **`[BE]` Fix Recipe Step Output Type to Use Model Contribution File Type**
    *   `[âœ…]` 8.a. `[DEPS]` Recipe steps in database migrations have `output_type: 'rendered_document'` (the final product), but planners expect `output_type` to be a `ModelContributionFileType` (what the model produces). The actual document key (e.g., `business_case`, `feature_spec`, `technical_approach`, `success_metrics`) is found in `outputs_required.documents[0].document_key`. The `getStageRecipe.ts` function in `supabase/functions/dialectic-service/getStageRecipe.ts` (lines 89-99) validates `output_type` against only 3 values (`HeaderContext`, `AssembledDocumentJson`, `RenderedDocument`), which is architecturally incorrect: `HeaderContext` and `AssembledDocumentJson` are backend-only and should never be sent to the frontend. The `OutputType` type in `supabase/functions/dialectic-service/dialectic.interface.ts` (lines 627-631) incorrectly includes these backend-only types. All planners (`planPerSourceDocument`, `planAllToOne`, `planPerSourceGroup`, `planPairwiseByOrigin`, `planPerSourceDocumentByLineage`, `planPerModel`) validate that `recipeStep.output_type` must be a `ModelContributionFileType` (using `isModelContributionFileType` check), and they use it directly to set `jobPayload.output_type` for EXECUTE jobs. The `shouldEnqueueRenderJob` function in `supabase/functions/_shared/utils/shouldEnqueueRenderJob.ts` checks if `outputType` matches any `document_key` in `outputs_required` that has markdown `file_type`, so `output_type` should match `document_key` for proper rendering logic. Every `document_key` is a `FileType`, and `output_type` should match the `document_key` to create semantic alignment. The fix requires: (1) defining `OutputType` as a subset of `ModelContributionFileTypes` that become rendered documents (excludes `HeaderContext`, `AssembledDocumentJson`, and other backend-only types), (2) updating all stage migration files (`20251006194531_thesis_stage.sql`, `20251006194542_antithesis_stage.sql`, `20251006194558_parenthesis_stage.sql`, `20251006194549_synthesis_stage.sql`, `20251006194605_paralysis_stage.sql`) to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'` for all EXECUTE job steps, (3) updating `getStageRecipe.ts` to validate that `output_type` is a `ModelContributionFileType` and is in the `OutputType` subset (renderable types), and pass it through as-is to the DTO (no mapping needed since `output_type` will match `document_key`), (4) filtering out PLAN job steps with `header_context` output from the DTO sent to frontend (or handling them separately) since they are backend-only.
    *   `[âœ…]` 8.b. `[TYPES]` In `supabase/functions/dialectic-service/dialectic.interface.ts`, define `OutputType` as a subset of `ModelContributionFileTypes` that become rendered documents. This excludes backend-only types like `HeaderContext`, `AssembledDocumentJson`, `ModelContributionRawJson`, `PairwiseSynthesisChunk`, `ReducedSynthesis`, `Synthesis`, `header_context_pairwise`, `SynthesisHeaderContext`, and other intermediate types that don't become user-facing rendered documents. The `OutputType` should include all `ModelContributionFileTypes` that have markdown outputs in `outputs_required` (e.g., `business_case`, `feature_spec`, `technical_approach`, `success_metrics`, `business_case_critique`, `technical_feasibility_assessment`, `risk_register`, `non_functional_requirements`, `dependency_map`, `comparison_vector`, `product_requirements`, `system_architecture`, `tech_stack`, `technical_requirements`, `master_plan`, `milestone_schema`, `updated_master_plan`, `actionable_checklist`, `advisor_recommendations`). Import `ModelContributionFileTypes` from `../_shared/types/file_manager.types.ts` and create a manually curated union type `OutputType` that includes only the renderable `ModelContributionFileTypes`. This provides type safety and semantic clarity: `OutputType` represents "FileTypes that become RenderedDocument". Replace the current `OutputType` definition (lines 627-631) with this new subset type.
    *   `[âœ…]` 8.b.i. `[TYPES]` In `supabase/functions/_shared/utils/type-guards/type_guards.file_manager.ts`, create a type guard function `isOutputType(value: ModelContributionFileTypes): value is OutputType` that validates if a `ModelContributionFileType` is in the `OutputType` subset (renderable types). This function should check against a runtime map similar to `MODEL_CONTRIBUTION_FILE_TYPES_MAP`, but only include the renderable types. Import `OutputType` from `../../dialectic-service/dialectic.interface.ts` and create `OUTPUT_TYPES_MAP: { [K in OutputType]: true }` with all renderable types, then implement `isOutputType` to check if the value exists in this map.
    *   `[âœ…]` 8.c. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-service/getStageRecipe.test.ts` (or create if it doesn't exist), write tests that verify `getStageRecipe` accepts renderable `ModelContributionFileTypes` (those in `OutputType`) for EXECUTE job steps and filters out backend-only types.
        *   `[âœ…]` 8.c.i. Create a test case that mocks a recipe step with `output_type: 'business_case'` (a renderable `ModelContributionFileType` in `OutputType`) and `job_type: 'EXECUTE'`, and assert that `getStageRecipe` returns successfully with `output_type: 'business_case'` in the response DTO.
        *   `[âœ…]` 8.c.ii. Create a test case that mocks a recipe step with `output_type: 'feature_spec'` (a renderable `ModelContributionFileType` in `OutputType`) and `job_type: 'EXECUTE'`, and assert that `getStageRecipe` returns successfully with `output_type: 'feature_spec'` in the response DTO.
        *   `[âœ…]` 8.c.iii. Create a test case that mocks a recipe step with `output_type: 'header_context'` (a backend-only `ModelContributionFileType` NOT in `OutputType`) and `job_type: 'PLAN'`, and assert that `getStageRecipe` either: (a) excludes this step from the DTO response (filters it out), or (b) returns an error indicating backend-only types cannot be sent to frontend. PLAN jobs with `header_context` are backend-only and should not appear in the frontend DTO.
        *   `[âœ…]` 8.c.iv. Create a test case that mocks a recipe step with `output_type: 'rendered_document'` (which is NOT a `ModelContributionFileType`), and assert that `getStageRecipe` returns an error. The database should never have `output_type: 'rendered_document'` after migrations are updated.
        *   `[âœ…]` 8.c.v. These tests must fail initially because `getStageRecipe.ts` validation (lines 89-99) only accepts 3 values (`HeaderContext`, `AssembledDocumentJson`, `RenderedDocument`), not the renderable `ModelContributionFileTypes`.
    *   `[âœ…]` 8.d. `[BE]` **GREEN**: In `supabase/functions/dialectic-service/getStageRecipe.ts`, update the validation logic (lines 89-99) to validate that `output_type` is a `ModelContributionFileType` and is in the `OutputType` subset (renderable types), and filter out backend-only steps from the DTO.
        *   `[âœ…]` 8.d.i. Import `ModelContributionFileTypes`, `isModelContributionFileType`, and `OutputType` from `../_shared/types/file_manager.types.ts`, `../_shared/utils/type-guards/type_guards.file_manager.ts`, and `./dialectic.interface.ts` respectively (if not already imported).
        *   `[âœ…]` 8.d.ii. Replace the restrictive validation (lines 92-99) that only accepts 3 values with: (1) a check that uses `isModelContributionFileType(rawType)` to validate that `output_type` is a valid `ModelContributionFileType`, (2) a check that uses `isOutputType(rawType)` (from step 8.b.i) to verify `rawType` is in the `OutputType` subset (renderable types). If `output_type` is a `ModelContributionFileType` but not in `OutputType`, either filter out the step (for backend-only types like `header_context`) or return an error.
        *   `[âœ…]` 8.d.iii. Set `mappedOutputType` to `rawType as OutputType` after validating it's in the `OutputType` subset. The `output_type` passes through as-is (no mapping needed) since it will match `document_key` in `outputs_required`.
        *   `[âœ…]` 8.d.iv. For PLAN job steps with `output_type: 'header_context'` (or other backend-only types), either: (a) filter them out before adding to the `normalized` array (skip adding the DTO), or (b) return an error. Option (a) is preferred - backend-only steps should not be sent to the frontend.
        *   `[âœ…]` 8.d.v. Remove the error logging that references only the 3 specific values, and update it to log any invalid `output_type` that fails the `isModelContributionFileType` check or is not in the `OutputType` subset.
    *   `[âœ…]` 8.e. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 8.c and ensure they now pass. Verify that: (1) renderable `ModelContributionFileTypes` pass validation and appear in the DTO, (2) backend-only types like `header_context` are filtered out from the DTO, (3) invalid types return errors. Also verify that existing `getStageRecipe` tests still pass, but note that PLAN job steps with `header_context` should no longer appear in the DTO response (they are filtered out as backend-only).
    *   `[âœ…]` 8.f. `[DB]` In `supabase/migrations/20251006194531_thesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.g.i. For template step `'thesis_generate_business_case'` (line 323): change `output_type` from `'rendered_document'` (line 329) to `'business_case'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 336).
        *   `[âœ…]` 8.g.ii. For template step `'thesis_generate_feature_spec'` (line 485): change `output_type` from `'rendered_document'` (line 491) to `'feature_spec'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 498).
        *   `[âœ…]` 8.g.iii. For template step `'thesis_generate_technical_approach'` (line 643): change `output_type` from `'rendered_document'` (line 649) to `'technical_approach'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 656).
        *   `[âœ…]` 8.g.iv. For template step `'thesis_generate_success_metrics'` (line 800): change `output_type` from `'rendered_document'` (line 806) to `'success_metrics'` (which is the `document_key` in `outputs_required.documents[0].document_key` at line 813).
        *   `[âœ…]` 8.g.v. For instance step `'thesis_generate_business_case'` (line 1060): change `output_type` from `'rendered_document'` (line 1065) to `'business_case'`.
        *   `[âœ…]` 8.g.vi. For instance step `'thesis_generate_feature_spec'` (line 1132): change `output_type` from `'rendered_document'` (line 1137) to `'feature_spec'`.
        *   `[âœ…]` 8.g.vii. For instance step `'thesis_generate_technical_approach'` (line 1200): change `output_type` from `'rendered_document'` (line 1205) to `'technical_approach'`.
        *   `[âœ…]` 8.g.viii. For instance step `'thesis_generate_success_metrics'` (line 1267): change `output_type` from `'rendered_document'` (line 1272) to `'success_metrics'`.
        *   `[âœ…]` 8.g.ix. Verify that PLAN job steps (e.g., `'thesis_build_stage_header'`) keep their `output_type: 'header_context'` unchanged, as these are correct.
    *   `[âœ…]` 8.h. `[DB]` In `supabase/migrations/20251006194542_antithesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.h.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for antithesis stage include: `'business_case_critique'`, `'technical_feasibility_assessment'`, `'risk_register'`, `'non_functional_requirements'`, `'dependency_map'`, `'comparison_vector'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.i. `[DB]` In `supabase/migrations/20251006194558_parenthesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.i.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for parenthesis stage include: `'technical_requirements'`, `'master_plan'`, `'milestone_schema'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.j. `[DB]` In `supabase/migrations/20251006194549_synthesis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.j.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for synthesis stage include: `'product_requirements'`, `'system_architecture'`, `'tech_stack'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.k. `[DB]` In `supabase/migrations/20251006194605_paralysis_stage.sql`, update all EXECUTE job recipe steps to set `output_type` to the actual `ModelContributionFileType` from `outputs_required.documents[0].document_key` instead of `'rendered_document'`.
        *   `[âœ…]` 8.k.i. For each EXECUTE job step in the migration file, identify the `document_key` in `outputs_required.documents[0].document_key` and update `output_type` from `'rendered_document'` to that `document_key` value. Common document keys for paralysis stage include: `'updated_master_plan'`, `'actionable_checklist'`, `'advisor_recommendations'`. Ensure both template steps and instance steps are updated.
    *   `[âœ…]` 8.l. `[TEST-INT]` **RED**: In `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file, write a test that verifies planners can successfully create EXECUTE jobs from recipe steps with `output_type` set to actual `ModelContributionFileTypes` (e.g., `'business_case'`) when using real recipe steps from the updated database.
        *   `[âœ…]` 8.l.i. Create a test case that sets up a PLAN job and fetches real recipe steps from the database (after migrations are updated in steps 8.f-8.k).
        *   `[âœ…]` 8.l.ii. Find an EXECUTE job recipe step (e.g., `'thesis_generate_business_case'`) and verify it has `output_type: 'business_case'` (not `'rendered_document'`).
        *   `[âœ…]` 8.l.iii. Call the planner function (e.g., `planPerSourceDocument`) with the recipe step and source documents, and assert that it successfully creates child EXECUTE job payloads with `output_type: 'business_case'`.
        *   `[âœ…]` 8.l.iv. Assert that the `isModelContributionFileType` validation in the planner passes (no error is thrown).
        *   `[âœ…]` 8.l.v. Verify that `output_type` in the recipe step matches `document_key` in `outputs_required.documents[0].document_key` (e.g., both are `'business_case'`), ensuring semantic alignment. This test verifies the end-to-end flow: database has correct `output_type` matching `document_key`, `getStageRecipe` returns it correctly, and planners can use it to create EXECUTE jobs.
    *   `[âœ…]` 8.m. `[TEST-INT]` **GREEN**: Re-run the test from step 8.l and ensure it passes. This verifies that the complete end-to-end flow works correctly after all changes (types updated, source code updated, database migrations applied).
    *   `[âœ…]` 8.n. `[LINT]` Run the linter for all modified files (`supabase/functions/dialectic-service/dialectic.interface.ts`, `supabase/functions/dialectic-service/getStageRecipe.ts`) and resolve any warnings or errors.

*   `[âœ…]` 9. **`[BE]` Fix assembleTurnPrompt to Query Header Context by Contribution ID Instead of Storage Path**
    *   `[âœ…]` 9.a. `[DEPS]` The `assembleTurnPrompt` function in `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` (lines 47-51, 78-82) requires `payload.header_context_resource_id` (a storage path string) and hardcodes bucket `"SB_CONTENT_STORAGE_BUCKET"` to download header context. However, planners (e.g., `planPerSourceDocument` in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, line 88) set `inputs[`${doc.contribution_type}_id`] = doc.id`, which for `header_context` creates `inputs.header_context_id` with the contribution ID. Header context is stored as a contribution in `dialectic_contributions` with `contribution_type = 'header_context'`. The `assemblePlannerPrompt` and `assembleSeedPrompt` functions correctly use `gatherInputsForStage` which queries contributions by metadata (stage, iteration, etc.) and gets storage details from the database record, avoiding duplication of storage paths in payloads. The fix requires: (1) updating `assembleTurnPrompt` to read `inputs.header_context_id` from `job.payload.inputs.header_context_id`, query `dialectic_contributions` by that ID to get `storage_bucket`, `storage_path`, and `file_name`, construct the full path, and download using the record's bucket (matching the pattern in `gatherInputsForStage` lines 104-185), (2) removing the `header_context_resource_id` requirement from the payload precondition check (line 47-51), (3) removing the hardcoded bucket usage, ensuring the function uses the database as the single source of truth for storage details.
    *   `[âœ…]` 9.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.test.ts`, write tests that verify `assembleTurnPrompt` queries header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 9.b.i. Create a test case that mocks a job payload with `inputs.header_context_id` set to a contribution ID (e.g., `"contrib-123"`), and mocks a database query to `dialectic_contributions` that returns a contribution record with `storage_bucket: "dialectic_contributions"`, `storage_path: "path/to/header"`, `file_name: "header_context.json"`, and `contribution_type: "header_context"`.
        *   `[âœ…]` 9.b.ii. Mock `downloadFromStorage` to be called with the contribution's `storage_bucket` and the constructed path (`${storage_path}/${file_name}`) instead of hardcoded `"SB_CONTENT_STORAGE_BUCKET"` and `payload.header_context_resource_id`.
        *   `[âœ…]` 9.b.iii. Assert that `assembleTurnPrompt` successfully queries the contribution by ID, constructs the storage path from the record, and downloads using the record's bucket. This test must fail because `assembleTurnPrompt` currently requires `header_context_resource_id` in payload and uses hardcoded bucket.
        *   `[âœ…]` 9.b.iv. Create a test case that verifies `assembleTurnPrompt` throws an error when `inputs.header_context_id` is missing or invalid (contribution not found in database). This test must fail because the function currently checks for `header_context_resource_id` instead.
        *   `[âœ…]` 9.b.v. Create a test case that verifies `assembleTurnPrompt` throws an error when the contribution record is missing `storage_bucket`, `storage_path`, or `file_name`. This test must fail initially but should pass after implementation.
    *   `[âœ…]` 9.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts`, update the function to query header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 9.c.i. Remove the precondition check for `payload.header_context_resource_id` (lines 47-51) that throws an error when missing.
        *   `[âœ…]` 9.c.ii. Add a precondition check that verifies `job.payload.inputs` exists and is a record, and that `job.payload.inputs.header_context_id` is a string (the contribution ID).
        *   `[âœ…]` 9.c.iii. Query `dialectic_contributions` by `inputs.header_context_id` to get the contribution record, selecting `storage_bucket`, `storage_path`, `file_name`, and `contribution_type` fields. Verify the contribution exists and has `contribution_type = 'header_context'`.
        *   `[âœ…]` 9.c.iv. Validate that the contribution record has `storage_bucket`, `storage_path`, and `file_name` (all non-null strings). If any are missing, throw an error indicating the contribution is missing storage details.
        *   `[âœ…]` 9.c.v. Construct the full storage path as `${contrib.storage_path}/${contrib.file_name}` (or just `contrib.storage_path` if `file_name` is empty, matching the pattern in `gatherInputsForStage` line 144-146).
        *   `[âœ…]` 9.c.vi. Replace the `downloadFromStorage` call (lines 78-82) to use `contrib.storage_bucket` instead of hardcoded `"SB_CONTENT_STORAGE_BUCKET"`, and use the constructed path instead of `job.payload.header_context_resource_id`.
        *   `[âœ…]` 9.c.vii. Ensure all error messages are updated to reference the contribution ID lookup instead of `header_context_resource_id`.
    *   `[âœ…]` 9.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 9.b and ensure they now pass. Also verify that existing `assembleTurnPrompt` tests still pass (update any tests that mock `header_context_resource_id` to instead mock `inputs.header_context_id` and the database query).
    *   `[âœ…]` 9.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` and resolve any warnings or errors.

*   `[âœ…]` 10. **`[BE]` Fix assembleContinuationPrompt to Query Header Context by Contribution ID Instead of Storage Path**
    *   `[âœ…]` 10.a. `[DEPS]` The `assembleContinuationPrompt` function in `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts` (lines 82-89) optionally uses `payload.header_context_resource_id` (storage path) and hardcodes bucket `"dialectic_project_resources"`. However, planners (e.g., `planPerSourceDocument` in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, line 88) set `inputs[`${doc.contribution_type}_id`] = doc.id`, which for `header_context` creates `inputs.header_context_id` with the contribution ID. Header context is stored as a contribution in `dialectic_contributions` with `contribution_type = 'header_context'`. The `assemblePlannerPrompt` and `assembleSeedPrompt` functions correctly use `gatherInputsForStage` which queries contributions by metadata (stage, iteration, etc.) and gets storage details from the database record, avoiding duplication of storage paths in payloads. The fix requires: (1) updating `assembleContinuationPrompt` to optionally read `inputs.header_context_id` and query the contribution if present, (2) removing the hardcoded bucket usage and storage path requirement, ensuring the function uses the database as the single source of truth for storage details, (3) keeping the optional behavior: if `inputs.header_context_id` is missing, the function should continue without header context (no error thrown).
    *   `[âœ…]` 10.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.test.ts`, write tests that verify `assembleContinuationPrompt` optionally queries header context by contribution ID from `inputs` instead of requiring `header_context_resource_id` in payload.
        *   `[âœ…]` 10.b.i. Create a test case that mocks a job payload with `inputs.header_context_id` set to a contribution ID, and mocks a database query that returns a contribution record with storage details, and asserts that `assembleContinuationPrompt` successfully queries and downloads the header context using the contribution's bucket and path.
        *   `[âœ…]` 10.b.ii. Create a test case that verifies `assembleContinuationPrompt` works correctly when `inputs.header_context_id` is missing (header context is optional for continuation prompts), and no header context is included in the final prompt. This test should pass initially since the function already handles optional header context (line 82-106).
        *   `[âœ…]` 10.b.iii. Create a test case that verifies `assembleContinuationPrompt` throws an error when `inputs.header_context_id` is provided but the contribution is not found in the database. This test must fail because the function currently uses `header_context_resource_id` directly without querying.
        *   `[âœ…]` 10.b.iv. Create a test case that verifies `assembleContinuationPrompt` uses the contribution's `storage_bucket` instead of hardcoded `"dialectic_project_resources"` when downloading header context. This test must fail because the function currently hardcodes the bucket (line 87).
    *   `[âœ…]` 10.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts`, update the function to optionally query header context by contribution ID from `inputs` instead of using `header_context_resource_id` in payload.
        *   `[âœ…]` 10.c.i. Update the header context fetching logic (lines 82-106) to check for `job.payload.inputs?.header_context_id` instead of `job.payload?.header_context_resource_id`.
        *   `[âœ…]` 10.c.ii. If `inputs.header_context_id` exists and is a string, query `dialectic_contributions` by that ID to get the contribution record with `storage_bucket`, `storage_path`, `file_name`, and `contribution_type` fields. Verify the contribution exists and has `contribution_type = 'header_context'`.
        *   `[âœ…]` 10.c.iii. Validate that the contribution record has `storage_bucket`, `storage_path`, and `file_name` (all non-null strings). If any are missing, throw an error indicating the contribution is missing storage details.
        *   `[âœ…]` 10.c.iv. Construct the full storage path as `${contrib.storage_path}/${contrib.file_name}` (or just `contrib.storage_path` if `file_name` is empty).
        *   `[âœ…]` 10.c.v. Replace the `downloadFromStorage` call (lines 85-89) to use `contrib.storage_bucket` instead of hardcoded `"dialectic_project_resources"`, and use the constructed path instead of `headerResourceId`.
        *   `[âœ…]` 10.c.vi. Ensure all error messages are updated to reference the contribution ID lookup instead of `header_context_resource_id`.
        *   `[âœ…]` 10.c.vii. Keep the optional behavior: if `inputs.header_context_id` is missing or undefined, the function should continue without header context (no error thrown), matching the current optional behavior.
    *   `[âœ…]` 10.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 10.b and ensure they now pass. Also verify that existing `assembleContinuationPrompt` tests still pass (update any tests that mock `header_context_resource_id` to instead mock `inputs.header_context_id` and the database query).
    *   `[âœ…]` 10.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assembleContinuationPrompt.ts` and resolve any warnings or errors.

*   `[âœ…]` 11. **`[BE]` Fix planAllToOne to Extract and Validate document_key**
    *   `[âœ…]` 11.a. `[DEPS]` The `planAllToOne` planner function in `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 11.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts`, write tests that verify `planAllToOne` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 11.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'business_case'` and asserts that the created payload has `document_key: 'business_case'`.
        *   `[âœ…]` 11.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property (e.g., only has `header_context_artifact`), and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planAllToOne` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 11.b.v. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key` set to `null` or empty string, and asserts that `planAllToOne` throws an error (step outputs documents but `document_key` is invalid).
        *   `[âœ…]` 11.b.vi. Create a test case that mocks a recipe step with `outputs_required` missing or undefined, and asserts that `planAllToOne` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 11.b.vii. These tests must fail because `planAllToOne` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 11.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 11.c.i. Before creating `newPayload` (line 44), check if the step outputs documents: verify that `recipeStep.outputs_required` exists, is an object, has a `documents` property that is an array, and the array has at least one item.
        *   `[âœ…]` 11.c.ii. If the step outputs documents (condition from 11.c.i is true), extract `document_key` from `recipeStep.outputs_required.documents[0].document_key`. If `documents[0]` is missing, not an object, or missing `document_key` property, throw an error: `"planAllToOne requires recipeStep.outputs_required.documents[0].document_key but it is missing"`.
        *   `[âœ…]` 11.c.iii. If the step outputs documents, validate that `document_key` is a non-empty string. If it's null, undefined, empty string, or not a string type, throw an error: `"planAllToOne requires recipeStep.outputs_required.documents[0].document_key to be a non-empty string, but received: ${typeof document_key === 'string' ? `'${document_key}'` : String(document_key)}"`.
        *   `[âœ…]` 11.c.iv. If the step outputs documents, store the validated `document_key` in a variable. If the step does not output documents, leave `document_key` as `undefined`.
        *   `[âœ…]` 11.c.v. Add `document_key` to the `newPayload` object (after line 68, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 11.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 11.b and ensure they now pass. Also verify that existing `planAllToOne` tests still pass.
    *   `[âœ…]` 11.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` and `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 12. **`[BE]` Fix planPairwiseByOrigin to Extract and Validate document_key**
    *   `[âœ…]` 12.a. `[DEPS]` The `planPairwiseByOrigin` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 12.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts`, write tests that verify `planPairwiseByOrigin` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 12.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'pairwise_synthesis_chunk'` and asserts that the created payload has `document_key: 'pairwise_synthesis_chunk'`.
        *   `[âœ…]` 12.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPairwiseByOrigin` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 12.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPairwiseByOrigin` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 12.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPairwiseByOrigin` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 12.b.v. These tests must fail because `planPairwiseByOrigin` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 12.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 12.c.i. Before creating `newPayload` (line 91), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPairwiseByOrigin"` instead of `"planAllToOne"`.
        *   `[âœ…]` 12.c.ii. Add `document_key` to the `newPayload` object (after line 116, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 12.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 12.b and ensure they now pass. Also verify that existing `planPairwiseByOrigin` tests still pass.
    *   `[âœ…]` 12.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 13. **`[BE]` Fix planPerModel to Extract and Validate document_key**
    *   `[âœ…]` 13.a. `[DEPS]` The `planPerModel` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 13.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts`, write tests that verify `planPerModel` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 13.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'synthesis'` and asserts that the created payload has `document_key: 'synthesis'`.
        *   `[âœ…]` 13.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerModel` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 13.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerModel` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 13.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerModel` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 13.b.v. These tests must fail because `planPerModel` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 13.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 13.c.i. Before creating `newPayload` (line 75), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerModel"` instead of `"planAllToOne"`.
        *   `[âœ…]` 13.c.ii. Add `document_key` to the `newPayload` object (after line 98, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 13.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 13.b and ensure they now pass. Also verify that existing `planPerModel` tests still pass.
    *   `[âœ…]` 13.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 14. **`[BE]` Fix planPerSourceDocument to Extract and Validate document_key**
    *   `[âœ…]` 14.a. `[DEPS]` The `planPerSourceDocument` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 14.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts`, write tests that verify `planPerSourceDocument` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 14.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'business_case_critique'` and asserts that the created payload has `document_key: 'business_case_critique'`.
        *   `[âœ…]` 14.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceDocument` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 14.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerSourceDocument` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 14.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceDocument` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 14.b.v. These tests must fail because `planPerSourceDocument` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 14.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 14.c.i. Before creating `newPayload` (line 94), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerSourceDocument"` instead of `"planAllToOne"`.
        *   `[âœ…]` 14.c.ii. Add `document_key` to the `newPayload` object (after line 116, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 14.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 14.b and ensure they now pass. Also verify that existing `planPerSourceDocument` tests still pass.
    *   `[âœ…]` 14.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 15. **`[BE]` Fix planPerSourceDocumentByLineage to Extract and Validate document_key**
    *   `[âœ…]` 15.a. `[DEPS]` The `planPerSourceDocumentByLineage` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 15.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts`, write tests that verify `planPerSourceDocumentByLineage` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 15.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'technical_requirements'` and asserts that the created payload has `document_key: 'technical_requirements'`.
        *   `[âœ…]` 15.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceDocumentByLineage` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 15.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerSourceDocumentByLineage` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 15.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceDocumentByLineage` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 15.b.v. These tests must fail because `planPerSourceDocumentByLineage` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 15.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 15.c.i. Before creating `newPayload` (line 70), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerSourceDocumentByLineage"` instead of `"planAllToOne"`.
        *   `[âœ…]` 15.c.ii. Add `document_key` to the `newPayload` object (after line 99, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 15.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 15.b and ensure they now pass. Also verify that existing `planPerSourceDocumentByLineage` tests still pass.
    *   `[âœ…]` 15.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 16. **`[BE]` Fix planPerSourceGroup to Extract and Validate document_key**
    *   `[âœ…]` 16.a. `[DEPS]` The `planPerSourceGroup` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` creates `DialecticExecuteJobPayload` objects but does not set `document_key`. The `assembleTurnPrompt` function requires `job.payload.document_key` (string) to find document info in `headerContext.files_to_generate`, but only for steps that output documents. The `document_key` must be extracted from `recipeStep.outputs_required.documents[0].document_key` ONLY IF the step outputs documents (i.e., if `outputs_required.documents` exists and has at least one item). If the step outputs documents (has `outputs_required.documents` array with items), then `document_key` must be a non-empty string and must be extracted and validated. If the step does not output documents (missing `outputs_required.documents` or empty array), then `document_key` should not be set in the payload. If the step outputs documents but `outputs_required.documents[0].document_key` is missing, undefined, null, or not a string, the planner must throw an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing.
    *   `[âœ…]` 16.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts`, write tests that verify `planPerSourceGroup` sets `document_key` in the payload when the step outputs documents and does not require it when the step does not output documents.
        *   `[âœ…]` 16.b.i. Create a test case that mocks a recipe step with `outputs_required.documents[0].document_key: 'synthesis'` and asserts that the created payload has `document_key: 'synthesis'`.
        *   `[âœ…]` 16.b.ii. Create a test case that mocks a recipe step with `outputs_required.documents` array empty, and asserts that `planPerSourceGroup` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 16.b.iii. Create a test case that mocks a recipe step with `outputs_required` missing `documents` property, and asserts that `planPerSourceGroup` does NOT set `document_key` in the payload (step does not output documents, so `document_key` is not required).
        *   `[âœ…]` 16.b.iv. Create a test case that mocks a recipe step with `outputs_required.documents[0]` missing `document_key` property, and asserts that `planPerSourceGroup` throws an error (step outputs documents but `document_key` is missing).
        *   `[âœ…]` 16.b.v. These tests must fail because `planPerSourceGroup` currently does not set `document_key` in the payload and does not validate its presence conditionally.
    *   `[âœ…]` 16.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts`, conditionally extract `document_key` from `recipeStep.outputs_required` only if the step outputs documents, and set it in the payload, throwing errors when missing for document-outputting steps.
        *   `[âœ…]` 16.c.i. Before creating `newPayload` (line 54), use the same conditional logic as step 11.c.i through 11.c.v, but with error messages prefixed with `"planPerSourceGroup"` instead of `"planAllToOne"`.
        *   `[âœ…]` 16.c.ii. Add `document_key` to the `newPayload` object (after line 80, before the closing brace) only if it was extracted: `...(documentKey ? { document_key: documentKey } : {})`. Do not use any fallback or default value.
    *   `[âœ…]` 16.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 16.b and ensure they now pass. Also verify that existing `planPerSourceGroup` tests still pass.
    *   `[âœ…]` 16.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 17. **`[TEST-INT]` Fix Integration Test to Verify End-to-End document_key Flow**
    *   `[âœ…]` 17.a. `[DEPS]` After all planners are updated (steps 11-16), write an integration test that verifies the complete end-to-end flow: planners create EXECUTE job payloads with `document_key`, and `assembleTurnPrompt` can successfully process them. The test file `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file should verify this flow.
    *   `[âœ…]` 17.b. `[TEST-INT]` **RED**: In `supabase/functions/dialectic-worker/processComplexJob.integration.test.ts` or similar integration test file, write a test that verifies EXECUTE jobs created by planners include `document_key` and can be processed by `assembleTurnPrompt`.
        *   `[âœ…]` 17.b.i. Create a test case that sets up a PLAN job, calls a planner function (e.g., `planPerSourceDocument`) with a recipe step that has `outputs_required.documents[0].document_key`, and creates child EXECUTE jobs.
        *   `[âœ…]` 17.b.ii. Assert that the created EXECUTE job payloads have `document_key` set to the expected value from `outputs_required.documents[0].document_key`.
        *   `[âœ…]` 17.b.iii. Mock `assembleTurnPrompt` and verify it receives a payload with `document_key` set correctly, and that it can successfully find the document info in `headerContext.files_to_generate` using that `document_key`.
        *   `[âœ…]` 17.b.iv. This test must fail initially if any planner is missing `document_key`, but should pass after all planners are updated (steps 11-16).
    *   `[âœ…]` 17.c. `[TEST-INT]` **GREEN**: Re-run the test from step 17.b and ensure it now passes. This verifies that the complete end-to-end flow works correctly: planners create payloads with `document_key`, and `assembleTurnPrompt` can process them successfully.
    *   `[âœ…]` 17.d. `[LINT]` Run the linter for the integration test file and resolve any warnings or errors.
    *   `[âœ…]` 17.e. `[CRITERIA]` All six planners (`planAllToOne`, `planPairwiseByOrigin`, `planPerModel`, `planPerSourceDocument`, `planPerSourceDocumentByLineage`, `planPerSourceGroup`) now extract `document_key` from `recipeStep.outputs_required.documents[0].document_key` and set it in the `DialecticExecuteJobPayload`. If `document_key` is missing, undefined, null, empty string, or not a string, each planner throws an error immediately (fail loud and hard) - no fallbacks, defaults, or silent healing. All unit tests pass, integration tests verify the end-to-end flow works, and `assembleTurnPrompt` can successfully process EXECUTE jobs created by any planner. Error messages clearly identify which planner failed and why `document_key` is missing.
    *   `[âœ…]` 17.f. `[COMMIT]` Commit message: "fix: add document_key validation to all planner EXECUTE job payloads - Extract document_key from recipeStep.outputs_required.documents[0].document_key - Throw errors immediately if document_key is missing, null, empty, or invalid (fail loud and hard, no fallbacks) - Update all six planners (planAllToOne, planPairwiseByOrigin, planPerModel, planPerSourceDocument, planPerSourceDocumentByLineage, planPerSourceGroup) - Add unit tests for each planner verifying document_key extraction and error handling - Add integration test verifying end-to-end flow with assembleTurnPrompt - Resolves missing document_key error in assembleTurnPrompt"

SessionContributionsDisplayCard should not render a GeneratedContributionsCard for any document that is not highlighted in StageRunChecklist

GeneratedContributionsCard should not render a document for any document that is not highlighted in StageRunChecklist

*   `[âœ…]` 18. **`[TYPES]` Define ContentToInclude Type, Update ContextForDocument, and Define HeaderContext Interface in dialectic.interface.ts**
    *   `[âœ…]` 18.a. `[DEPS]` The `ContextForDocument` interface in `supabase/functions/dialectic-service/dialectic.interface.ts` (line 1240) currently defines `content_to_include` as `Record<string, unknown> | Record<string, unknown>[]`, which is too generic and doesn't enforce schema consistency. The `assembleTurnPrompt.ts` file (line 9) and `assembleContinuationPrompt.ts` file (line 8) both import `HeaderContext` from `dialectic.interface.ts`, but this type is NOT exported from that file, causing a missing type definition that will cause TypeScript errors. Based on complete analysis of all recipe migrations in Recipe-Planner-Gap-Analysis.md (lines 862-900), all `content_to_include` structures are objects (conceptually `Record<string, ...>`) where values can be: string (empty string "" for placeholders, or filled strings), string[] (array of strings), boolean (for flags), number (for scores, counts), nested ContentToInclude objects (recursive), or ContentToInclude[] (array of nested objects for repeated sections). **IMPORTANT**: Because the type is recursive, TypeScript requires index signature syntax `{[key: string]: ...}` rather than `Record<string, ...>` which cannot express recursion. The only exception is Antithesis `non_functional_requirements` which uses array of strings at top level - this will be fixed in migration step 20. The unified type must support all observed structures from all 5 stage migrations, and any structure from the migration that is not aligned to other structures in other migrations must be aligned to the common, unified pattern. The `HeaderContext` interface must be defined to match the actual structure of the header_context artifact generated by PLAN jobs: `system_materials: SystemMaterials`, `header_context_artifact: HeaderContextArtifact`, and `context_for_documents: ContextForDocument[]`. It must NOT have `files_to_generate` (that's in recipe step, not header context). All three type definitions must be added to the same file in a single step to ensure type consistency and avoid import errors.
    *   `[âœ…]` 18.b. `[TYPES]` In `supabase/functions/dialectic-service/dialectic.interface.ts`, define all three types/interfaces in the correct order: `ContentToInclude` type (before `ContextForDocument` interface, around line 1230), update `ContextForDocument` interface (line 1239-1242), and define `HeaderContext` interface (after `ContextForDocument`, around line 1242).
        *   `[âœ…]` 18.b.i. Add the `ContentToInclude` type definition before the `ContextForDocument` interface definition (around line 1230, before line 1239 where `ContextForDocument` is defined). The type definition must include the complete JSDoc comment explaining all observed structures and examples from recipes (as specified in Recipe-Planner-Gap-Analysis.md Fix 2, lines 1110-1128). **IMPORTANT**: TypeScript does not permit recursive types with `Record<string, ...>` syntax. Use index signature syntax instead. The type must be exported with this exact multi-line format: `export type ContentToInclude = {` on the first line, `[key: string]:` on the second line, then each union member (`| string`, `| string[]`, `| boolean`, `| number`, `| ContentToInclude`, `| ContentToInclude[]`) on separate lines with comments, then closing with `};` on the final line. This index signature syntax is the only way TypeScript supports recursive type definitions. Do NOT use `Record<string, ...>` as it cannot express recursion.
        *   `[âœ…]` 18.b.ii. Update the `ContextForDocument` interface (lines 1239-1242) to use `ContentToInclude` instead of the generic type. Change line 1240 from `content_to_include: Record<string, unknown> | Record<string, unknown>[];` to `content_to_include: ContentToInclude;`. Ensure `ContentToInclude` is accessible (it should be in the same file after step 18.b.i).
        *   `[âœ…]` 18.b.iii. Verify that `SystemMaterials` and `HeaderContextArtifact` types/interfaces are already defined in the file. If they are missing, this step must halt and report the missing types as a blocking issue. If they exist, proceed to define `HeaderContext`.
        *   `[âœ…]` 18.b.iv. Add the `HeaderContext` interface definition exactly as specified in Recipe-Planner-Gap-Analysis.md Fix 2 (lines 1146-1157) after the `ContextForDocument` interface definition (after `ContextForDocument`). The interface definition must include the complete JSDoc comment explaining that `files_to_generate` is NOT in header_context, that it's defined in the EXECUTE recipe step's outputs_required, and that `context_for_documents` is filled by PLAN job agent with alignment details. Note that `review_metadata` is stage-specific (only Antithesis) and is not part of the base `HeaderContext` interface - it should be handled separately in stage-specific logic if needed. Ensure the interface is exported: `export interface HeaderContext { system_materials: SystemMaterials; header_context_artifact: HeaderContextArtifact; context_for_documents: ContextForDocument[]; }`
        *   `[âœ…]` 18.b.v. Add `context_for_documents?: ContextForDocument[]` as an optional field to the `DialecticPlanJobPayload` interface (around line 682-684) so planners can pass it in PLAN job payloads. This ensures `assemblePlannerPrompt` can access `context_for_documents` from the job payload. The interface currently only extends `DialecticBaseJobPayload` and has `job_type: JobType`. Update it to: `export interface DialecticPlanJobPayload extends DialecticBaseJobPayload { job_type: JobType; context_for_documents?: ContextForDocument[]; }`
    *   `[âœ…]` 18.c. `[LINT]` Run the linter for `supabase/functions/dialectic-service/dialectic.interface.ts` and resolve any warnings or errors. Verify that all three types are properly exported and can be imported by other files.

*   `[âœ…]` 19. **`[DB]` Fix Thesis Stage Migration - Verify and Fix Structure Matching Between PLAN and EXECUTE Steps**
    *   `[âœ…]` 19.a. `[DEPS]` The Thesis stage migration file `supabase/migrations/20251006194531_thesis_stage.sql` has PLAN steps with `context_for_documents` and EXECUTE steps with `files_to_generate`. According to Recipe-Planner-Gap-Analysis.md Gap 9 (lines 793-850) and Gap 10 (lines 852-963), ALL recipe migrations must ensure: (1) `context_for_documents[].document_key` values exactly match `files_to_generate[].from_document_key` values for the EXECUTE steps, (2) `context_for_documents[].content_to_include` schema exactly matches `documents[].content_to_include` schema for the same `document_key`. The Thesis stage has 4 EXECUTE steps: `thesis_generate_business_case`, `thesis_generate_feature_spec`, `thesis_generate_technical_approach`, and `thesis_generate_success_metrics`. Each EXECUTE step must have its `files_to_generate[].from_document_key` match the corresponding PLAN step's `context_for_documents[].document_key`, and the `content_to_include` structures must match exactly. The migration file must be verified and any mismatches must be fixed to ensure proper PLAN â†” EXECUTE structure mapping.
    *   `[âœ…]` 19.b. `[DB]` In `supabase/migrations/20251006194531_thesis_stage.sql`, verify and fix structure matching between PLAN and EXECUTE steps.
        *   `[âœ…]` 19.b.i. For the PLAN step (lines 171-251), identify all `context_for_documents` entries and their `document_key` values: `business_case`, `feature_spec`, `technical_approach`, `success_metrics`. Document the `content_to_include` structure for each entry.
        *   `[âœ…]` 19.b.ii. For each EXECUTE step (`thesis_generate_business_case` around line 323, `thesis_generate_feature_spec` around line 485, `thesis_generate_technical_approach` around line 643, `thesis_generate_success_metrics` around line 800), verify that `files_to_generate[].from_document_key` matches the PLAN step's `context_for_documents[].document_key` for the same document. For example, `thesis_generate_business_case` EXECUTE step should have `files_to_generate` with `from_document_key: "business_case"` matching the PLAN step's `context_for_documents` entry with `document_key: "business_case"`.
        *   `[âœ…]` 19.b.iii. For each EXECUTE step, verify that `documents[].content_to_include` structure exactly matches the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Compare the structure (not values) - they must have the same keys, same nested structure, same array positions, etc. For example, if PLAN step has `{"field1": "", "field2": []}`, the EXECUTE step must have the same structure `{"field1": "", "field2": []}` (values can differ, but structure must match).
        *   `[âœ…]` 19.b.iv. Fix any mismatches found: (1) If `from_document_key` doesn't match `document_key`, update `from_document_key` to match, (2) If `content_to_include` structures don't match, update the EXECUTE step's `documents[].content_to_include` structure to exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Ensure JSON structure remains valid after changes.
        *   `[âœ…]` 19.b.v. **Fix 7: Standardize PLAN step `content_to_include` structures**: For the PLAN step's `context_for_documents` entry for `feature_spec` (line 219), change `content_to_include` from an array `[{...}]` to an object structure that conforms to the `ContentToInclude` type. The structure should be: `{"features": [{"feature_name": "", "user_stories": []}]}` (wrapping the array in an object with a `features` key). This ensures all `content_to_include` structures are objects (not arrays at top level) as required by the `ContentToInclude` type.
        *   `[âœ…]` 19.b.vi. **Fix 7: Update corresponding EXECUTE step**: For the EXECUTE step `thesis_generate_feature_spec` (around line 485), update the `documents[].content_to_include` structure to match the standardized PLAN step structure: `{"features": [{"feature_name": "", "user_stories": []}]}`. Ensure the structure exactly matches the PLAN step.
        *   `[âœ…]` 19.b.vii. **Fix 8: Standardize all EXECUTE step `content_to_include` structures**: For all 4 EXECUTE steps, ensure that `documents[].content_to_include` structures conform to the `ContentToInclude` type: (1) Must be objects (not arrays at top level), (2) All nested structures must use allowed types (string, string[], boolean, number, ContentToInclude, ContentToInclude[]), (3) Structures must exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Fix any structures that don't conform.
        *   `[âœ…]` 19.b.viii. Verify that all 4 EXECUTE steps have been checked and fixed. Document any changes made in comments if needed.
    *   `[âœ…]` 19.c. `[LINT]` Run the linter for `supabase/migrations/20251006194531_thesis_stage.sql` and resolve any warnings or errors. Verify JSON structure is valid.

*   `[âœ…]` 20. **`[DB]` Fix Antithesis Stage Migration - Fix non_functional_requirements Structure and Verify Structure Matching**
    *   `[âœ…]` 20.a. `[DEPS]` The Antithesis stage migration file `supabase/migrations/20251006194542_antithesis_stage.sql` has a PLAN step with `context_for_documents` entry for `non_functional_requirements` that uses an array of strings at the top level (e.g., `["security", "performance", ...]`) instead of an object structure. According to Recipe-Planner-Gap-Analysis.md Gap 7 (lines 736-763) and Gap 10 (lines 852-963), all `content_to_include` structures must be objects (Record<string, ...>), not arrays at the top level. This must be changed to `{"categories": ["security", "performance", ...]}` to match the unified object pattern defined by the `ContentToInclude` type. The corresponding EXECUTE step's `documents[].content_to_include` must also be updated to match this structure. Additionally, according to Gap 9 and Gap 10, ALL recipe migrations must ensure structure matching between PLAN and EXECUTE steps: `context_for_documents[].document_key` must match `files_to_generate[].from_document_key`, and `content_to_include` structures must match exactly.
    *   `[âœ…]` 20.b. `[DB]` In `supabase/migrations/20251006194542_antithesis_stage.sql`, fix the `non_functional_requirements` structure and verify structure matching.
        *   `[âœ…]` 20.b.i. Find the PLAN step's `context_for_documents` entry for `non_functional_requirements` (should be in the PLAN step around lines 448-577). Change the `content_to_include` from an array of strings (e.g., `["security", "performance", ...]`) to an object with a `categories` property: `{"categories": ["security", "performance", ...]}`. Preserve the actual category values, only change the structure from array to object. Ensure JSON structure remains valid.
        *   `[âœ…]` 20.b.ii. Find the EXECUTE step for `non_functional_requirements` (should be an EXECUTE step in the same file). Update the `documents[].content_to_include` to match the PLAN step structure: `{"categories": ["security", "performance", ...]}`. Ensure the structure exactly matches the PLAN step (same keys, same array structure within the object).
        *   `[âœ…]` 20.b.iii. For all other documents in the Antithesis stage (business_case_critique, technical_feasibility_assessment, risk_register, dependency_map, comparison_vector), verify that PLAN step's `context_for_documents[].document_key` matches EXECUTE step's `files_to_generate[].from_document_key` for each document. Verify that `content_to_include` structures match exactly between PLAN and EXECUTE steps for each `document_key`.
        *   `[âœ…]` 20.b.iv. Fix any mismatches found: (1) If `from_document_key` doesn't match `document_key`, update `from_document_key` to match, (2) If `content_to_include` structures don't match, update the EXECUTE step's `documents[].content_to_include` structure to exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Ensure JSON structure remains valid after all changes.
        *   `[âœ…]` 20.b.v. **Fix 7: Standardize all PLAN step `content_to_include` structures**: For all PLAN step `context_for_documents` entries, ensure that `content_to_include` structures conform to the `ContentToInclude` type: (1) Must be objects (not arrays at top level - `non_functional_requirements` is already fixed in 20.b.i), (2) All nested structures must use allowed types (string, string[], boolean, number, ContentToInclude, ContentToInclude[]), (3) All structures must be consistent across documents of the same type. Fix any structures that don't conform.
        *   `[âœ…]` 20.b.vi. **Fix 8: Standardize all EXECUTE step `content_to_include` structures**: For all EXECUTE steps, ensure that `documents[].content_to_include` structures conform to the `ContentToInclude` type and exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Fix any structures that don't conform.
    *   `[âœ…]` 20.c. `[LINT]` Run the linter for `supabase/migrations/20251006194542_antithesis_stage.sql` and resolve any warnings or errors. Verify JSON structure is valid.

*   `[âœ…]` 21. **`[DB]` Fix Synthesis Stage Migration - Remove files_to_generate from PLAN Steps, Add to EXECUTE Steps, and Verify Structure Matching**
    *   `[âœ…]` 21.a. `[DEPS]` The Synthesis stage migration file `supabase/migrations/20251006194549_synthesis_stage.sql` has multiple issues identified in Recipe-Planner-Gap-Analysis.md: (1) Synthesis Pairwise PLAN step (lines 247-368, specifically lines 350-367) incorrectly includes `files_to_generate`, (2) Synthesis Final Header PLAN step (lines 779-938, specifically lines 924-937) incorrectly includes `files_to_generate`, (3) Synthesis Pairwise EXECUTE step (lines 390-420) is missing `files_to_generate` - JSON ends at line 419 with just `]` closing the documents array, (4) Synthesis Final Deliverables EXECUTE steps are missing `files_to_generate`: `product_requirements` (around line 1018), `system_architecture` (around line 1070), and `tech_stack` (around line 1124). According to the conceptual model (Gap 3, Gap 6), PLAN steps should only have `context_for_documents` (which defines the document models with empty `content_to_include` objects for the agent to fill), while `files_to_generate` belongs only in EXECUTE steps (which define execution instructions). Additionally, according to Gap 9 and Gap 10, ALL recipe migrations must ensure structure matching between PLAN and EXECUTE steps.
    *   `[âœ…]` 21.b. `[DB]` In `supabase/migrations/20251006194549_synthesis_stage.sql`, remove `files_to_generate` from PLAN steps, add to EXECUTE steps, and verify structure matching.
        *   `[âœ…]` 21.b.i. For Synthesis Pairwise PLAN step (lines 247-368): Remove the `files_to_generate` array (lines 350-367) that contains entries for `synthesis_pairwise_business_case`, `synthesis_pairwise_feature_spec`, `synthesis_pairwise_technical_approach`, and `synthesis_pairwise_success_metrics`. Remove the comma before `files_to_generate` if present. Ensure the JSON structure remains valid after removal. Verify that `context_for_documents` array remains intact with proper structure.
        *   `[âœ…]` 21.b.ii. For Synthesis Final Header PLAN step (lines 779-938): Remove the `files_to_generate` array (lines 924-937) that contains entries for `product_requirements`, `system_architecture`, and `tech_stack`. Remove the comma before `files_to_generate` if present. Ensure the JSON structure remains valid after removal. Verify that `context_for_documents` array remains intact with proper structure.
        *   `[âœ…]` 21.b.iii. For Synthesis Pairwise EXECUTE step (lines 390-420): After the `documents` array closes (line 419), add a comma and then add `files_to_generate` array with entries matching the document keys in the `documents` array. Each entry must have `from_document_key` (matching the `document_key` from the documents array) and `template_filename` (matching the `template_filename` from the documents array). The structure should be: `"files_to_generate": [{"template_filename": "synthesis_pairwise_business_case.json", "from_document_key": "synthesis_pairwise_business_case"}, {"template_filename": "synthesis_pairwise_feature_spec.json", "from_document_key": "synthesis_pairwise_feature_spec"}, {"template_filename": "synthesis_pairwise_technical_approach.json", "from_document_key": "synthesis_pairwise_technical_approach"}, {"template_filename": "synthesis_pairwise_success_metrics.json", "from_document_key": "synthesis_pairwise_success_metrics"}]`. Ensure JSON structure is valid.
        *   `[âœ…]` 21.b.iv. For Synthesis Final Deliverables EXECUTE step `product_requirements` (around line 1018): After the `documents` array closes, add a comma and then add `files_to_generate` array with entry: `{"template_filename": "synthesis_product_requirements_document.md", "from_document_key": "product_requirements"}`. Verify the `template_filename` matches what's in the `documents` array. Ensure JSON structure is valid.
        *   `[âœ…]` 21.b.v. For Synthesis Final Deliverables EXECUTE step `system_architecture` (around line 1070): After the `documents` array closes, add a comma and then add `files_to_generate` array with entry: `{"template_filename": "synthesis_system_architecture.md", "from_document_key": "system_architecture"}`. Verify the `template_filename` matches what's in the `documents` array. Ensure JSON structure is valid.
        *   `[âœ…]` 21.b.vi. For Synthesis Final Deliverables EXECUTE step `tech_stack` (around line 1124): After the `documents` array closes, add a comma and then add `files_to_generate` array with entry: `{"template_filename": "synthesis_tech_stack.md", "from_document_key": "tech_stack"}`. Verify the `template_filename` matches what's in the `documents` array. Ensure JSON structure is valid.
        *   `[âœ…]` 21.b.vii. For all Synthesis PLAN and EXECUTE steps, verify that `context_for_documents[].document_key` values exactly match `files_to_generate[].from_document_key` values for the corresponding EXECUTE steps. For example, Synthesis Pairwise PLAN step has `context_for_documents` with `document_key: "synthesis_pairwise_business_case"`, and the Synthesis Pairwise EXECUTE step must have `files_to_generate` with `from_document_key: "synthesis_pairwise_business_case"`. Verify this mapping for all documents: synthesis_pairwise_business_case, synthesis_pairwise_feature_spec, synthesis_pairwise_technical_approach, synthesis_pairwise_success_metrics, product_requirements, system_architecture, tech_stack.
        *   `[âœ…]` 21.b.viii. For all Synthesis PLAN and EXECUTE steps, verify that `context_for_documents[].content_to_include` schema exactly matches `documents[].content_to_include` schema for the same `document_key`. Compare the structure (not values) - they must have the same keys, same nested structure, same array positions, etc. Fix any mismatches by updating the EXECUTE step's `documents[].content_to_include` structure to exactly match the PLAN step's `context_for_documents[].content_to_include` structure.
        *   `[âœ…]` 21.b.ix. **Fix 7: Standardize all Synthesis PLAN step `content_to_include` structures**: For all PLAN step `context_for_documents` entries (Pairwise and Final Header), ensure that `content_to_include` structures conform to the `ContentToInclude` type: (1) Must be objects (not arrays at top level), (2) All nested structures must use allowed types (string, string[], boolean, number, ContentToInclude, ContentToInclude[]), (3) All structures must be consistent across documents of the same type. Fix any structures that don't conform.
        *   `[âœ…]` 21.b.x. **Fix 8: Standardize all Synthesis EXECUTE step `content_to_include` structures**: For all EXECUTE steps (Pairwise, Document-level, and Final Deliverables), ensure that `documents[].content_to_include` structures conform to the `ContentToInclude` type and exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Fix any structures that don't conform.
    *   `[âœ…]` 21.c. `[LINT]` Run the linter for `supabase/migrations/20251006194549_synthesis_stage.sql` and resolve any warnings or errors. Verify JSON structure is valid for all steps.

*   `[âœ…]` 22. **`[DB]` Fix Parenthesis Stage Migration - Verify and Fix Structure Matching Between PLAN and EXECUTE Steps**
    *   `[âœ…]` 22.a. `[DEPS]` The Parenthesis stage migration file `supabase/migrations/20251006194558_parenthesis_stage.sql` has PLAN steps with `context_for_documents` and EXECUTE steps with `files_to_generate`. According to Recipe-Planner-Gap-Analysis.md Gap 9 (lines 793-850) and Gap 10 (lines 852-963), ALL recipe migrations must ensure: (1) `context_for_documents[].document_key` values exactly match `files_to_generate[].from_document_key` values for the EXECUTE steps, (2) `context_for_documents[].content_to_include` schema exactly matches `documents[].content_to_include` schema for the same `document_key`. The Parenthesis stage has 3 EXECUTE steps: `parenthesis_generate_technical_requirements`, `parenthesis_generate_master_plan`, and `parenthesis_generate_milestone_schema`. Each EXECUTE step must have its `files_to_generate[].from_document_key` match the corresponding PLAN step's `context_for_documents[].document_key`, and the `content_to_include` structures must match exactly.
    *   `[âœ…]` 22.b. `[DB]` In `supabase/migrations/20251006194558_parenthesis_stage.sql`, verify and fix structure matching between PLAN and EXECUTE steps.
        *   `[âœ…]` 22.b.i. For the PLAN step (lines 271-393), identify all `context_for_documents` entries and their `document_key` values: `technical_requirements`, `master_plan`, `milestone_schema`. Document the `content_to_include` structure for each entry.
        *   `[âœ…]` 22.b.ii. For each EXECUTE step (`parenthesis_generate_technical_requirements` around line 647, `parenthesis_generate_master_plan` around line 800, `parenthesis_generate_milestone_schema` around line 950), verify that `files_to_generate[].from_document_key` matches the PLAN step's `context_for_documents[].document_key` for the same document. For example, `parenthesis_generate_technical_requirements` EXECUTE step should have `files_to_generate` with `from_document_key: "technical_requirements"` matching the PLAN step's `context_for_documents` entry with `document_key: "technical_requirements"`.
        *   `[âœ…]` 22.b.iii. For each EXECUTE step, verify that `documents[].content_to_include` structure exactly matches the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Compare the structure (not values) - they must have the same keys, same nested structure, same array positions, etc. For example, if PLAN step has `{"array_field": [], "string_field": "", "nested_object": {}}`, the EXECUTE step must have the same structure (values can differ, but structure must match).
        *   `[âœ…]` 22.b.iv. Fix any mismatches found: (1) If `from_document_key` doesn't match `document_key`, update `from_document_key` to match, (2) If `content_to_include` structures don't match, update the EXECUTE step's `documents[].content_to_include` structure to exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Ensure JSON structure remains valid after changes.
        *   `[âœ…]` 22.b.v. **Fix 7: Standardize all Parenthesis PLAN step `content_to_include` structures**: For all PLAN step `context_for_documents` entries, ensure that `content_to_include` structures conform to the `ContentToInclude` type: (1) Must be objects (not arrays at top level), (2) All nested structures must use allowed types (string, string[], boolean, number, ContentToInclude, ContentToInclude[]), (3) All structures must be consistent across documents of the same type. Fix any structures that don't conform.
        *   `[âœ…]` 22.b.vi. **Fix 8: Standardize all Parenthesis EXECUTE step `content_to_include` structures**: For all EXECUTE steps, ensure that `documents[].content_to_include` structures conform to the `ContentToInclude` type and exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Fix any structures that don't conform.
        *   `[âœ…]` 22.b.vii. Verify that all 3 EXECUTE steps have been checked and fixed. Document any changes made in comments if needed.
    *   `[âœ…]` 22.c. `[LINT]` Run the linter for `supabase/migrations/20251006194558_parenthesis_stage.sql` and resolve any warnings or errors. Verify JSON structure is valid.

*   `[âœ…]` 23. **`[DB]` Fix Paralysis Stage Migration - Add content_to_include to EXECUTE Step and Verify Structure Matching**
    *   `[âœ…]` 23.a. `[DEPS]` The Paralysis stage migration file `supabase/migrations/20251006194605_paralysis_stage.sql` has an EXECUTE step for `actionable_checklist` (lines 458-486) where the `documents` array entry is missing the `content_to_include` field. According to Recipe-Planner-Gap-Analysis.md Gap 8 (lines 764-791), EXECUTE step `documents[].content_to_include` must exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key` to enable proper mapping. The PLAN step (lines 293-315) has `context_for_documents` with `actionable_checklist` entry that includes `content_to_include: {"action_items": ["..."]}`. The EXECUTE step must have the same structure. Additionally, according to Gap 9 and Gap 10, ALL recipe migrations must ensure structure matching between PLAN and EXECUTE steps for all documents: `context_for_documents[].document_key` must match `files_to_generate[].from_document_key`, and `content_to_include` structures must match exactly.
    *   `[âœ…]` 23.b. `[DB]` In `supabase/migrations/20251006194605_paralysis_stage.sql`, add `content_to_include` to the EXECUTE step and verify structure matching.
        *   `[âœ…]` 23.b.i. Find the EXECUTE step for `actionable_checklist` (lines 458-486). Locate the `documents` array entry (should be around lines 461-464 based on the analysis).
        *   `[âœ…]` 23.b.ii. Add `content_to_include` field to the document entry. The structure must exactly match the PLAN step's `context_for_documents` entry for `actionable_checklist`. Based on the PLAN step (lines 293-315), it should be: `"content_to_include": {"action_items": ["..."]}`. Use the same structure as the PLAN step (empty array or placeholder values are acceptable for the migration - the actual values will be filled by the agent during execution). Ensure proper comma placement and JSON structure validity.
        *   `[âœ…]` 23.b.iii. For all documents in the Paralysis stage (actionable_checklist, updated_master_plan, advisor_recommendations), verify that PLAN step's `context_for_documents[].document_key` matches EXECUTE step's `files_to_generate[].from_document_key` for each document. Verify that `content_to_include` structures match exactly between PLAN and EXECUTE steps for each `document_key`.
        *   `[âœ…]` 23.b.iv. Fix any mismatches found: (1) If `from_document_key` doesn't match `document_key`, update `from_document_key` to match, (2) If `content_to_include` structures don't match, update the EXECUTE step's `documents[].content_to_include` structure to exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Ensure JSON structure remains valid after all changes.
        *   `[âœ…]` 23.b.v. **Fix 7: Standardize all Paralysis PLAN step `content_to_include` structures**: For all PLAN step `context_for_documents` entries, ensure that `content_to_include` structures conform to the `ContentToInclude` type: (1) Must be objects (not arrays at top level), (2) All nested structures must use allowed types (string, string[], boolean, number, ContentToInclude, ContentToInclude[]), (3) All structures must be consistent across documents of the same type. Fix any structures that don't conform.
        *   `[âœ…]` 23.b.vi. **Fix 8: Standardize all Paralysis EXECUTE step `content_to_include` structures**: For all EXECUTE steps, ensure that `documents[].content_to_include` structures conform to the `ContentToInclude` type and exactly match the PLAN step's `context_for_documents[].content_to_include` structure for the same `document_key`. Fix any structures that don't conform.
    *   `[âœ…]` 23.c. `[LINT]` Run the linter for `supabase/migrations/20251006194605_paralysis_stage.sql` and resolve any warnings or errors. Verify JSON structure is valid.

*   `[âœ…]` 24. **`[BE]` Fix isHeaderContext Type Guard and Tests in type_guards.dialectic.ts, and Define isContentToInclude Helper Function**
    *   `[âœ…]` 24.a. `[DEPS]` The type guard `isHeaderContext` in `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.ts` (lines 182-205) currently validates `files_to_generate` as optional (lines 197-202), but according to the new `HeaderContext` interface defined in step 18, `files_to_generate` should NOT be in `HeaderContext` at all (it's in recipe step, not header context). The type guard must be updated to match the new interface structure. The function signature uses `ReturnType<typeof JSON.parse>` which is not type-safe. The type guard should import `HeaderContext` from `../../dialectic-service/dialectic.interface.ts` and use it in the return type annotation. Additionally, steps 25, 27-32 require a helper function `isContentToInclude(value: unknown): value is ContentToInclude` to validate that `content_to_include` structures conform to the `ContentToInclude` type. This helper must be defined in the same file (`type_guards.dialectic.ts`) and exported so it can be imported by `assembleTurnPrompt` and all planner functions. The test file `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.test.ts` must be updated to test both the new `isHeaderContext` structure and the new `isContentToInclude` helper function. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 24.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.test.ts`, write tests for `isHeaderContext` that verify it matches the new `HeaderContext` interface structure.
        *   `[âœ…]` 24.b.i. Create a test case that asserts `isHeaderContext` returns `true` for a valid `HeaderContext` object with: `system_materials` (valid `SystemMaterials`), `header_context_artifact` (valid `HeaderContextArtifact`), and `context_for_documents` (array of valid `ContextForDocument` objects with `ContentToInclude` structures). This test must pass after the type guard is updated.
        *   `[âœ…]` 24.b.ii. Create a test case that asserts `isHeaderContext` returns `false` for an object that has `files_to_generate` property (since `HeaderContext` interface does not include `files_to_generate`). This test must fail initially because the current type guard allows `files_to_generate` as optional, but should pass after the type guard is updated to reject it.
        *   `[âœ…]` 24.b.iii. Create a test case that asserts `isHeaderContext` returns `false` for an object missing `system_materials`. This test should pass with the current type guard.
        *   `[âœ…]` 24.b.iv. Create a test case that asserts `isHeaderContext` returns `false` for an object missing `header_context_artifact`. This test should pass with the current type guard.
        *   `[âœ…]` 24.b.v. Create a test case that asserts `isHeaderContext` returns `false` for an object missing `context_for_documents`. This test should pass with the current type guard.
        *   `[âœ…]` 24.b.vi. Create a test case that asserts `isHeaderContext` returns `false` for an object where `context_for_documents` is not an array. This test should pass with the current type guard.
        *   `[âœ…]` 24.b.vii. Create a test case that asserts `isHeaderContext` returns `false` for an object where `context_for_documents` contains invalid entries (missing `document_key` or invalid `content_to_include` structure). This test should pass with the current type guard if it validates structure.
        *   `[âœ…]` 24.b.viii. `[TEST-UNIT]` **RED**: Write tests for `isContentToInclude` helper function that will be defined in step 24.c.vi. Create test cases that verify: (1) `isContentToInclude` returns `true` for valid `ContentToInclude` objects (simple objects with string values like `{"field1": "", "field2": ""}`, objects with string arrays like `{"field1": [], "field2": ["value1", "value2"]}`, objects with nested objects like `{"dimensions": {"feasibility": {"score": 0, "rationale": ""}}}`, objects with arrays of objects like `{"features": [{"name": "", "stories": []}]}`, mixed structures combining all types), (2) `isContentToInclude` returns `false` for arrays at top level (must be objects, not arrays - e.g., `["string1", "string2"]` should fail), (3) `isContentToInclude` returns `false` for invalid value types (functions, null, undefined as top-level value in object), (4) `isContentToInclude` correctly validates nested structures recursively (deeply nested objects and arrays of objects). These tests must fail initially because the function doesn't exist yet.
    *   `[âœ…]` 24.c. `[BE]` **GREEN**: In `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.ts`, update the `isHeaderContext` function to match the new `HeaderContext` interface and define the `isContentToInclude` helper function.
        *   `[âœ…]` 24.c.i. Import `HeaderContext` from `../../../dialectic-service/dialectic.interface.ts` at the top of the file (the file is at `supabase/functions/_shared/utils/type-guards/`, so it needs three levels up to reach `dialectic-service`).
        *   `[âœ…]` 24.c.ii. Update the function signature (line 182) from `export function isHeaderContext(value: unknown): value is ReturnType<typeof JSON.parse>` to `export function isHeaderContext(value: unknown): value is HeaderContext`.
        *   `[âœ…]` 24.c.iii. Remove the `files_to_generate` validation block (lines 197-202) entirely, since `HeaderContext` interface does not include this property.
        *   `[âœ…]` 24.c.iv. Ensure the validation for `system_materials`, `header_context_artifact`, and `context_for_documents` remains intact (lines 185-195). These validations should continue to work correctly.
        *   `[âœ…]` 24.c.v. Verify the function still returns `true` only when all required fields are present and valid.
        *   `[âœ…]` 24.c.vi. Import `ContentToInclude` from `../../../dialectic-service/dialectic.interface.ts` at the top of the file (same import path as `HeaderContext`).
        *   `[âœ…]` 24.c.vii. Define and export the `isContentToInclude` helper function: `export function isContentToInclude(value: unknown): value is ContentToInclude`. The function must: (1) Check that value is an object using `isRecord(value)` helper (import from `../type_guards.ts` if needed), (2) Check that value is NOT an array at top level using `!Array.isArray(value)` - if it's an array, return `false`, (3) Recursively validate that all values in the object are allowed types according to the `ContentToInclude` type definition: `string`, `string[]`, `boolean`, `number`, or recursively `ContentToInclude`/`ContentToInclude[]`. For each key-value pair in the object: (a) If value is `string`, `boolean`, or `number`, it's valid, (b) If value is an array, check if it's `string[]` (all elements are strings) or `ContentToInclude[]` (all elements pass `isContentToInclude` recursively), (c) If value is an object, recursively call `isContentToInclude(value)` to validate nested structures, (d) If value is any other type (function, null, undefined, etc.), return `false`. The function must handle all cases from the `ContentToInclude` type definition: `Record<string, string | string[] | boolean | number | ContentToInclude | ContentToInclude[]>`. Export the function so it can be imported by `assembleTurnPrompt` (step 25) and all planner functions (steps 27-32).
    *   `[âœ…]` 24.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 24.b (including 24.b.viii for `isContentToInclude`) and ensure they now pass. The test from 24.b.ii should now pass because the type guard rejects `files_to_generate`. Also verify that existing `isHeaderContext` tests still pass. Verify that all `isContentToInclude` tests from 24.b.viii pass.
    *   `[âœ…]` 24.e. `[LINT]` Run the linter for `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.ts` and `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 25. **`[BE]` Fix assembleTurnPrompt to Read files_to_generate from Recipe Step and Use header_context for Alignment, and Tests**
    *   `[âœ…]` 25.a. `[DEPS]` The `assembleTurnPrompt` function in `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` currently has incorrect logic (lines 152-159) that looks for `files_to_generate` in `headerContext` and uses `document_key` instead of `from_document_key`. According to Recipe-Planner-Gap-Analysis.md Fix 1 (lines 1026-1082) and Gap 1 (lines 615-632) and Gap 2 (lines 634-651), the function must: (1) read `files_to_generate` from `stage.recipe_step.outputs_required.files_to_generate` (execution instructions), (2) use `header_context.context_for_documents` for cross-document alignment details (completed by PLAN job), (3) match `files_to_generate[].from_document_key` to `header_context.context_for_documents[].document_key`, (4) use the matched entry's `content_to_include` for document generation, (5) validate that `content_to_include` is filled (not empty). The function also imports `HeaderContext` from `dialectic.interface.ts` (line 9), which should now work correctly after step 18 defines the interface. The test file `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.test.ts` must be updated to test the new behavior. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 25.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.test.ts`, write tests that verify `assembleTurnPrompt` reads `files_to_generate` from recipe step and uses `header_context.context_for_documents` for alignment.
        *   `[âœ…]` 25.b.i. Create a test case that mocks `stage.recipe_step.outputs_required.files_to_generate` with an array containing `{from_document_key: "business_case", template_filename: "thesis_business_case.md"}`, mocks `headerContext.context_for_documents` with an array containing `{document_key: "business_case", content_to_include: {"field1": "value1"}}`, and asserts that `assembleTurnPrompt` successfully finds the document info using `from_document_key` matching `document_key`, and uses the `content_to_include` from `context_for_documents` for alignment. This test must fail because the function currently looks for `files_to_generate` in `headerContext` and uses `document_key` instead of `from_document_key`.
        *   `[âœ…]` 25.b.ii. Create a test case that mocks `stage.recipe_step.outputs_required` missing `files_to_generate`, and asserts that `assembleTurnPrompt` throws an error with message indicating `files_to_generate` is missing from recipe step. This test must fail because the function currently doesn't check for `files_to_generate` in recipe step.
        *   `[âœ…]` 25.b.iii. Create a test case that mocks `headerContext` missing `context_for_documents`, and asserts that `assembleTurnPrompt` throws an error indicating `context_for_documents` is missing from header context. This test must fail because the function currently doesn't validate `context_for_documents` exists.
        *   `[âœ…]` 25.b.iv. Create a test case that mocks `files_to_generate` with `from_document_key: "business_case"` but `headerContext.context_for_documents` has no entry with `document_key: "business_case"`, and asserts that `assembleTurnPrompt` throws an error indicating no matching `context_for_documents` entry found. This test must fail because the function currently doesn't perform this matching.
        *   `[âœ…]` 25.b.v. Create a test case that mocks `context_for_documents` entry with empty `content_to_include` object (`{}`), and asserts that `assembleTurnPrompt` throws an error indicating `content_to_include` is not filled in. This test must fail because the function currently doesn't validate that `content_to_include` is filled.
        *   `[âœ…]` 25.b.vi. Create a test case that verifies `assembleTurnPrompt` uses `docInfo.template_filename` from the matched `files_to_generate` entry (not from `headerContext`). This test must fail because the function currently gets template filename from the wrong location.
        *   `[âœ…]` 25.b.vii. Create a test case that mocks `files_to_generate` with `from_document_key: "business_case"` but the matched `context_for_documents` entry has a `content_to_include` structure that doesn't match the `ContentToInclude` type schema (e.g., has invalid nested structure), and asserts that `assembleTurnPrompt` throws an error indicating structure mismatch. This test must fail because the function currently doesn't validate structure matching.
        *   `[âœ…]` 25.b.viii. Create a test case that verifies `contextForDoc.content_to_include` is merged into the `renderContext` object passed to `renderPrompt`, ensuring alignment details are available in the template context. This test must fail because the function currently doesn't merge alignment details into render context.
    *   `[âœ…]` 25.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts`, rewrite the logic to read `files_to_generate` from recipe step and use `header_context.context_for_documents` for alignment.
        *   `[âœ…]` 25.c.i. Implement the logic described in Recipe-Planner-Gap-Analysis.md Fix 1 (lines 1050-1082) as a specification: Get `files_to_generate` from `stage.recipe_step.outputs_required?.files_to_generate`, validate it exists and is an array, find the document info using `from_document_key` matching `documentKey`, get alignment details from `headerContext.context_for_documents` by matching `document_key`, validate that `content_to_include` is filled (not empty), and use `docInfo.template_filename` for template file and `contextForDoc.content_to_include` for alignment details in prompt. Do not copy-paste pseudocode - implement the actual TypeScript logic following the specification.
        *   `[âœ…]` 25.c.ii. **Fix 9: Add runtime validation that verifies PLAN â†” EXECUTE structure mapping**: (1) Validate that `files_to_generate[].from_document_key` matches `headerContext.context_for_documents[].document_key` for the matched entry. (2) **Validate `content_to_include` structure conforms to `ContentToInclude` type**: Import the `isContentToInclude` helper function from `../../utils/type-guards/type_guards.dialectic.ts` (defined in step 24.c.vii) and use it to validate that `contextForDoc.content_to_include` conforms to the `ContentToInclude` type. (3) **Validate structure matching**: Compare the structure (not values) of `contextForDoc.content_to_include` with the expected structure from the recipe step's `documents[].content_to_include` for the same `document_key` - they must have the same keys, same nested structure, same array positions. Use the `isHeaderContext` type guard (from Step 24) to validate the header context structure at runtime. If structure mismatch is detected, throw an error indicating the mapping violation: `assembleTurnPrompt requires content_to_include structure for document_key '${documentKey}' to match the recipe step's expected structure`. **Note**: Per Fix 9 (line 1394), structure matching validation is optional and may be better performed here where `header_context` is already loaded, rather than in planners.
        *   `[âœ…]` 25.c.iii. Update any subsequent code that uses `docInfo` to ensure it uses `docInfo.template_filename` (which now comes from recipe step, not header context).
        *   `[âœ…]` 25.c.iv. Merge `contextForDoc.content_to_include` into the prompt context by adding it to the `renderContext` object that is passed to `renderPrompt`. The `content_to_include` object should be merged into `renderContext` so that template variables can access the alignment details. Ensure the merge happens after `system_materials` and `user_domain_overlay_values` but before `document_specific_data`, so alignment details can be overridden by document-specific data if needed.
        *   `[âœ…]` 25.c.v. Verify the `HeaderContext` import now resolves correctly after step 18 defines the interface.
    *   `[âœ…]` 25.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 25.b and ensure they now pass. Also verify that existing `assembleTurnPrompt` tests still pass (update any tests that mock `headerContext.files_to_generate` to instead mock `stage.recipe_step.outputs_required.files_to_generate`).
    *   `[âœ…]` 25.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.ts` and `supabase/functions/_shared/prompt-assembler/assembleTurnPrompt.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 26. **`[BE]` Fix assemblePlannerPrompt to Include context_for_documents in PLAN Prompts, and Tests**
    *   `[âœ…]` 26.a. `[DEPS]` The `assemblePlannerPrompt` function in `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.ts` must include `context_for_documents` in PLAN prompts so the agent knows what alignment details to produce. According to Recipe-Planner-Gap-Analysis.md Fix 6 (lines 1261-1271), the function must: (1) extract `context_for_documents` from `recipe_step.outputs_required`, (2) include the empty `content_to_include` object models in the prompt, (3) instruct the agent to fill in these models with specific alignment values, (4) structure the prompt to ensure the agent produces `header_context` with completed `content_to_include` objects. The test file `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.test.ts` must be updated to test the new behavior. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 26.b. `[TEST-UNIT]` **RED**: In `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.test.ts`, write tests that verify `assemblePlannerPrompt` includes `context_for_documents` in PLAN prompts.
        *   `[âœ…]` 26.b.i. Create a test case that mocks a PLAN job with `recipe_step.outputs_required.context_for_documents` containing entries with empty `content_to_include` object models, and asserts that `assemblePlannerPrompt` includes these `context_for_documents` in the generated prompt. This test must fail if the function doesn't currently include `context_for_documents`.
        *   `[âœ…]` 26.b.ii. Create a test case that asserts the prompt includes instructions telling the agent to fill in the `content_to_include` objects with specific alignment values. This test must fail if the function doesn't currently include such instructions.
        *   `[âœ…]` 26.b.iii. Create a test case that mocks `recipe_step.outputs_required` missing `context_for_documents`, and asserts that `assemblePlannerPrompt` throws an error indicating `context_for_documents` is required for PLAN jobs. This test must fail if the function doesn't currently validate this.
    *   `[âœ…]` 26.c. `[BE]` **GREEN**: In `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.ts`, update the function to include `context_for_documents` in PLAN prompts.
        *   `[âœ…]` 26.c.i. Read the current implementation to understand how it assembles PLAN prompts.
        *   `[âœ…]` 26.c.ii. Extract `context_for_documents` from `recipe_step.outputs_required.context_for_documents` (validate it exists and is an array).
        *   `[âœ…]` 26.c.iii. Include the `context_for_documents` structure (with empty `content_to_include` object models) in the prompt that is sent to the agent.
        *   `[âœ…]` 26.c.iv. Add instructions in the prompt telling the agent to: (1) fill in the `content_to_include` objects with specific alignment values (shared terminology, consistent values, coordinated decisions), (2) produce a `header_context` artifact with completed `content_to_include` objects, (3) ensure all documents in the step group will use these alignment details.
        *   `[âœ…]` 26.c.v. Ensure the prompt structure clearly separates the empty models (what the agent should fill) from other prompt content.
    *   `[âœ…]` 26.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 26.b and ensure they now pass. Also verify that existing `assemblePlannerPrompt` tests still pass.
    *   `[âœ…]` 26.e. `[LINT]` Run the linter for `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.ts` and `supabase/functions/_shared/prompt-assembler/assemblePlannerPrompt.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 27. **`[BE]` Fix planAllToOne to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 27.a. `[DEPS]` The `planAllToOne` planner function in `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` currently does not validate or pass `context_for_documents` for PLAN jobs, and does not validate `files_to_generate` for EXECUTE jobs. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** According to Recipe-Planner-Gap-Analysis.md Fix 3 (lines 1179-1210) and Fix 4 (lines 1213-1244), when `job_type === 'PLAN'`, the planner MUST ALWAYS: (1) validate that `recipe_step.outputs_required.context_for_documents` exists and is an array with entries (this is REQUIRED, not optional), (2) validate that each entry has a `document_key` and an empty `content_to_include` object model (not an array at top level), (3) pass the entire `context_for_documents` structure into the job payload so the prompt assembler can include it. When `job_type === 'EXECUTE'`, the planner MUST ALWAYS: (1) validate that `recipe_step.outputs_required.files_to_generate` exists and is an array with entries (this is REQUIRED, not optional), (2) validate that `recipe_step.outputs_required.documents` exists and is an array with entries (this is REQUIRED, not optional), (3) validate structure (each `files_to_generate` entry has `from_document_key` and `template_filename`). The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 44-74) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with the planner function name (e.g., 'planAllToOne requires...') to aid debugging. The test file `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 27.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts`, write tests that verify `planAllToOne` validates and passes `context_for_documents` for PLAN jobs and validates `files_to_generate` for EXECUTE jobs.
        *   `[âœ…]` 27.b.i. Create a test case that mocks a PLAN job with `recipe_step.outputs_required.context_for_documents` containing valid entries, and asserts that `planAllToOne` successfully creates a job payload that includes `context_for_documents`. This test must fail because the function currently doesn't handle `context_for_documents`.
        *   `[âœ…]` 27.b.ii. Create a test case that mocks a PLAN job with `recipe_step.outputs_required` missing `context_for_documents`, and asserts that `planAllToOne` throws an error indicating `context_for_documents` is required for PLAN jobs. This test must fail because the function currently doesn't validate this.
        *   `[âœ…]` 27.b.iii. Create a test case that mocks a PLAN job with `context_for_documents` entry missing `document_key`, and asserts that `planAllToOne` throws an error indicating `document_key` is missing. This test must fail because the function currently doesn't validate structure.
        *   `[âœ…]` 27.b.iv. Create a test case that mocks a PLAN job with `context_for_documents` entry missing `content_to_include`, and asserts that `planAllToOne` throws an error indicating `content_to_include` object model is missing. This test must fail because the function currently doesn't validate structure.
        *   `[âœ…]` 27.b.v. Create a test case that mocks an EXECUTE job with `recipe_step.outputs_required.files_to_generate` containing valid entries, and asserts that `planAllToOne` successfully creates a job payload. This test should pass if the function doesn't currently validate (it just doesn't check), but will need to pass after validation is added.
        *   `[âœ…]` 27.b.vi. Create a test case that mocks an EXECUTE job with `recipe_step.outputs_required` missing `files_to_generate`, and asserts that `planAllToOne` throws an error indicating `files_to_generate` is required for EXECUTE jobs. This test must fail because the function currently doesn't validate this.
        *   `[âœ…]` 27.b.vii. Create a test case that mocks an EXECUTE job with `files_to_generate` entry missing `from_document_key`, and asserts that `planAllToOne` throws an error indicating `from_document_key` is missing. This test must fail because the function currently doesn't validate structure.
        *   `[âœ…]` 27.b.viii. Create a test case that mocks an EXECUTE job with `files_to_generate` entry missing `template_filename`, and asserts that `planAllToOne` throws an error indicating `template_filename` is missing. This test must fail because the function currently doesn't validate structure.
    *   `[âœ…]` 27.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts`, add validation and passing of `context_for_documents` for PLAN jobs and validation of `files_to_generate` for EXECUTE jobs.
        *   `[âœ…]` 27.c.i. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file.
        *   `[âœ…]` 27.c.ii. Before creating `newPayload` (line 44), validate that `recipeStep.job_type` is either `'PLAN'` or `'EXECUTE'`. If it's neither, throw an error: `planAllToOne requires job_type to be 'PLAN' or 'EXECUTE', received: ${recipeStep.job_type}`.
        *   `[âœ…]` 27.c.iii. Add a check for `recipeStep.job_type === 'PLAN'`. If true, implement the validation pattern from Recipe-Planner-Gap-Analysis.md Fix 3 (lines 1192-1206): validate that `context_for_documents` exists, is an array, and has entries (`contextForDocuments.length > 0`); validate that each entry has `document_key` (non-empty string) and `content_to_include` object model (must be an object, not an array at top level - use `Array.isArray()` check and throw error if array); **validate `content_to_include` structure conforms to `ContentToInclude` type**: Import the `isContentToInclude` helper function from `../../_shared/utils/type-guards/type_guards.dialectic.ts` (defined in step 24.c.vii) and use it to validate that each `content_to_include` entry conforms to the type (object, not array at top level, all values are allowed types). Include `context_for_documents` in the job payload structure so `assemblePlannerPrompt` can access it. All error messages must be prefixed with 'planAllToOne requires...'. Ensure the validation happens before creating the job payload, so invalid PLAN jobs fail early.
        *   `[âœ…]` 27.c.iv. After the PLAN job validation, add a check for `recipeStep.job_type === 'EXECUTE'`. If true, implement the validation pattern from Recipe-Planner-Gap-Analysis.md Fix 4 (lines 1226-1240): validate that `files_to_generate` exists, is an array, and has entries (`filesToGenerate.length > 0`); validate that each entry has `from_document_key` (non-empty string) and `template_filename` (non-empty string). All error messages must be prefixed with 'planAllToOne requires...'. Ensure the validation happens before creating the job payload, so invalid EXECUTE jobs fail early.
        *   `[âœ…]` 27.c.v. Ensure the existing `document_key` extraction logic (lines 44-74) still works correctly and is not affected by the new validation logic.
        *   `[âœ…]` 27.c.vi. The `DialecticPlanJobPayload` interface was already updated in step 18.b.v to include `context_for_documents?: ContextForDocument[]`. Use this field when creating PLAN job payloads by adding `context_for_documents` to the payload object when `job_type === 'PLAN'`.
        *   `[âœ…]` 27.c.vii. **Fix 9: Validate PLAN â†” EXECUTE structure mapping**: When creating EXECUTE jobs, validate that each `files_to_generate[].from_document_key` matches a `document_key` in the PLAN step's `context_for_documents`. If the planner has access to the PLAN step's `context_for_documents` (via recipe step lookup or parent job context), add validation: for each `file` in `filesToGenerate`, check if `file.from_document_key` exists in the PLAN step's `context_for_documents[].document_key` array. If no match is found, throw an error: `planAllToOne requires files_to_generate[].from_document_key '${file.from_document_key}' to match a document_key in the PLAN step's context_for_documents`. **Note**: This validation requires access to the PLAN step's `context_for_documents`. If the planner doesn't have direct access (e.g., needs to fetch from database), this validation is deferred to `assembleTurnPrompt` where `header_context` is already loaded (as noted in Fix 9 line 1394). The validation in `assembleTurnPrompt` (step 25.c.ii) will catch any mismatches at runtime.
    *   `[âœ…]` 27.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 27.b and ensure they now pass. Also verify that existing `planAllToOne` tests still pass.
    *   `[âœ…]` 27.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.ts` and `supabase/functions/dialectic-worker/strategies/planners/planAllToOne.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 28. **`[BE]` Fix planPairwiseByOrigin to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 28.a. `[DEPS]` The `planPairwiseByOrigin` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` needs the same updates as `planAllToOne` from step 27. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 56-86) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with 'planPairwiseByOrigin requires...' instead of 'planAllToOne requires...'. The test file `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 28.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts`, write the same eight test cases as step 27.b (four for PLAN jobs, four for EXECUTE jobs), but with error messages prefixed with `"planPairwiseByOrigin"` instead of `"planAllToOne"`.
    *   `[âœ…]` 28.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts`, add the same validation pattern as step 27.c (27.c.i through 27.c.vii), but with error messages prefixed with `"planPairwiseByOrigin requires"` instead of `"planAllToOne requires"`. Use `'PLAN'` and `'EXECUTE'` (uppercase) for job_type comparisons. Validate empty arrays explicitly (`array.length > 0`). Validate that `content_to_include` is an object, not an array at top level. Include `content_to_include` structure validation using the same `isContentToInclude` helper as step 27.c.iii.
    *   `[âœ…]` 28.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 28.b and ensure they now pass. Also verify that existing `planPairwiseByOrigin` tests still pass.
    *   `[âœ…]` 28.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPairwiseByOrigin.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 29. **`[BE]` Fix planPerModel to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 29.a. `[DEPS]` The `planPerModel` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` needs the same updates as `planAllToOne` from step 27. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 76-106) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with 'planPerModel requires...' instead of 'planAllToOne requires...'. The test file `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 29.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts`, write the same eight test cases as step 27.b (four for PLAN jobs, four for EXECUTE jobs), but with error messages prefixed with `"planPerModel"` instead of `"planAllToOne"`.
    *   `[âœ…]` 29.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts`, add the same validation pattern as step 27.c (27.c.i through 27.c.vii), but with error messages prefixed with `"planPerModel requires"` instead of `"planAllToOne requires"`. Use `'PLAN'` and `'EXECUTE'` (uppercase) for job_type comparisons. Validate empty arrays explicitly (`array.length > 0`). Validate that `content_to_include` is an object, not an array at top level. Include `content_to_include` structure validation using the same `isContentToInclude` helper as step 27.c.iii.
    *   `[âœ…]` 29.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 29.b and ensure they now pass. Also verify that existing `planPerModel` tests still pass.
    *   `[âœ…]` 29.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerModel.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerModel.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 30. **`[BE]` Fix planPerSourceDocument to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 30.a. `[DEPS]` The `planPerSourceDocument` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` needs the same updates as `planAllToOne` from step 27. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 66-96) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with 'planPerSourceDocument requires...' instead of 'planAllToOne requires...'. The test file `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 30.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts`, write the same eight test cases as step 27.b (four for PLAN jobs, four for EXECUTE jobs), but with error messages prefixed with `"planPerSourceDocument"` instead of `"planAllToOne"`.
    *   `[âœ…]` 30.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts`, add the same validation pattern as step 27.c (27.c.i through 27.c.vii), but with error messages prefixed with `"planPerSourceDocument requires"` instead of `"planAllToOne requires"`. Use `'PLAN'` and `'EXECUTE'` (uppercase) for job_type comparisons. Validate empty arrays explicitly (`array.length > 0`). Validate that `content_to_include` is an object, not an array at top level. Include `content_to_include` structure validation using the same `isContentToInclude` helper as step 27.c.iii.
    *   `[âœ…]` 30.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 30.b and ensure they now pass. Also verify that existing `planPerSourceDocument` tests still pass.
    *   `[âœ…]` 30.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocument.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 31. **`[BE]` Fix planPerSourceDocumentByLineage to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 31.a. `[DEPS]` The `planPerSourceDocumentByLineage` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` needs the same updates as `planAllToOne` from step 27. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 54-84) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with 'planPerSourceDocumentByLineage requires...' instead of 'planAllToOne requires...'. The test file `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 31.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts`, write the same eight test cases as step 27.b (four for PLAN jobs, four for EXECUTE jobs), but with error messages prefixed with `"planPerSourceDocumentByLineage"` instead of `"planAllToOne"`.
    *   `[âœ…]` 31.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts`, add the same validation pattern as step 27.c (27.c.i through 27.c.vii), but with error messages prefixed with `"planPerSourceDocumentByLineage requires"` instead of `"planAllToOne requires"`. Use `'PLAN'` and `'EXECUTE'` (uppercase) for job_type comparisons. Validate empty arrays explicitly (`array.length > 0`). Validate that `content_to_include` is an object, not an array at top level. Include `content_to_include` structure validation using the same `isContentToInclude` helper as step 27.c.iii.
    *   `[âœ…]` 31.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 31.b and ensure they now pass. Also verify that existing `planPerSourceDocumentByLineage` tests still pass.
    *   `[âœ…]` 31.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceDocumentByLineage.test.ts` and resolve any warnings or errors.

*   `[âœ…]` 32. **`[BE]` Fix planPerSourceGroup to Validate and Pass context_for_documents for PLAN Jobs and Validate files_to_generate for EXECUTE Jobs, and Tests**
    *   `[âœ…]` 32.a. `[DEPS]` The `planPerSourceGroup` planner function in `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` needs the same updates as `planAllToOne` from step 27. **CRITICAL ARCHITECTURAL REQUIREMENT: PLAN steps ALWAYS include `context_for_documents` in `recipe_step.outputs_required`. This is NEVER conditional. EXECUTE steps ALWAYS include `documents` and `files_to_generate` in `recipe_step.outputs_required`. This is NEVER conditional.** The function already extracts `document_key` from `outputs_required.documents[0].document_key` (lines 55-85) and sets it in the payload. Import `ContextForDocument` from `../../dialectic-service/dialectic.interface.ts` at the top of the file. All error messages must be prefixed with 'planPerSourceGroup requires...' instead of 'planAllToOne requires...'. The test file `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts` must be updated to test both PLAN and EXECUTE job validation. Test and source files must be edited in the same step per Instructions for Agent block.
    *   `[âœ…]` 32.b. `[TEST-UNIT]` **RED**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts`, write the same eight test cases as step 27.b (four for PLAN jobs, four for EXECUTE jobs), but with error messages prefixed with `"planPerSourceGroup"` instead of `"planAllToOne"`.
    *   `[âœ…]` 32.c. `[BE]` **GREEN**: In `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts`, add the same validation pattern as step 27.c (27.c.i through 27.c.vii), but with error messages prefixed with `"planPerSourceGroup requires"` instead of `"planAllToOne requires"`. Use `'PLAN'` and `'EXECUTE'` (uppercase) for job_type comparisons. Validate empty arrays explicitly (`array.length > 0`). Validate that `content_to_include` is an object, not an array at top level. Include `content_to_include` structure validation using the same `isContentToInclude` helper as step 27.c.iii.
    *   `[âœ…]` 32.d. `[TEST-UNIT]` **GREEN**: Re-run all tests from step 32.b and ensure they now pass. Also verify that existing `planPerSourceGroup` tests still pass.
    *   `[âœ…]` 32.e. `[LINT]` Run the linter for `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.ts` and `supabase/functions/dialectic-worker/strategies/planners/planPerSourceGroup.test.ts` and resolve any warnings or errors.

*   `[ ]` 33. **`[TEST-INT]` Fix Integration Test to Verify Complete Cross-Document Coordination Flow**
    *   `[ ]` 33.a. `[DEPS]` After all planners are updated (steps 27-32), `assembleTurnPrompt` is fixed (step 25), and `assemblePlannerPrompt` is fixed (step 26), the existing integration test file `supabase/integration_tests/services/planner_output_type.integration.test.ts` is incorrect and incomplete. Update this test to verify the complete PLAN â†’ EXECUTE cross-document coordination flow: (1) PLAN job receives `context_for_documents` from recipe step, (2) PLAN job generates `header_context` with filled `content_to_include` objects, (3) EXECUTE jobs consume the `header_context` and use alignment details, (4) documents generated in parallel are aligned using the same `header_context`. The test must verify that `files_to_generate` is read from recipe step (not header context) and that `context_for_documents` alignment details are used correctly.
    *   `[ ]` 33.b. `[TEST-INT]` **RED**: In `supabase/integration_tests/services/planner_output_type.integration.test.ts`, fix and expand the test to verify the complete cross-document coordination flow.
        *   `[ ]` 33.b.i. Update the existing test that verifies `document_key` flow to also verify that `assembleTurnPrompt` reads `files_to_generate` from `stage.recipe_step.outputs_required.files_to_generate` (not from `headerContext.files_to_generate`).
        *   `[ ]` 33.b.ii. Update the test to verify that `headerContext.context_for_documents` contains filled `content_to_include` objects (not empty models), and that `assembleTurnPrompt` uses these alignment details in the prompt context.
        *   `[ ]` 33.b.iii. Add a test case that verifies the complete PLAN â†’ EXECUTE flow: create a PLAN job, verify it generates `header_context` with filled `content_to_include`, create EXECUTE jobs that consume that `header_context`, and verify that `assembleTurnPrompt` successfully matches `from_document_key` to `document_key` and uses the alignment details.
        *   `[ ]` 33.b.iv. Add a test case that verifies structure matching: ensure that `files_to_generate[].from_document_key` values match `context_for_documents[].document_key` values, and that `content_to_include` structures match between PLAN and EXECUTE steps.
        *   `[ ]` 33.b.v. Remove or fix any incorrect test code that assumes `files_to_generate` is in `headerContext` (the test incorrectly creates `headerContext` with `files_to_generate` - this should be removed or updated to match the correct architecture where `files_to_generate` is in recipe step).
    *   `[ ]` 33.c. `[TEST-INT]` **GREEN**: Re-run all tests from step 33.b and ensure they now pass. This verifies that the complete end-to-end cross-document coordination flow works correctly: PLAN jobs generate `header_context` with alignment details, EXECUTE jobs consume it correctly, and documents are aligned.
    *   `[ ]` 33.d. `[LINT]` Run the linter for `supabase/integration_tests/services/planner_output_type.integration.test.ts` and resolve any warnings or errors.
    *   `[ ]` 33.e. `[CRITERIA]` The integration test verifies: (1) PLAN jobs generate `header_context` with `context_for_documents` containing filled `content_to_include` objects, (2) EXECUTE jobs read `files_to_generate` from recipe step (not header context), (3) `assembleTurnPrompt` matches `from_document_key` to `document_key` and uses alignment details from `context_for_documents`, (4) structure matching is validated at runtime, (5) documents generated in parallel use the same alignment details from `header_context`.

*   `[âœ…]` 34. **`[CRITERIA]` Verify All Gaps Are Resolved**
    *   `[âœ…]` 34.a. `[DEPS]` According to Recipe-Planner-Gap-Analysis.md, all identified gaps must be resolved. This step verifies that the implementation addresses every gap.
    *   `[âœ…]` 34.b. `[CRITERIA]` Verify that all gaps from Recipe-Planner-Gap-Analysis.md are resolved.
        *   `[âœ…]` 34.b.i. **Gap 1 (Location Mismatch)**: Verify `assembleTurnPrompt` reads `files_to_generate` from recipe step, not header context. âœ… Resolved by step 25.
        *   `[âœ…]` 34.b.ii. **Gap 2 (Field Name Mismatch)**: Verify `assembleTurnPrompt` uses `from_document_key` (not `document_key`) when matching. âœ… Resolved by step 25.
        *   `[âœ…]` 34.b.iii. **Gap 3 (Inconsistent Recipe Definitions)**: Verify Synthesis PLAN steps don't have `files_to_generate`, and Synthesis EXECUTE steps do have `files_to_generate`. âœ… Resolved by step 21.
        *   `[âœ…]` 34.b.iv. **Gap 4 (Missing Validation)**: Verify planners validate `context_for_documents` for PLAN jobs and `files_to_generate` for EXECUTE jobs. âœ… Resolved by steps 27-32.
        *   `[âœ…]` 34.b.v. **Gap 5 (Missing HeaderContext Type)**: Verify `HeaderContext` interface is defined and exported. âœ… Resolved by step 18.
        *   `[âœ…]` 34.b.vi. **Gap 6 (Header Context Generation)**: Verify PLAN jobs generate `header_context` with `context_for_documents` (not `files_to_generate`). âœ… Resolved by steps 21, 26.
        *   `[âœ…]` 34.b.vii. **Gap 7 (Inconsistent PLAN Step Structure)**: Verify Antithesis `non_functional_requirements` uses object structure. âœ… Resolved by step 20.
        *   `[âœ…]` 34.b.viii. **Gap 8 (Inconsistent EXECUTE Step Structure)**: Verify Paralysis EXECUTE step has `content_to_include`. âœ… Resolved by step 23.
        *   `[âœ…]` 34.b.ix. **Gap 9 (PLAN â†” EXECUTE Structure Mapping)**: Verify `context_for_documents[].document_key` matches `files_to_generate[].from_document_key` and structures match. âœ… Resolved by steps 19, 20, 21, 22, 23.
        *   `[âœ…]` 34.b.x. **Gap 10 (Missing Type Definitions)**: Verify `ContentToInclude` and `HeaderContext` types are defined. âœ… Resolved by step 18.

*   `[âœ…]` 35. **`[COMMIT]` Commit All Changes with Comprehensive Message**
    *   `[âœ…]` 35.a. `[DEPS]` After all work is complete, tested, and linted, commit all changes with a comprehensive commit message that describes all fixes.
    *   `[âœ…]` 35.b. `[COMMIT]` Commit message: "fix: resolve recipe-planner data architecture gaps for cross-document coordination - Define ContentToInclude type for consistent content_to_include structures across all stages - Define HeaderContext interface matching actual PLAN job output structure (no files_to_generate) - Update ContextForDocument to use ContentToInclude type - Fix all 5 stage migrations: verify and fix structure matching between PLAN and EXECUTE steps (context_for_documents[].document_key matches files_to_generate[].from_document_key, content_to_include structures match exactly) - Fix Synthesis stage migration: remove files_to_generate from PLAN steps, add to EXECUTE steps - Fix Antithesis stage migration: change non_functional_requirements from array to object structure - Fix Paralysis stage migration: add content_to_include to actionable_checklist EXECUTE step - Update isHeaderContext type guard to match new HeaderContext interface (remove files_to_generate validation) - Fix assembleTurnPrompt to read files_to_generate from recipe step (not header context) and use from_document_key - Fix assembleTurnPrompt to extract alignment details from header_context.context_for_documents - Fix assemblePlannerPrompt to include context_for_documents in PLAN prompts - Update all six planners to validate and pass context_for_documents for PLAN jobs - Update all six planners to validate files_to_generate for EXECUTE jobs - Add comprehensive unit tests for all changes - Fix integration test to verify complete cross-document coordination flow - Resolves all 10 gaps identified in Recipe-Planner-Gap-Analysis.md"


*   `[ ]` 36. **`[PROMPT]` Fix All Prompt Templates and Document Templates to Exactly Match Database Structures**
    *   `[âœ…]` 36.a. `[DEPS]` The prompt template files in `docs/prompts/` and document template files in `docs/templates/` are loaded from storage and used by `assemblePlannerPrompt` and `assembleTurnPrompt`. These files must EXACTLY match the database structures defined in the stage migration files (`supabase/migrations/*_stage.sql`). The database migration files define the expected structure for `context_for_documents`, `content_to_include`, `files_to_generate`, and document templates. Any mismatch between the file-based templates and database structures causes PLAN jobs to generate invalid `header_context` artifacts (as seen in the investigation where `feature_spec.content_to_include` was an array instead of an object). Every prompt template file must be FIXED to match its corresponding database structure in the migration file. Every document template file must be FIXED to match its corresponding database structure. The database migration files are the source of truth. The file-based templates must be corrected to exactly match. This correction ensures that the AI agent receives instructions that match the validated type structures, preventing structural validation failures at runtime. Each step must: (1) read the database structure from the migration file, (2) read the corresponding prompt/template file, (3) UPDATE the file to exactly match the database structure, (4) ensure all `content_to_include` structures are objects (not arrays at top level), (5) ensure all `document_key` values match, (6) ensure all `template_filename` values match.
    *   `[âœ…]` 36.b. **`[PROMPT]` Fix Thesis Stage Planner Prompt Template**
        *   `[âœ…]` 36.b.i. `[DEPS]` The thesis stage planner prompt template file is `docs/prompts/thesis/thesis_planner_header_v1.md`. The database migration file `supabase/migrations/20251006194531_thesis_stage.sql` defines the expected `context_for_documents` structure for the PLAN step (lines 201-264). The planner prompt template contains a JSON schema example showing the expected `HeaderContext` structure, including `context_for_documents` array with `content_to_include` objects for each document. The template's schema example must EXACTLY match the database structure. The investigation identified that the template file currently shows `feature_spec.content_to_include` as an array (lines 84-90), but the database expects an object structure with `{"features": [...]}`. The database structure is the source of truth and the template must be corrected to match it exactly.
        *   `[âœ…]` 36.b.ii. `[PROMPT]` Read `supabase/migrations/20251006194531_thesis_stage.sql` PLAN step `context_for_documents` structure (lines 201-264) to get the exact database structure for all four documents: `business_case`, `feature_spec`, `technical_approach`, `success_metrics`.
        *   `[âœ…]` 36.b.iii. `[PROMPT]` Read `docs/prompts/thesis/thesis_planner_header_v1.md` and locate the `HeaderContext` schema example (lines 36-111) that shows the JSON structure with `context_for_documents` array.
        *   `[âœ…]` 36.b.iv. `[PROMPT]` Update `docs/prompts/thesis/thesis_planner_header_v1.md` to fix `feature_spec.content_to_include`: change from array structure `[{...}]` (lines 84-90) to object structure `{"features": [{"feature_name": "", "feature_objective": "", "user_stories": [], "acceptance_criteria": [], "dependencies": [], "success_metrics": []}]}` exactly matching the database structure (lines 221-232).
        *   `[âœ…]` 36.b.v. `[PROMPT]` Update `docs/prompts/thesis/thesis_planner_header_v1.md` to ensure `business_case.content_to_include` matches the database structure exactly: include all fields (market_opportunity, user_problem_validation, competitive_analysis, differentiation_&_value_proposition, risks_&_mitigation, strengths, weaknesses, opportunities, threats, next_steps, proposal_references, executive_summary) with exact field names from database (lines 204-217).
        *   `[âœ…]` 36.b.vi. `[PROMPT]` Update `docs/prompts/thesis/thesis_planner_header_v1.md` to ensure `technical_approach.content_to_include` matches the database structure exactly: include all fields (architecture, components, data, deployment, sequencing, risk_mitigation, open_questions) with exact field names from database (lines 236-244).
        *   `[âœ…]` 36.b.vii. `[PROMPT]` Update `docs/prompts/thesis/thesis_planner_header_v1.md` to ensure `success_metrics.content_to_include` matches the database structure exactly: include all fields (outcome_alignment, north_star_metric, primary_kpis, leading_indicators, lagging_indicators, guardrails, measurement_plan, risk_signals, next_steps, data_sources, reporting_cadence, ownership, escalation_plan) with exact field names from database (lines 248-262).
        *   `[âœ…]` 36.b.viii. `[PROMPT]` Verify all `content_to_include` structures in the updated template are objects (not arrays at top level). Ensure the JSON schema example in the template exactly reflects the database structure. Ensure proper JSON formatting and indentation is maintained.
    *   `[âœ…]` 36.c. **`[PROMPT]` Fix Thesis Stage Turn Prompt Templates**
        *   `[âœ…]` 36.c.i. `[DEPS]` The thesis stage has four turn prompt template files: `docs/prompts/thesis/thesis_business_case_turn_v1.md`, `docs/prompts/thesis/thesis_feature_spec_turn_v1.md`, `docs/prompts/thesis/thesis_technical_approach_turn_v1.md`, `docs/prompts/thesis/thesis_success_metrics_turn_v1.md`. These turn prompts are used by `assembleTurnPrompt` for EXECUTE jobs. The database migration file defines the expected document structures in EXECUTE steps (lines 323-891). Each turn prompt template must not contain hardcoded structure examples that conflict with database definitions. The database structure is the source of truth.
        *   `[âœ…]` 36.c.ii. `[PROMPT]` Read each thesis turn prompt template file. If any contain hardcoded structure examples that conflict with database definitions, remove or update them to match the database EXECUTE step structures from `supabase/migrations/20251006194531_thesis_stage.sql`. Ensure all structure references align with database definitions.
    *   `[âœ…]` 36.d. **`[PROMPT]` Fix Thesis Stage Document Templates**
        *   `[âœ…]` 36.d.i. `[DEPS]` The thesis stage has four document template files: `docs/templates/thesis/thesis_business_case.md`, `docs/templates/thesis/thesis_feature_spec.md`, `docs/templates/thesis/thesis_technical_approach.md`, `docs/templates/thesis/thesis_success_metrics.md`. These document templates are referenced by `template_filename` in the database EXECUTE steps. The database migration file defines the expected `template_filename` values and `documents[].content_to_include` structures for each document. Template file content structure must exactly match the expected document structure from database.
        *   `[âœ…]` 36.d.ii. `[PROMPT]` In `supabase/migrations/20251006194531_thesis_stage.sql`, identify all `template_filename` values in EXECUTE steps. Ensure corresponding files exist in `docs/templates/thesis/`. If any files are missing, create them with the correct structure.
        *   `[âœ…]` 36.d.iii. `[PROMPT]` Read each document template file and update its structure to exactly match the database `documents[].content_to_include` structure for that document from the EXECUTE step. Templates may use placeholder syntax (e.g., `{{field_name}}`) that must map to fields in `content_to_include`. Ensure all field names match exactly with the database structure.
        *   `[âœ…]` 36.d.iv. `[PROMPT]` Update each document template file to ensure the template structure exactly aligns with the database structure. If templates reference fields, ensure all field names match the database `content_to_include` structure exactly.
    *   `[âœ…]` 36.e. **`[PROMPT]` Fix Antithesis Stage Planner Prompt Template**
        *   `[âœ…]` 36.e.i. `[DEPS]` The antithesis stage planner prompt template file is `docs/prompts/antithesis/antithesis_planner_review_v1.md`. The database migration file `supabase/migrations/20251006194542_antithesis_stage.sql` defines the expected `context_for_documents` structure for the PLAN step. According to step 20 of this checklist, `non_functional_requirements.content_to_include` was changed from an array to an object structure `{"categories": [...]}` in the database. The planner prompt template must match this corrected structure exactly.
        *   `[âœ…]` 36.e.ii. `[PROMPT]` Read `supabase/migrations/20251006194542_antithesis_stage.sql` PLAN step `context_for_documents` structure to get the exact database structure for all documents.
        *   `[âœ…]` 36.e.iii. `[PROMPT]` Read `docs/prompts/antithesis/antithesis_planner_review_v1.md` and locate the `HeaderContext` schema example.
        *   `[âœ…]` 36.e.iv. `[PROMPT]` Update `docs/prompts/antithesis/antithesis_planner_review_v1.md` to fix `non_functional_requirements.content_to_include`: change from array structure `[...]` to object structure `{"categories": [...]}` exactly matching the database structure.
        *   `[âœ…]` 36.e.v. `[PROMPT]` Update `docs/prompts/antithesis/antithesis_planner_review_v1.md` to ensure all other `context_for_documents` entries match database structures exactly: `business_case_critique`, `technical_feasibility_assessment`, `risk_register`, `dependency_map`, `comparison_vector`. Ensure all `document_key` values match and all `content_to_include` structures are objects (not arrays at top level), matching the database structure exactly.
    *   `[âœ…]` 36.f. **`[PROMPT]` Fix Antithesis Stage Turn Prompt Templates**
        *   `[âœ…]` 36.f.i. `[DEPS]` The antithesis stage has six turn prompt template files: `docs/prompts/antithesis/antithesis_business_case_critique_turn_v1.md`, `docs/prompts/antithesis/antithesis_feasibility_assessment_turn_v1.md`, `docs/prompts/antithesis/antithesis_risk_register_turn_v1.md`, `docs/prompts/antithesis/antithesis_non_functional_requirements_turn_v1.md`, `docs/prompts/antithesis/antithesis_dependency_map_turn_v1.md`, `docs/prompts/antithesis/antithesis_comparison_vector_turn_v1.md`. Each turn prompt template must not contain hardcoded structure examples that conflict with database definitions.
        *   `[âœ…]` 36.f.ii. `[PROMPT]` Read each antithesis turn prompt template file. If any contain hardcoded structure examples that conflict with database definitions, remove or update them to match the database EXECUTE step structures from `supabase/migrations/20251006194542_antithesis_stage.sql`. Ensure all structure references align with database definitions.
    *   `[âœ…]` 36.g. **`[PROMPT]` Fix Antithesis Stage Document Templates**
        *   `[âœ…]` 36.g.i. `[DEPS]` The antithesis stage has six document template files: `docs/templates/antithesis/antithesis_business_case_critique.md`, `docs/templates/antithesis/antithesis_feasibility_assessment.md`, `docs/templates/antithesis/antithesis_risk_register.md`, `docs/templates/antithesis/antithesis_non_functional_requirements.md`, `docs/templates/antithesis/antithesis_dependency_map.md`, `docs/templates/antithesis/antithesis_comparison_vector.json`. All `template_filename` values in database must match actual files, and template structures must align with database `documents[].content_to_include` structures.
        *   `[âœ…]` 36.g.ii. `[PROMPT]` In `supabase/migrations/20251006194542_antithesis_stage.sql`, identify all `template_filename` values. Ensure corresponding files exist. Read each document template file and update its structure to exactly match the database `documents[].content_to_include` structure for that document. Ensure all field names match exactly with the database structure.
    *   `[âœ…]` 36.h. **`[PROMPT]` Fix Synthesis Stage Planner Prompt Templates**
        *   `[âœ…]` 36.h.i. `[DEPS]` The synthesis stage has two planner prompt template files: `docs/prompts/synthesis/synthesis_pairwise_header_planner_v1.md` (for pairwise planning) and `docs/prompts/synthesis/synthesis_final_header_planner_v1.md` (for final header planning). According to step 21 of this checklist, PLAN steps should NOT have `files_to_generate` (it was removed from database). The database migration file `supabase/migrations/20251006194549_synthesis_stage.sql` defines the expected structures. Planner prompt templates must not reference `files_to_generate` in their schema examples, and `context_for_documents` structures must match database definitions exactly.
        *   `[âœ…]` 36.h.ii. `[PROMPT]` Read `supabase/migrations/20251006194549_synthesis_stage.sql` PLAN step `context_for_documents` structure for pairwise planning to get the exact database structure.
        *   `[âœ…]` 36.h.iii. `[PROMPT]` Read `docs/prompts/synthesis/synthesis_pairwise_header_planner_v1.md` and locate the `HeaderContext` schema example. Remove any `files_to_generate` references if present. Update all `context_for_documents` entries to exactly match the database PLAN step structure.
        *   `[âœ…]` 36.h.iv. `[PROMPT]` Read `supabase/migrations/20251006194549_synthesis_stage.sql` PLAN step `context_for_documents` structure for final header planning to get the exact database structure.
        *   `[âœ…]` 36.h.v. `[PROMPT]` Read `docs/prompts/synthesis/synthesis_final_header_planner_v1.md` and locate the `HeaderContext` schema example. Remove any `files_to_generate` references if present. Update all `context_for_documents` entries to exactly match the database PLAN step structure.
    *   `[âœ…]` 36.i. **`[PROMPT]` Fix Synthesis Stage Turn Prompt Templates**
        *   `[âœ…]` 36.i.i. `[DEPS]` The synthesis stage has thirteen turn prompt template files covering pairwise, document-level, and final deliverables. Each turn prompt template must not contain hardcoded structure examples that conflict with database definitions.
        *   `[âœ…]` 36.i.ii. `[PROMPT]` Read each synthesis turn prompt template file. If any contain hardcoded structure examples that conflict with database definitions, remove or update them to match the database EXECUTE step structures from `supabase/migrations/20251006194549_synthesis_stage.sql`. Ensure all structure references align with database definitions.
    *   `[âœ…]` 36.j. **`[PROMPT]` Fix Synthesis Stage Document Templates**
        *   `[âœ…]` 36.j.i. `[DEPS]` The synthesis stage has thirteen document template files. All `template_filename` values in database must match actual files, and template structures must align with database `documents[].content_to_include` structures.
        *   `[âœ…]` 36.j.ii. `[PROMPT]` In `supabase/migrations/20251006194549_synthesis_stage.sql`, identify all `template_filename` values. Ensure corresponding files exist. Read each document template file and update its structure to exactly match the database `documents[].content_to_include` structure for that document. Ensure all field names match exactly with the database structure.
    *   `[âœ…]` 36.k. **`[PROMPT]` Fix Parenthesis Stage Planner Prompt Template**
        *   `[âœ…]` 36.k.i. `[DEPS]` The parenthesis stage planner prompt template file is `docs/prompts/parenthesis/parenthesis_planner_header_v1.md`. The database migration file `supabase/migrations/20251006194558_parenthesis_stage.sql` defines the expected `context_for_documents` structure. The planner prompt template must match the database structure exactly.
        *   `[âœ…]` 36.k.ii. `[PROMPT]` Read `supabase/migrations/20251006194558_parenthesis_stage.sql` PLAN step `context_for_documents` structure to get the exact database structure for all documents: `technical_requirements`, `master_plan`, `milestone_schema`.
        *   `[âœ…]` 36.k.iii. `[PROMPT]` Read `docs/prompts/parenthesis/parenthesis_planner_header_v1.md` and locate the `HeaderContext` schema example.
        *   `[âœ…]` 36.k.iv. `[PROMPT]` Update `docs/prompts/parenthesis/parenthesis_planner_header_v1.md` to ensure all `context_for_documents` entries exactly match database structures: ensure all `document_key` values match and all `content_to_include` structures are objects (not arrays at top level), matching the database structure exactly.
    *   `[âœ…]` 36.l. **`[PROMPT]` Fix Parenthesis Stage Turn Prompt Templates**
        *   `[âœ…]` 36.l.i. `[DEPS]` The parenthesis stage has four turn prompt template files. Each turn prompt template must not contain hardcoded structure examples that conflict with database definitions.
        *   `[âœ…]` 36.l.ii. `[PROMPT]` Read each parenthesis turn prompt template file. If any contain hardcoded structure examples that conflict with database definitions, remove or update them to match the database EXECUTE step structures from `supabase/migrations/20251006194558_parenthesis_stage.sql`. Ensure all structure references align with database definitions.
    *   `[âœ…]` 36.m. **`[PROMPT]` Fix Parenthesis Stage Document Templates**
        *   `[âœ…]` 36.m.i. `[DEPS]` The parenthesis stage has three document template files. All `template_filename` values in database must match actual files, and template structures must align with database `documents[].content_to_include` structures.
        *   `[âœ…]` 36.m.ii. `[PROMPT]` In `supabase/migrations/20251006194558_parenthesis_stage.sql`, identify all `template_filename` values. Ensure corresponding files exist. Read each document template file and update its structure to exactly match the database `documents[].content_to_include` structure for that document. Ensure all field names match exactly with the database structure.
    *   `[âœ…]` 36.n. **`[PROMPT]` Fix Paralysis Stage Planner Prompt Template**
        *   `[âœ…]` 36.n.i. `[DEPS]` The paralysis stage planner prompt template file is `docs/prompts/paralysis/paralysis_planner_header_v1.md`. The database migration file `supabase/migrations/20251006194605_paralysis_stage.sql` defines the expected `context_for_documents` structure. According to step 23 of this checklist, the EXECUTE step for `actionable_checklist` was updated to include `content_to_include` in the database. The planner prompt template must match the database structure exactly.
        *   `[âœ…]` 36.n.ii. `[PROMPT]` Read `supabase/migrations/20251006194605_paralysis_stage.sql` PLAN step `context_for_documents` structure to get the exact database structure for all documents: `actionable_checklist`, `updated_master_plan`, `advisor_recommendations`.
        *   `[âœ…]` 36.n.iii. `[PROMPT]` Read `docs/prompts/paralysis/paralysis_planner_header_v1.md` and locate the `HeaderContext` schema example.
        *   `[âœ…]` 36.n.iv. `[PROMPT]` Update `docs/prompts/paralysis/paralysis_planner_header_v1.md` to ensure all `context_for_documents` entries exactly match database structures: ensure all `document_key` values match and all `content_to_include` structures are objects (not arrays at top level), matching the database structure exactly.
    *   `[âœ…]` 36.o. **`[PROMPT]` Fix Paralysis Stage Turn Prompt Templates**
        *   `[âœ…]` 36.o.i. `[DEPS]` The paralysis stage has four turn prompt template files. Each turn prompt template must not contain hardcoded structure examples that conflict with database definitions.
        *   `[âœ…]` 36.o.ii. `[PROMPT]` Read each paralysis turn prompt template file. If any contain hardcoded structure examples that conflict with database definitions, remove or update them to match the database EXECUTE step structures from `supabase/migrations/20251006194605_paralysis_stage.sql`. Ensure all structure references align with database definitions.
    *   `[âœ…]` 36.p. **`[PROMPT]` Fix Paralysis Stage Document Templates**
        *   `[âœ…]` 36.p.i. `[DEPS]` The paralysis stage has three document template files. All `template_filename` values in database must match actual files, and template structures must align with database `documents[].content_to_include` structures.
        *   `[âœ…]` 36.p.ii. `[PROMPT]` In `supabase/migrations/20251006194605_paralysis_stage.sql`, identify all `template_filename` values. Ensure corresponding files exist. Read each document template file and update its structure to exactly match the database `documents[].content_to_include` structure for that document. Ensure all field names match exactly with the database structure.
    *   `[ ]` 36.q. **`[PROMPT]` Upload Updated Prompt and Document Templates to Storage**
        *   `[ ]` 36.q.i. `[DEPS]` After all prompt template files and document template files have been fixed to match database structures, they must be uploaded to storage using the `seed_prompt_templates.ts` script. The script uploads files from `docs/prompts/` and `docs/templates/` to the storage bucket referenced by `dialectic_document_templates` table. This ensures that when `assemblePlannerPrompt` and `assembleTurnPrompt` load templates from storage, they receive the corrected versions that match database structures.
        *   `[ ]` 36.q.ii. `[PROMPT]` Run the `seed_prompt_templates.ts` script to upload all updated prompt and document templates to storage. Ensure the script completes successfully and that all files are uploaded to the correct storage paths as defined in the database `dialectic_document_templates` table.
    *   `[ ]` 36.r. `[CRITERIA]` All prompt template files and document template files EXACTLY match their corresponding database structures in the stage migration files. All `content_to_include` structures are objects (not arrays at top level). All `document_key` values match between templates and database. All `template_filename` values match between database and actual files. All updated templates have been uploaded to storage. No structural mismatches exist between file-based templates and database definitions.