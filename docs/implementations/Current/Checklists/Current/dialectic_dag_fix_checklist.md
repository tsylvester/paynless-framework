# Dialectic DAG Traversal Fix Checklist

## Overview

This checklist addresses the known issues preventing the dialectic system from correctly walking the DAG. Issues are derived from `Dialectic_Modeling_Explanation_v3.md` Known Issues section.

**Issues Addressed:**
1. Issue 2: Header Context Not Matched to Producing Model (`planPerSourceDocument`)
2. Issue 3: Anchor Selection Logic Does Not Distinguish Job Types (`selectAnchorSourceDocument`)
3. Issue 4: Input Bundling Not Implemented for Multi-Input Steps (`planPerModel`)
4. Issue 6: Lineage Tracking at Branch Points (planners setting `source_group = null`)
5. Issue 1: Wrong Granularity Strategy in Synthesis Pairwise Steps (migration)
6. Issue 5: Synthesis Consolidation Strategy Incorrect (migration)

**Dependency Order:**
- `selectAnchorSourceDocument` (helper) â†’ consumed by all planners
- `planPerSourceDocument` (planner) â†’ consumed by worker
- `planPerModel` (planner) â†’ consumed by worker
- Migrations â†’ depend on planners working correctly

*   `[âœ…]` 94. **selectAnchorSourceDocument** Implement decision tree that distinguishes job types and output types
    *   `[âœ…]` 94.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 94.a.i. `selectAnchorSourceDocument(recipeStep, sourceDocs)` in `helpers.ts` returns `SelectAnchorResult`
        *   `[âœ…]` 94.a.ii. Consumed by: `planPerSourceDocument`, `planPerSourceDocumentByLineage`, `planPairwiseByOrigin`, `planPerModel`
        *   `[âœ…]` 94.a.iii. Must access `recipeStep.job_type`, `recipeStep.output_type`, `recipeStep.granularity_strategy`
    *   `[âœ…]` 94.b. [TYPES] Update `SelectAnchorResult` type in `dialectic.interface.ts`
        *   `[âœ…]` 94.b.i. Add status `'derive_from_header_context'` for EXECUTE steps that consume header_context but produce documents
        *   `[âœ…]` 94.b.ii. Deprecate/remove `'no_document_inputs_required'` status (replace with more specific statuses)
        *   `[âœ…]` 94.b.iii. [TYPE-GUARD-TEST] Add tests for `isSelectAnchorResult` type guard if it exists
        *   `[âœ…]` 94.b.iv. [TYPE-GUARDS] Update type guard for new status values
    *   `[âœ…]` 94.c. [TEST-UNIT] Unit tests for `selectAnchorSourceDocument` decision tree
        *   `[âœ…]` 94.c.i. Assert PLAN + `all_to_one` returns `{ status: 'no_anchor_required' }`
        *   `[âœ…]` 94.c.ii. Assert PLAN + `per_source_document` with doc inputs returns `{ status: 'anchor_found', document: <input_doc> }`
        *   `[âœ…]` 94.c.iii. Assert EXECUTE with doc inputs returns `{ status: 'anchor_found', document: <highest_relevance_doc> }`
        *   `[âœ…]` 94.c.iv. Assert EXECUTE with only header_context input returns `{ status: 'derive_from_header_context' }`
        *   `[âœ…]` 94.c.v. Assert EXECUTE producing header_context (not document) returns `{ status: 'no_anchor_required' }`
        *   `[âœ…]` 94.c.vi. Assert Thesis Step 2 scenario (header_context input, document output) returns `'derive_from_header_context'`
        *   `[âœ…]` 94.c.vii. Assert Antithesis Step 1 scenario (doc inputs, header_context output) returns `'anchor_found'` for lineage
        *   `[âœ…]` 94.c.viii. Assert Synthesis Step 3 scenario (consolidation/merge) returns `'no_anchor_required'`
    *   `[âœ…]` 94.d. [BE] Implement decision tree logic in `selectAnchorSourceDocument`
        *   `[âœ…]` 94.d.i. Add parameter access for `job_type`, `output_type`, `granularity_strategy` from recipeStep
        *   `[âœ…]` 94.d.ii. Implement: IF `job_type == 'PLAN'` AND `granularity_strategy == 'all_to_one'` â†’ return `'no_anchor_required'`
        *   `[âœ…]` 94.d.iii. Implement: IF `job_type == 'PLAN'` AND other granularity â†’ find anchor from inputs for lineage
        *   `[âœ…]` 94.d.iv. Implement: IF `job_type == 'EXECUTE'` with doc inputs â†’ return `'anchor_found'` with highest relevance
        *   `[âœ…]` 94.d.v. Implement: IF `job_type == 'EXECUTE'` with only header_context input â†’ return `'derive_from_header_context'`
        *   `[âœ…]` 94.d.vi. Implement: IF `job_type == 'EXECUTE'` AND `output_type == 'header_context'` â†’ return `'no_anchor_required'`
        *   `[âœ…]` 94.d.vii. Remove fallback/default logic that hides missing cases; throw explicit error for unhandled scenarios
    *   `[âœ…]` 94.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 94.e.i. Verify all decision tree branches covered
        *   `[âœ…]` 94.e.ii. Verify no regressions in existing anchor selection behavior
    *   `[âœ…]` 94.f. [TEST-INT] Integration test with planner consumers
        *   `[âœ…]` 94.f.i. Assert `planPerSourceDocument` correctly handles `'derive_from_header_context'` status
        *   `[âœ…]` 94.f.ii. Assert `planPerModel` correctly handles `'no_anchor_required'` for consolidation
    *   `[âœ…]` 94.g. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 94.g.i. Function distinguishes PLAN vs EXECUTE job types
        *   `[âœ…]` 94.g.ii. Function distinguishes header_context vs document output types
        *   `[âœ…]` 94.g.iii. Returns `'derive_from_header_context'` for Thesis EXECUTE steps
        *   `[âœ…]` 94.g.iv. Returns `'no_anchor_required'` for consolidation/merge steps
        *   `[âœ…]` 94.g.v. No hidden defaults or fallbacks; explicit errors for unhandled cases
    *   `[âœ…]` 94.h. [COMMIT] `fix(dialectic): selectAnchorSourceDocument distinguishes job types and output types`

*   `[âœ…]` 95. **planPerSourceDocument** Add model-filtering to match header_context to producing model
    *   `[âœ…]` 95.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 95.a.i. `planPerSourceDocument(sourceDocs, parentJob, recipeStep)` in `planPerSourceDocument.ts`
        *   `[âœ…]` 95.a.ii. Depends on: `selectAnchorSourceDocument` (updated in step 94)
        *   `[âœ…]` 95.a.iii. Must access source document's `model_id` or `model_slug` to filter
        *   `[âœ…]` 95.a.iv. Must access parent job's `model_id` to match against source docs
    *   `[âœ…]` 95.b. [TYPES] Verify `SourceDocument` interface includes model identification
        *   `[âœ…]` 95.b.i. Confirm `SourceDocument` has `model_id` or equivalent field for filtering
        *   `[âœ…]` 95.b.ii. If missing, add `model_id?: string` to `SourceDocument` interface
        *   `[âœ…]` 95.b.iii. [TYPE-GUARD-TEST] Add test for model_id field presence check if new
        *   `[âœ…]` 95.b.iv. [TYPE-GUARDS] Update `isSourceDocument` guard if interface changes
    *   `[âœ…]` 95.c. [TEST-UNIT] Unit tests for model-filtering behavior
        *   `[âœ…]` 95.c.i. Assert: Given source documents from 3 different models (each with a header_context), planner called with model_id=A creates jobs only for model A's documents, with each job receiving model A's header_context as an input. No job is created FOR the header_context itself.
        *   `[âœ…]` 95.c.ii. Assert: Given header_context from model A and parent job for model B, no jobs created (empty result or error)
        *   `[âœ…]` 95.c.iii. Assert: Given multiple docs from same model, creates job for each doc from that model
        *   `[âœ…]` 95.c.iv. Assert: Model filtering applies only when source docs have model identification; fallback to current behavior if model_id absent
        *   `[âœ…]` 95.c.v. Assert: EXECUTE jobs inherit model_id from the source document, not parent job
    *   `[âœ…]` 95.d. [BE] Implement model-filtering logic
        *   `[âœ…]` 95.d.i. Extract `model_id` from parent job payload
        *   `[âœ…]` 95.d.ii. Separate sourceDocs into header_contexts and non-header_context documents. Filter both by model_id === parentJob.payload.model_id. Create jobs only for the non-header_context documents, passing the matching header_context as an input to each job.
        *   `[âœ…]` 95.d.iii. If filtered list is empty, return empty array (no jobs for this model)
        *   `[âœ…]` 95.d.iv. For EXECUTE jobs, set child job's `model_id` from the source document's `model_id`
        *   `[âœ…]` 95.d.v. Handle `'derive_from_header_context'` status from `selectAnchorSourceDocument`
    *   `[âœ…]` 95.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 95.e.i. Verify model filtering works correctly
        *   `[âœ…]` 95.e.ii. Verify backward compatibility when model_id is absent
    *   `[âœ…]` 95.f. [TEST-INT] Integration test with worker
        *   `[âœ…]` 95.f.i. Assert: Thesis stage with 3 models produces 3 header_contexts, then 3Ã—4=12 documents where each model uses its own header_context
        *   `[âœ…]` 95.f.ii. Assert: Child job payload includes correct model_id from source document
    *   `[âœ…]` 95.g. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 95.g.i. Each model only receives header_context it produced
        *   `[âœ…]` 95.g.ii. Documents generated are aligned with producing model's choices
        *   `[âœ…]` 95.g.iii. Model A never receives Model B's header_context
        *   `[âœ…]` 95.g.iv. Backward compatible when model_id is absent from source docs
    *   `[âœ…]` 95.h. [COMMIT] `fix(dialectic): planPerSourceDocument filters source docs by producing model`

*   `[âœ…]` 96. **planPerModel** Add input bundling and lineage handling for consolidation steps
    *   `[âœ…]` 96.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 96.a.i. `planPerModel(sourceDocs, parentJob, recipeStep)` in `planPerModel.ts`
        *   `[âœ…]` 96.a.ii. Depends on: `selectAnchorSourceDocument` (updated in step 94)
        *   `[âœ…]` 96.a.iii. Must bundle ALL source documents into single job per model
        *   `[âœ…]` 96.a.iv. Must handle `'no_anchor_required'` status for consolidation steps
    *   `[âœ…]` 96.b. [TYPES] Verify interface supports multiple input documents
        *   `[âœ…]` 96.b.i. Confirm `DialecticExecuteJobPayload.inputs` can hold multiple document IDs
        *   `[âœ…]` 96.b.ii. Confirm payload can represent bundled inputs (e.g., `inputs: { pairwise_ids: [...] }`)
        *   `[âœ…]` 96.b.iii. [TYPE-GUARD-TEST] Update tests if payload interface changes
        *   `[âœ…]` 96.b.iv. [TYPE-GUARDS] Update guards if payload interface changes
    *   `[âœ…]` 96.c. [TEST-UNIT] Unit tests for input bundling and lineage handling
        *   `[âœ…]` 96.c.i. Assert: Given nÂ² pairwise outputs, creates 1 job per model with all that model's outputs bundled
        *   `[âœ…]` 96.c.ii. Assert: Job payload `inputs` contains array of all bundled document IDs
        *   `[âœ…]` 96.c.iii. Assert: When `selectAnchorSourceDocument` returns `'no_anchor_required'`, planner sets `document_relationships.source_group = null`
        *   `[âœ…]` 96.c.iv. Assert: Consolidation job creates new lineage root (source_group = null signals producer to set self.id)
        *   `[âœ…]` 96.c.v. Assert: Job is assigned to correct model based on parent job's model_id
    *   `[âœ…]` 96.d. [BE] Implement input bundling and lineage handling
        *   `[âœ…]` 96.d.i. Bundle ALL sourceDocs into single job's inputs array
        *   `[âœ…]` 96.d.ii. When `selectAnchorSourceDocument` returns `'no_anchor_required'`, explicitly set `document_relationships.source_group = null`
        *   `[âœ…]` 96.d.iii. Ensure job is assigned to `parentJob.payload.model_id`
        *   `[âœ…]` 96.d.iv. Create `inputs` object with all document IDs grouped by contribution_type
    *   `[âœ…]` 96.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 96.e.i. Verify bundling works correctly
        *   `[âœ…]` 96.e.ii. Verify lineage handling for consolidation
    *   `[âœ…]` 96.f. [TEST-INT] Integration test with worker
        *   `[âœ…]` 96.f.i. Assert: Synthesis Step 3 with 3 models produces 3Ã—4=12 consolidated documents
        *   `[âœ…]` 96.f.ii. Assert: Each consolidated document has `source_group = self.id` (set by producer after save)
    *   `[âœ…]` 96.g. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 96.g.i. Each model receives ALL its pairwise outputs as bundled inputs
        *   `[âœ…]` 96.g.ii. Consolidation creates new lineage (source_group starts as null, producer sets to self.id)
        *   `[âœ…]` 96.g.iii. n models produce nÃ—4 consolidated documents (not 1Ã—4 or nÂ²Ã—4)
    *   `[âœ…]` 96.h. [COMMIT] `fix(dialectic): planPerModel bundles inputs and handles consolidation lineage`

*   `[âœ…]` 97. **20251006194549_synthesis_stage.sql** Fix granularity_strategy for pairwise and consolidation steps
    *   `[âœ…]` 97.a. [DEPS] Dependencies
        *   `[âœ…]` 97.a.i. Depends on: `planPairwiseByOrigin` planner existing and working
        *   `[âœ…]` 97.a.ii. Depends on: `planPerModel` planner updated (step 96)
        *   `[âœ…]` 97.a.iii. Migration file: `20251006194549_synthesis_stage.sql`
    *   `[âœ…]` 97.b. [DB] Update Step 2 pairwise steps granularity_strategy
        *   `[âœ…]` 97.b.i. Line 361: Change `'per_source_document'` to `'pairwise_by_origin'` for `synthesis_pairwise_business_case`
        *   `[âœ…]` 97.b.ii. Line 422: Change `'per_source_document'` to `'pairwise_by_origin'` for `synthesis_pairwise_feature_spec`
        *   `[âœ…]` 97.b.iii. Line 492: Change `'per_source_document'` to `'pairwise_by_origin'` for `synthesis_pairwise_technical_approach`
        *   `[âœ…]` 97.b.iv. Locate and change Step 2d: `'per_source_document'` to `'pairwise_by_origin'` for `synthesis_pairwise_success_metrics`
    *   `[âœ…]` 97.c. [DB] Update Step 3 consolidation steps granularity_strategy
        *   `[âœ…]` 97.c.i. Line 610: Change `'all_to_one'` to `'per_model'` for `synthesis_document_business_case`
        *   `[âœ…]` 97.c.ii. Line 656: Change `'all_to_one'` to `'per_model'` for `synthesis_document_feature_spec`
        *   `[âœ…]` 97.c.iii. Line 705: Change `'all_to_one'` to `'per_model'` for `synthesis_document_technical_approach`
        *   `[âœ…]` 97.c.iv. Line 740: Change `'all_to_one'` to `'per_model'` for `synthesis_document_success_metrics`
    *   `[âœ…]` 97.d. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 97.d.i. All Step 2 pairwise branches use `'pairwise_by_origin'`
        *   `[âœ…]` 97.d.ii. All Step 3 consolidation branches use `'per_model'`
        *   `[âœ…]` 97.d.iii. Migration applies cleanly to database
    *   `[âœ…]` 97.e. [COMMIT] `fix(db): synthesis_stage migration uses correct granularity strategies`

*   `[âœ…]` 98. **20251006194605_paralysis_stage.sql** Fix granularity_strategy for multi-input steps
    *   `[âœ…]` 98.a. [DEPS] Dependencies
        *   `[âœ…]` 98.a.i. Depends on: `planPerModel` planner updated (step 96)
        *   `[âœ…]` 98.a.ii. Migration file: `20251006194605_paralysis_stage.sql`
        *   `[âœ…]` 98.a.iii. Issue: Steps use `per_source_document` but require multiple bundled inputs (TRD + Master Plan + Milestone Schema from parenthesis)
    *   `[âœ…]` 98.b. [DB] Update EXECUTE steps to use bundling strategy
        *   `[âœ…]` 98.b.i. Line 435: Change `'per_source_document'` to `'per_model'` for `actionable_checklist` step
        *   `[âœ…]` 98.b.ii. Line 554: Change `'per_source_document'` to `'per_model'` for `updated_master_plan` step
        *   `[âœ…]` 98.b.iii. Line 684: Change `'per_source_document'` to `'per_model'` for `advisor_recommendations` step
        *   `[âœ…]` 98.b.iv. Verify remaining `per_source_document` usages (lines 767, 861, 943) and update if they also require bundled inputs
    *   `[âœ…]` 98.c. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 98.c.i. Each model receives ALL parenthesis inputs (TRD, Master Plan, Milestone Schema) bundled together
        *   `[âœ…]` 98.c.ii. Produces nÃ—3 paralysis documents (one set per model), not nÃ—inputsÃ—3
        *   `[âœ…]` 98.c.iii. Migration applies cleanly to database
    *   `[âœ…]` 98.d. [COMMIT] `fix(db): paralysis_stage migration uses bundling strategy for multi-input steps`

*   `[âœ…]` 99. **Integration Test: Full DAG Traversal** Verify all five stages complete successfully
    *   `[âœ…]` 99.a. [DEPS] Dependencies
        *   `[âœ…]` 99.a.i. Depends on: All planner fixes (steps 94-96)
        *   `[âœ…]` 99.a.ii. Depends on: Migration fixes (steps 97-98)
        *   `[âœ…]` 99.a.iii. Requires: Test harness that can execute full dialectic session
    *   `[âœ…]` 99.b. [TEST-INT] Integration tests for complete DAG traversal
        *   `[âœ…]` 99.b.i. Assert: Thesis stage produces nÃ—4 documents with correct header_context matching
        *   `[âœ…]` 99.b.ii. Assert: Antithesis stage produces nÂ²Ã—6 critique documents
        *   `[âœ…]` 99.b.iii. Assert: Synthesis pairwise step produces nÂ³Ã—4 pairwise documents
        *   `[âœ…]` 99.b.iv. Assert: Synthesis consolidation produces nÃ—4 consolidated documents with new lineage
        *   `[âœ…]` 99.b.v. Assert: Synthesis final produces nÃ—3 deliverables
        *   `[âœ…]` 99.b.vi. Assert: Parenthesis produces nÃ—3 planning documents in correct sequence
        *   `[âœ…]` 99.b.vii. Assert: Paralysis produces nÃ—3 implementation documents with bundled inputs
        *   `[âœ…]` 99.b.viii. Assert: All documents have correct `source_group` lineage tracking
        *   `[âœ…]` 99.b.ix. Assert: All documents have correct `[stageSlug]` anchor references
    *   `[âœ…]` 99.c. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 99.c.i. Full DAG traversal completes without errors
        *   `[âœ…]` 99.c.ii. Document counts match expected fan-out/fan-in pattern
        *   `[âœ…]` 99.c.iii. Each model uses its own header_context throughout
        *   `[âœ…]` 99.c.iv. Lineage tracking correctly identifies branch points
        *   `[âœ…]` 99.c.v. File naming produces unique, non-colliding paths
        *   `[âœ…]` 99.c.vi. Paralysis receives bundled inputs from Parenthesis (not fan-out explosion)
    *   `[âœ…]` 99.d. [COMMIT] `test(dialectic): integration test verifies complete DAG traversal`

*   `[ ]` 100. **Documentation Update** Update Dialectic_Modeling_Explanation.md to reflect fixes
    *   `[ ]` 100.a. [DEPS] Dependencies
        *   `[ ]` 100.a.i. Depends on: All fixes verified working (steps 94-99)
    *   `[ ]` 100.b. [DOCS] Update documentation
        *   `[ ]` 100.b.i. Remove or mark resolved: Issue 1 (pairwise granularity)
        *   `[ ]` 100.b.ii. Remove or mark resolved: Issue 2 (header_context matching)
        *   `[ ]` 100.b.iii. Remove or mark resolved: Issue 3 (anchor selection)
        *   `[ ]` 100.b.iv. Remove or mark resolved: Issue 4 (input bundling)
        *   `[ ]` 100.b.v. Remove or mark resolved: Issue 5 (consolidation strategy)
        *   `[ ]` 100.b.vi. Remove or mark resolved: Issue 6 (lineage at branch points)
        *   `[ ]` 100.b.vii. Add resolved: Issue 7 (paralysis fan-out explosion)
        *   `[ ]` 100.b.viii. Update Path Context Fields: Correct `attemptCount` description (increment to prevent overwrites, not model invocation counter)
    *   `[ ]` 100.c. [CRITERIA] Acceptance criteria
        *   `[ ]` 100.c.i. Documentation accurately reflects working implementation
        *   `[ ]` 100.c.ii. Known Issues section updated to reflect resolved state
        *   `[ ]` 100.c.iii. Future developers will not reintroduce fixed bugs
    *   `[ ]` 100.d. [COMMIT] `docs(dialectic): update explanation to reflect resolved issues`

*   `[âœ…]` 101. **Fix executeModelCallAndSave.ts** handling of `AssembledDocumentJson` key extraction
    *   `[âœ…]` 101.a. [DEPS] `executeModelCallAndSave` depends on `file_manager.types.ts` and `type_guards.file_manager.ts`.
    *   `[âœ…]` 101.b. [TYPES] Define `DocumentRelated` union in `file_manager.types.ts` to include `DocumentKey` types plus `AssembledDocumentJson`, `ModelContributionRawJson`, and `RenderedDocument`.
        *   `[âœ…]` 101.b.i [TYPE-GUARD-TEST] Create `supabase/functions/_shared/utils/type-guards/type_guards.file_manager.test.ts` to test `isDocumentRelated`.
        *   `[âœ…]` 101.b.ii [TYPE-GUARDS] Implement `isDocumentRelated` in `type_guards.file_manager.ts`.
    *   `[âœ…]` 101.c. [TEST-UNIT] Create `supabase/functions/dialectic-worker/executeModelCallAndSave.[appropriate test file].ts` with a RED test case that passes a payload with `output_type: assembled_document_json` and a `document_key`, asserting that the key is extracted (currently fails).
    *   `[âœ…]` 101.d. [WORKER] Update `executeModelCallAndSave.ts` to use `isDocumentRelated` instead of `isDocumentKey` for the extraction logic.
    *   `[âœ…]` 101.e. [TEST-UNIT] Run `executeModelCallAndSave.test.ts` to prove the test passes (GREEN).
    *   `[âœ…]` 101.f. [TEST-INT] Run `dialectic_full_dag_traversal.integration.test.ts` to prove the integration flow works.
    *   `[âœ…]` 101.g. [CRITERIA] All tests pass.
    *   `[âœ…]` 101.h. [COMMIT] `fix: ensure document_key is extracted for assembled_document_json in worker`

*   `[ðŸš§]` 102. **assembleTurnPrompt.ts** Fix DI violations and use injected dependencies
    *   `[âœ…]` 102.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 102.a.i. `assembleTurnPrompt(deps: AssembleTurnPromptDeps, params: AssembleTurnPromptParams)` in `assembleTurnPrompt.ts`
        *   `[âœ…]` 102.a.ii. Deps interface (line 21-27): `dbClient`, `fileManager`, `gatherContext`, `render`, `downloadFromStorage`
        *   `[âœ…]` 102.a.iii. Params interface (line 29-35): `job`, `project`, `session`, `stage`, `sourceContributionId`
        *   `[âœ…]` 102.a.iv. `RenderFn` signature expects `(renderPromptFn, stage, context: DynamicContextVariables, userProjectOverlayValues)`
    *   `[âœ…]` 102.b. [TYPES] Verify existing types are sufficient
        *   `[âœ…]` 102.b.i. `AssembleTurnPromptDeps` already defined at line 21-27
        *   `[âœ…]` 102.b.ii. `AssembleTurnPromptParams` already defined at line 29-35
        *   `[âœ…]` 102.b.iii. `DynamicContextVariables` already defined at line 115-127
        *   `[âœ…]` 102.b.iv. `RenderFn` already defined at line 14-19
    *   `[ðŸš«]` 102.c. [TEST-UNIT] Existing test at `assembleTurnPrompt.rendering.test.ts` proves the flaw (RED state)
        *   `[ðŸš«]` 102.c.i. Test passes `render` and `gatherContext` as DI deps (lines 466-472)
        *   `[ðŸš«]` 102.c.ii. Test expects `EXPECTED_RENDERED_CONTENT` with filled placeholders (lines 288-299)
        *   `[ðŸš«]` 102.c.iii. Current implementation ignores DI deps, causing test to fail
        *   `[âœ…]` 102.c.div. **Not an obligation of assembleTurnPrompt!** Unit test for `render.ts` provided in `render.test.ts` suite. 
    *   `[âœ…]` 102.d. [BE] Fix `assembleTurnPrompt` to use injected dependencies
        *   `[âœ…]` 102.d.i. Update function signature from `({ dbClient, fileManager, job, ... })` to `(deps, params)` pattern
        *   `[âœ…]` 102.d.ii. Replace direct `downloadFromStorage()` calls with `deps.downloadFromStorage()`
        *   `[âœ…]` 102.d.iii. Call `deps.gatherContext()` to build proper `DynamicContextVariables`
        *   `[âœ…]` 102.d.iv. Replace direct `renderPrompt()` call with `deps.render(renderPrompt, stage, dynamicContext, project.user_domain_overlay_values)`
        *   `[âœ…]` 102.d.v. Remove direct imports of `downloadFromStorage` and `renderPrompt`
    *   `[ðŸš«]` 102.e. [TEST-UNIT] Rerun `assembleTurnPrompt.rendering.test.ts` and verify GREEN state
        *   `[ðŸš«]` 102.e.i. Assert rendered prompt includes `role` value
        *   `[ðŸš«]` 102.e.ii. Assert rendered prompt includes `style_guide_markdown` value
        *   `[ðŸš«]` 102.e.iii. Assert rendered prompt includes `header_context` JSON
        *   `[ðŸš«]` 102.e.iv. Assert `result.promptContent` equals `EXPECTED_RENDERED_CONTENT`
        *   `[âœ…]` 102.e.v. **Not an obligation of assembleTurnPrompt!** Unit test for `render.ts` provided in `render.test.ts` suite. 
    *   `[âœ…]` 102.f. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 102.f.i. Function signature matches `(deps: AssembleTurnPromptDeps, params: AssembleTurnPromptParams)`
        *   `[âœ…]` 102.f.ii. All storage downloads use `deps.downloadFromStorage`
        *   `[âœ…]` 102.f.iii. Context gathering uses `deps.gatherContext`
        *   `[âœ…]` 102.f.iv. Rendering uses `deps.render` with proper overlay layering
        *   `[ðŸš«]` 102.f.v. No direct imports of functions that should be injected
        *   `[âœ…]` 102.f.vi. `RenderFn` expects `renderPromptFn` as a param so the function is imported to be supplied to the `deps.render` call. 
        *   `[âœ…]` 102.f.vii. Correcting `RenderFn` DI construction out of scope for this step. 
    *   `[âœ…]` 102.g. [COMMIT] `fix(be): assembleTurnPrompt uses DI for downloadFromStorage, gatherContext, and render`


*   `[âœ…]` 103. **selectAnchorForCanonicalPathParams** Select anchor document for canonical path params based on relevance
    *   `[âœ…]` 103.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 103.a.i. `selectAnchorForCanonicalPathParams(recipeStep: DialecticRecipeStep, sourceDocs: SourceDocument[])` in `helpers.ts` returns `SourceDocument | null`
        *   `[âœ…]` 103.a.ii. Consumed by: `planAllToOne` (step 104)
        *   `[âœ…]` 103.a.iii. Must access `recipeStep.inputs_required` to extract document-type input rules
        *   `[âœ…]` 103.a.iv. Must access `recipeStep.inputs_relevance` to build relevance map for document keys
        *   `[âœ…]` 103.a.v. Must use `deconstructStoragePath` to extract `document_key` from source document filenames
        *   `[âœ…]` 103.a.vi. Must match source documents by `stage` and `document_key` against `inputs_required` rules
    *   `[âœ…]` 103.b. [TYPES] Verify existing types are sufficient
        *   `[âœ…]` 103.b.i. `SourceDocument` interface already includes `stage`, `file_name`, `storage_path` fields
        *   `[âœ…]` 103.b.ii. `DialecticRecipeStep` interface already includes `inputs_required` and `inputs_relevance` arrays
        *   `[âœ…]` 103.b.iii. `deconstructStoragePath` utility already exists in `path_deconstructor.ts` and returns `documentKey` field
    *   `[âœ…]` 103.c. [TEST-UNIT] Unit tests for `selectAnchorForCanonicalPathParams` in `helpers.test.ts`
        *   `[âœ…]` 103.c.i. Assert: Given recipe step with `inputs_required` containing business_case (relevance 1.0) and feature_spec (relevance 0.9), and sourceDocs with matching documents, returns business_case document (highest relevance)
        *   `[âœ…]` 103.c.ii. Assert: Given recipe step with empty `inputs_relevance` array, returns `null` (no relevance metadata available)
        *   `[âœ…]` 103.c.iii. Assert: Given recipe step with no document inputs in `inputs_required`, returns `null`
        *   `[âœ…]` 103.c.iv. Assert: Given recipe step with document input but no matching source document (stage mismatch), returns `null`
        *   `[âœ…]` 103.c.v. Assert: Given recipe step with document input but no matching source document (document_key mismatch), returns `null`
        *   `[âœ…]` 103.c.vi. Assert: Given multiple document inputs with identical highest relevance, throws error with message indicating ambiguous selection
        *   `[âœ…]` 103.c.vii. Assert: Extracts `document_key` from source document filename using `deconstructStoragePath` for matching logic
        *   `[âœ…]` 103.c.viii. Assert: Matches source documents by both `stage` and extracted `document_key` from filename
    *   `[âœ…]` 103.d. [BE] Implement `selectAnchorForCanonicalPathParams` in `helpers.ts`
        *   `[âœ…]` 103.d.i. Extract document-type inputs from `recipeStep.inputs_required` array (filter for `type === 'document'`)
        *   `[âœ…]` 103.d.ii. If no document inputs found, return `null`
        *   `[âœ…]` 103.d.iii. Build relevance map from `recipeStep.inputs_relevance` array (map `document_key` to `relevance` number)
        *   `[âœ…]` 103.d.iv. If `inputs_relevance` is empty or undefined, return `null`
        *   `[âœ…]` 103.d.v. Find highest-relevance document input by iterating through document inputs and comparing relevance scores
        *   `[âœ…]` 103.d.vi. If multiple inputs have identical highest relevance, throw error with message listing tied document keys
        *   `[âœ…]` 103.d.vii. Extract `targetSlug` and `targetDocumentKey` from highest-relevance input rule
        *   `[âœ…]` 103.d.viii. Iterate through `sourceDocs` to find matching document
        *   `[âœ…]` 103.d.ix. For each source document, extract `document_key` from filename using `deconstructStoragePath({ storageDir: doc.storage_path, fileName: doc.file_name })`
        *   `[âœ…]` 103.d.x. Match source document where `doc.stage === targetSlug` AND extracted `document_key === targetDocumentKey`
        *   `[âœ…]` 103.d.xi. Return matched `SourceDocument` or `null` if no match found
    *   `[âœ…]` 103.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 103.e.i. Verify anchor selection works correctly for recipe steps with relevance metadata
        *   `[âœ…]` 103.e.ii. Verify returns `null` when no relevance metadata or no matching documents
        *   `[âœ…]` 103.e.iii. Verify error thrown for ambiguous relevance scores
        *   `[âœ…]` 103.e.iv. Verify document_key extraction from filename works correctly
    *   `[âœ…]` 103.f. [TEST-INT] Integration test with `planAllToOne` consumer
        *   `[âœ…]` 103.f.i. Assert: `planAllToOne` can call `selectAnchorForCanonicalPathParams` and receive anchor document for canonical path params
        *   `[âœ…]` 103.f.ii. Assert: When `selectAnchorForCanonicalPathParams` returns `null`, `planAllToOne` handles it correctly (passes `null` to `createCanonicalPathParams`)
    *   `[âœ…]` 103.g. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 103.g.i. Function selects highest-relevance document from `inputs_relevance` metadata
        *   `[âœ…]` 103.g.ii. Function extracts `document_key` from source document filenames for matching
        *   `[âœ…]` 103.g.iii. Function matches source documents by both `stage` and `document_key`
        *   `[âœ…]` 103.g.iv. Function returns `null` when no relevance metadata or no matching documents
        *   `[âœ…]` 103.g.v. Function throws error for ambiguous relevance scores (no silent fallback)
    *   `[âœ…]` 103.h. [COMMIT] `feat(dialectic): add selectAnchorForCanonicalPathParams helper for relevance-based anchor selection`

*   `[âœ…]` 104. **planAllToOne** Use `selectAnchorForCanonicalPathParams` for canonical path params when lineage anchor not required
    *   `[âœ…]` 104.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 104.a.i. `planAllToOne(sourceDocs, parentJob, recipeStep, _authToken)` in `planAllToOne.ts` returns `DialecticExecuteJobPayload[]`
        *   `[âœ…]` 104.a.ii. Depends on: `selectAnchorForCanonicalPathParams` (step 103)
        *   `[âœ…]` 104.a.iii. Depends on: `selectAnchorSourceDocument` (existing, for lineage anchor selection)
        *   `[âœ…]` 104.a.iv. Depends on: `createCanonicalPathParams` (existing, for building canonical path params)
        *   `[âœ…]` 104.a.v. Must handle PLAN branch (lines 52-168) and EXECUTE branch (lines 171-303)
    *   `[âœ…]` 104.b. [TYPES] Verify existing types are sufficient
        *   `[âœ…]` 104.b.i. `DialecticRecipeStep` interface already includes `inputs_relevance` array
        *   `[âœ…]` 104.b.ii. `SelectAnchorResult` type already includes `status: 'no_anchor_required'` variant
        *   `[âœ…]` 104.b.iii. `SourceDocument` type already compatible with `selectAnchorForCanonicalPathParams` return type
    *   `[âœ…]` 104.c. [TEST-UNIT] Unit tests for `planAllToOne` PLAN branch canonical path params in `planAllToOne.test.ts`
        *   `[âœ…]` 104.c.i. Assert: Given PLAN job with `all_to_one`, `inputs_relevance` with business_case relevance 1.0, and thesis document with filename `gpt-4_0_business_case.md`, `canonicalPathParams.sourceAnchorModelSlug` equals `'gpt-4'` (extracted from filename)
        *   `[âœ…]` 104.c.ii. Assert: Given PLAN job with `all_to_one` and empty `inputs_relevance`, `canonicalPathParams.sourceAnchorModelSlug` is `undefined` (no anchor available)
        *   `[âœ…]` 104.c.iii. Assert: Given PLAN job with `all_to_one`, seed_prompt as first sourceDoc, and thesis documents with relevance scores, selects highest-relevance thesis document (not seed_prompt) for canonical path params
        *   `[âœ…]` 104.c.iv. Assert: Given PLAN job with `all_to_one` and multiple thesis documents with different relevance scores, selects document with highest relevance (1.0) for canonical path params
        *   `[âœ…]` 104.c.v. Assert: Given PLAN job with `all_to_one` and `inputs_relevance` but no matching source documents, `canonicalPathParams.sourceAnchorModelSlug` is `undefined`
    *   `[âœ…]` 104.d. [TEST-UNIT] Unit tests for `planAllToOne` EXECUTE branch canonical path params in `planAllToOne.test.ts`
        *   `[âœ…]` 104.d.i. Assert: Given EXECUTE job with document inputs and `inputs_relevance`, `canonicalPathParams.sourceAnchorModelSlug` is extracted from highest-relevance document filename
        *   `[âœ…]` 104.d.ii. Assert: Given EXECUTE job with `per_model` granularity (consolidation) and `inputs_relevance`, `canonicalPathParams.sourceAnchorModelSlug` is extracted from highest-relevance document filename
        *   `[âœ…]` 104.d.iii. Assert: Given EXECUTE job with empty `inputs_relevance`, `canonicalPathParams.sourceAnchorModelSlug` is `undefined`
    *   `[âœ…]` 104.e. [TEST-UNIT] Unit test for error handling when relevance metadata missing in `planAllToOne.test.ts`
        *   `[âœ…]` 104.e.i. Assert: Given PLAN job with `all_to_one`, document inputs in `inputs_required`, but empty `inputs_relevance` array, throws error (no silent fallback to ordering heuristic)
    *   `[âœ…]` 104.f. [BE] Update `planAllToOne` PLAN branch to use `selectAnchorForCanonicalPathParams`
        *   `[âœ…]` 104.f.i. After calling `selectAnchorSourceDocument` (line 125), check if `anchorResult.status === 'no_anchor_required'`
        *   `[âœ…]` 104.f.ii. When `anchorResult.status === 'no_anchor_required'` AND `recipeStep.inputs_relevance` exists and has entries, call `selectAnchorForCanonicalPathParams(recipeStep, sourceDocs)`
        *   `[âœ…]` 104.f.iii. Use returned anchor document (or `null`) as `anchorForCanonicalPathParams` for `createCanonicalPathParams` call (line 153)
        *   `[âœ…]` 104.f.iv. Preserve existing behavior: `document_relationships.source_group` still uses `anchorDocument.id` (first sourceDoc, line 34) for lineage
        *   `[âœ…]` 104.f.v. Preserve existing behavior: `sourceContributionId` still uses `anchorDocument.id` (line 149) for lineage tracking
    *   `[âœ…]` 104.g. [BE] Update `planAllToOne` EXECUTE branch to use `selectAnchorForCanonicalPathParams`
        *   `[âœ…]` 104.g.i. After calling `selectAnchorSourceDocument` (line 262), check if `anchorResult.status === 'no_anchor_required'`
        *   `[âœ…]` 104.g.ii. When `anchorResult.status === 'no_anchor_required'` AND `recipeStep.inputs_relevance` exists and has entries, call `selectAnchorForCanonicalPathParams(recipeStep, sourceDocs)`
        *   `[âœ…]` 104.g.iii. Use returned anchor document (or `null`) as `anchorForCanonicalPathParams` for `createCanonicalPathParams` call (line 289)
        *   `[âœ…]` 104.g.iv. Preserve existing behavior: `document_relationships.source_group` still uses `anchorDocument.id` (line 293) for lineage
        *   `[âœ…]` 104.g.v. Preserve existing behavior: `sourceContributionId` still uses `anchorDocument.id` (line 285) for lineage tracking
    *   `[âœ…]` 104.h. [BE] Add error handling for missing relevance metadata in `planAllToOne`
        *   `[âœ…]` 104.h.i. When `anchorResult.status === 'no_anchor_required'` AND document inputs exist in `inputs_required` BUT `inputs_relevance` is empty or undefined, throw error indicating missing relevance metadata
        *   `[âœ…]` 104.h.ii. Error message should indicate that recipe has document inputs but no relevance metadata (no fallback to ordering)
    *   `[âœ…]` 104.i. [TEST-UNIT] Rerun `planAllToOne.test.ts` and verify all tests pass
        *   `[âœ…]` 104.i.i. Verify "planAllToOne extracts sourceAnchorModelSlug from thesis document filename when creating HeaderContext for antithesis stage, not from seed_prompt" test passes (line 1110)
        *   `[âœ…]` 104.i.ii. Verify "planAllToOne PLAN branch uses relevance-selected anchor for canonical path params" test passes (line 1346)
        *   `[âœ…]` 104.i.iii. Verify "planAllToOne throws when recipe lacks relevance metadata" test passes (line 1766)
        *   `[âœ…]` 104.i.iv. Verify no regressions in existing `planAllToOne` behavior
    *   `[âœ…]` 104.j. [TEST-INT] Integration test with canonical path params
        *   `[âœ…]` 104.j.i. Assert: PLAN job with `all_to_one` creates EXECUTE job with `canonicalPathParams.sourceAnchorModelSlug` extracted from highest-relevance source document filename
        *   `[âœ…]` 104.j.ii. Assert: EXECUTE job with `per_model` creates job with `canonicalPathParams.sourceAnchorModelSlug` extracted from highest-relevance source document filename
        *   `[âœ…]` 104.j.iii. Assert: File paths generated using `canonicalPathParams` correctly include model slug from anchor document
    *   `[âœ…]` 104.k. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 104.k.i. `planAllToOne` selects anchor document for canonical path params based on `inputs_relevance` even when lineage anchor is not required
        *   `[âœ…]` 104.k.ii. `sourceAnchorModelSlug` is extracted from highest-relevance document filename, not from seed_prompt or first document
        *   `[âœ…]` 104.k.iii. When `inputs_relevance` is empty but document inputs exist, function throws error (no silent fallback)
        *   `[âœ…]` 104.k.iv. Lineage tracking (`source_group`, `sourceContributionId`) remains unchanged and uses first sourceDoc or anchorDocument
        *   `[âœ…]` 104.k.v. Canonical path params anchor selection is independent of lineage anchor selection
    *   `[âœ…]` 104.l. [COMMIT] `fix(dialectic): planAllToOne selects anchor for canonical path params when lineage anchor not required`

*   `[ ]` 105. **processComplexJob** Schedule jobs with waiting_for_prerequisite for steps with missing intra-stage dependencies
    *   `[âœ…]` 105.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 105.a.i. `processComplexJob(dbClient, job, projectOwnerUserId, ctx, authToken)` in `processComplexJob.ts` returns `Promise<void>`
        *   `[âœ…]` 105.a.ii. Uses existing `ctx.planComplexStage` function (no signature changes required)
        *   `[âœ…]` 105.a.iii. Must access `stepIdToStep` Map to find prerequisite-producing steps by matching `output_type` to missing `document_key`
        *   `[âœ…]` 105.a.iv. Must access `filteredReadySteps` to identify steps that will be planned in this batch
        *   `[âœ…]` 105.a.v. Must access `completedStepSlugs` Set to identify already-completed prerequisite steps
        *   `[âœ…]` 105.a.vi. Must call `ctx.findSourceDocuments` to verify prerequisite availability and catch errors for missing inputs
        *   `[âœ…]` 105.a.vii. Must find prerequisite-producing job ID from `childJobs` array (after planning) by matching `planner_metadata.recipe_step_id` to prerequisite step ID
    *   `[âœ…]` 105.b. [TYPES] Verify existing types support status and prerequisite_job_id
        *   `[âœ…]` 105.b.i. Confirm `DialecticJobRow` interface includes `status` field with `'waiting_for_prerequisite'` as valid value
        *   `[âœ…]` 105.b.ii. Confirm `DialecticJobRow` interface includes `prerequisite_job_id` field (UUID or null)
        *   `[âœ…]` 105.b.iii. Confirm `DialecticJobRow` objects can be modified after creation (mutable status and prerequisite_job_id fields)
    *   `[âœ…]` 105.c. [TEST-UNIT] Unit tests for prerequisite step identification and job modification
        *   `[âœ…]` 105.c.i. Assert: Given step with missing intra-stage dependency (e.g., `generate-master-plan` missing `technical_requirements`), identifies prerequisite-producing step in `stepIdToStep` where `output_type === 'technical_requirements'`
        *   `[âœ…]` 105.c.ii. Assert: Given a completed prerequisite step, throws an error if its output document is not found (fail loud)
        *   `[âœ…]` 105.c.iii. Assert: Given prerequisite step is in `filteredReadySteps`, verifies prerequisite will be planned in this batch and schedules job with `waiting_for_prerequisite` status
        *   `[âœ…]` 105.c.iv. Assert: Given step with missing intra-stage dependency but prerequisite step not found in recipe, throws error (cannot schedule safely)
        *   `[âœ…]` 105.c.v. Assert: After planning prerequisite step, finds prerequisite job ID from `childJobs` array by matching `planner_metadata.recipe_step_id` to prerequisite step ID
        *   `[âœ…]` 105.c.vi. Assert: Waiting jobs created by `planComplexStage` are modified to have `status: 'waiting_for_prerequisite'` and `prerequisite_job_id` set before insertion
        *   `[âœ…]` 105.c.vii. Assert: Steps with available inputs are still planned normally with `status: 'pending'`
    *   `[âœ…]` 105.d. [BE] Implement prerequisite step identification and job modification in processComplexJob
        *   `[âœ…]` 105.d.i. Create separate list `stepsWithPrerequisiteDeps` for steps with missing intra-stage dependencies that have verifiable prerequisites
        *   `[âœ…]` 105.d.ii. In catch block (line 398), extract missing `document_key` from error message or by identifying which input rule failed
        *   `[âœ…]` 105.d.iii. Search `stepIdToStep` Map to find prerequisite-producing step where `output_type === missing_document_key`
        *   `[âœ…]` 105.d.iv. Verify prerequisite step exists in recipe instance (throw error if not found - cannot schedule safely)
        *   `[âœ…]` 105.d.v. Verify prerequisite step is in `filteredReadySteps` (will be available)
        *   `[âœ…]` 105.d.vi. If verified, add step to `stepsWithPrerequisiteDeps` instead of filtering out completely
        *   `[âœ…]` 105.d.vii. After planning `stepsWithAvailableInputs` (line 431), get `childJobs` array from `plannedChildrenArrays.flat()`
        *   `[âœ…]` 105.d.viii. For each step in `stepsWithPrerequisiteDeps`, call `planComplexStage` to get waiting job objects
        *   `[âœ…]` 105.d.ix. For each waiting job, find prerequisite-producing job ID from `childJobs` array by matching `planner_metadata.recipe_step_id` to prerequisite step ID
        *   `[âœ…]` 105.d.x. Modify waiting job objects: set `status: 'waiting_for_prerequisite'` and `prerequisite_job_id: prerequisiteJobId`
        *   `[âœ…]` 105.d.xi. Add modified waiting jobs to `childJobs` array before insertion (line 467)
    *   `[âœ…]` 105.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 105.e.i. Verify steps with missing intra-stage deps are scheduled with `waiting_for_prerequisite` status (not filtered out)
        *   `[âœ…]` 105.e.ii. Verify waiting jobs have correct `status: 'waiting_for_prerequisite'` and `prerequisite_job_id` set before insertion
        *   `[âœ…]` 105.e.iii. Verify no regressions in existing `processComplexJob` behavior for steps with available inputs
    *   `[ ]` 105.f. [TEST-INT] Integration test with handle_job_completion transition
        *   `[ ]` 105.f.i. Assert: When prerequisite job completes, `handle_job_completion` transitions waiting job from `waiting_for_prerequisite` to `pending`
        *   `[ ]` 105.f.ii. Assert: Parenthesis stage with `generate-technical_requirements` completing triggers `generate-master-plan` job to transition from `waiting_for_prerequisite` to `pending`
        *   `[ ]` 105.f.iii. Assert: Parent PLAN job can complete properly once all child jobs (including waiting ones) are scheduled
    *   `[âœ…]` 105.g. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 105.g.i. Steps with missing intra-stage dependencies are scheduled with `waiting_for_prerequisite` status instead of being filtered out
        *   `[âœ…]` 105.g.ii. Jobs with `waiting_for_prerequisite` have `prerequisite_job_id` set to the prerequisite-producing job ID
        *   `[âœ…]` 105.g.iii. When prerequisite job completes, `handle_job_completion` automatically transitions waiting job to `pending`
        *   `[âœ…]` 105.g.iv. Parent PLAN job can complete properly once all child jobs (including waiting ones) are scheduled
        *   `[âœ…]` 105.g.v. No steps are permanently skipped due to intra-stage dependencies
        *   `[âœ…]` 105.g.vi. No function signature changes required - uses existing `planComplexStage` as-is
    *   `[âœ…]` 105.h. [COMMIT] `fix(dialectic): schedule jobs with waiting_for_prerequisite for intra-stage dependencies`

*   `[âœ…]` 106. **processComplexJob** Create skeleton PLAN jobs for steps with missing intra-stage prerequisites; handle deferred planning when skeleton returns
    *   `[âœ…]` 106.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 106.a.i. `processComplexJob(dbClient, job, projectOwnerUserId, ctx, authToken)` in `processComplexJob.ts` returns `Promise<void>`
        *   `[âœ…]` 106.a.ii. Current bug: lines 535-542 call `ctx.planComplexStage` for steps in `stepsWithPrerequisiteDeps`, but `planComplexStage` calls `findSourceDocuments` which throws when prerequisite documents don't exist yet
        *   `[âœ…]` 106.a.iii. Fix: Create skeleton PLAN job with `waiting_for_prerequisite` status; when it returns after prereq completes, call `planComplexStage` then
        *   `[âœ…]` 106.a.iv. Skeleton jobs must include: `status: 'waiting_for_prerequisite'`, `prerequisite_job_id`, `job_type: 'PLAN'`, `planner_metadata.recipe_step_id`
        *   `[âœ…]` 106.a.v. Must inherit payload fields from parent job: `projectId`, `sessionId`, `stageSlug`, `iterationNumber`, `model_id`, `user_jwt`, `walletId`
        *   `[âœ…]` 106.a.vi. Detection: `job.prerequisite_job_id !== null` at start of `processComplexJob` indicates deferred single-step planning
    *   `[âœ…]` 106.b. [TEST-UNIT] Unit tests for skeleton PLAN job creation in `processComplexJob.intraStageDependency.test.ts`
        *   `[âœ…]` 106.b.i. Assert: `planComplexStage` is NOT called for steps in `stepsWithPrerequisiteDeps` during initial processing
        *   `[âœ…]` 106.b.ii. Assert: Skeleton PLAN job is created with `status: 'waiting_for_prerequisite'` and `job_type: 'PLAN'`
        *   `[âœ…]` 106.b.iii. Assert: Skeleton job has `prerequisite_job_id` set to the prerequisite-producing job ID
        *   `[âœ…]` 106.b.iv. Assert: Skeleton job has `planner_metadata.recipe_step_id` set to the step ID
        *   `[âœ…]` 106.b.v. Assert: Skeleton job inherits required payload fields from parent job
    *   `[âœ…]` 106.c. [TEST-UNIT] Unit tests for deferred planning when skeleton PLAN job returns
        *   `[âœ…]` 106.c.i. Assert: When `job.prerequisite_job_id !== null`, detects deferred single-step planning
        *   `[âœ…]` 106.c.ii. Assert: Fetches recipe step using `planner_metadata.recipe_step_id`
        *   `[âœ…]` 106.c.iii. Assert: Calls `findSourceDocuments` for the deferred step (now succeeds since prereq exists)
        *   `[âœ…]` 106.c.iv. Assert: Calls `planComplexStage` for the deferred step
        *   `[âœ…]` 106.c.v. Assert: Inserts resulting EXECUTE job(s) with `pending` status
    *   `[âœ…]` 106.d. [BE] Implement skeleton PLAN job creation in `processComplexJob.ts`
        *   `[âœ…]` 106.d.i. Remove `planComplexStage` call for steps in `stepsWithPrerequisiteDeps` (lines 535-542)
        *   `[âœ…]` 106.d.ii. Build skeleton PLAN job object with: `id: crypto.randomUUID()`, `status: 'waiting_for_prerequisite'`, `job_type: 'PLAN'`
        *   `[âœ…]` 106.d.iii. Set `prerequisite_job_id` to the ID of the prerequisite-producing job from `childJobs` array
        *   `[âœ…]` 106.d.iv. Set `payload.planner_metadata: { recipe_step_id: step.id }`
        *   `[âœ…]` 106.d.v. Inherit payload fields: `projectId`, `sessionId`, `stageSlug`, `iterationNumber`, `model_id`, `user_jwt`, `walletId`
        *   `[âœ…]` 106.d.vi. Add skeleton PLAN job to `childJobs` array before insertion
    *   `[âœ…]` 106.e. [BE] Implement deferred planning handler at start of `processComplexJob.ts`
        *   `[âœ…]` 106.e.i. Add early check: if `job.prerequisite_job_id !== null`, enter deferred planning block
        *   `[âœ…]` 106.e.ii. Fetch recipe step from database using `job.payload.planner_metadata.recipe_step_id`
        *   `[âœ…]` 106.e.iii. Call `findSourceDocuments` for the recipe step (prereq document now exists)
        *   `[âœ…]` 106.e.iv. Call `planComplexStage` for the recipe step to create EXECUTE job(s)
        *   `[âœ…]` 106.e.v. Insert resulting EXECUTE jobs with `pending` status
        *   `[âœ…]` 106.e.vi. Mark current skeleton PLAN job as `completed` and return early
    *   `[âœ…]` 106.f. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 106.f.i. Verify `planComplexStage` is not called for steps with missing prerequisites during initial processing
        *   `[âœ…]` 106.f.ii. Verify skeleton PLAN jobs have correct structure and payload
        *   `[âœ…]` 106.f.iii. Verify deferred planning handler correctly processes returned skeleton jobs
        *   `[âœ…]` 106.f.iv. Verify no regressions in existing `processComplexJob` behavior
    *   `[âœ…]` 106.g. [TEST-INT] Integration test with prerequisite completion flow
        *   `[âœ…]` 106.g.i. Assert: Skeleton PLAN job is inserted with `waiting_for_prerequisite` status
        *   `[âœ…]` 106.g.ii. Assert: When prerequisite EXECUTE job completes, skeleton PLAN job transitions to `pending`
        *   `[âœ…]` 106.g.iii. Assert: Skeleton PLAN job returns through `processComplexJob` and creates EXECUTE jobs
        *   `[âœ…]` 106.g.iv. Assert: Parenthesis stage completes with `generate-master-plan` executing after `generate-technical_requirements`
    *   `[âœ…]` 106.h. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 106.h.i. `planComplexStage` is never called for steps with missing intra-stage prerequisites during initial processing
        *   `[âœ…]` 106.h.ii. Skeleton PLAN jobs are created with `waiting_for_prerequisite` status
        *   `[âœ…]` 106.h.iii. `prerequisite_job_id !== null` detection routes skeleton jobs to deferred planning handler
        *   `[âœ…]` 106.h.iv. Deferred planning calls `findSourceDocuments` and `planComplexStage` when prereq is complete
        *   `[âœ…]` 106.h.v. No `findSourceDocuments` errors for steps with missing prerequisites
        *   `[âœ…]` 106.h.vi. All changes contained within `processComplexJob.ts` - no changes to `processSimpleJob.ts`
    *   `[âœ…]` 106.i. [COMMIT] `fix(dialectic): processComplexJob creates skeleton PLAN jobs and handles deferred planning`

*   `[ ]` 107. **processComplexJob** Eliminate duplicate deferred planning by introducing a dedicated `DialecticSkeletonJobPayload` (required `step_info`, required `planner_metadata`) so skeleton PLAN jobs complete cleanly and Parenthesis produces exactly nÃ—3 documents
    *   `[âœ…]` 107.a. [DEPS] Dependencies and target behavior
        *   `[âœ…]` 107.a.i. `processComplexJob(dbClient, job, projectOwnerUserId, ctx, authToken)` in `supabase/functions/dialectic-worker/processComplexJob.ts` creates skeleton PLAN jobs for missing intra-stage prerequisites, and later performs deferred planning when the skeleton returns.
        *   `[âœ…]` 107.a.ii. The DB trigger `handle_job_completion()` uses `payload.step_info.current_step` and `payload.step_info.total_steps` to decide whether a parent job becomes `completed` or wakes as `pending_next_step` (see `supabase/migrations/20260109165706_state_machine_fix.sql`).
        *   `[âœ…]` 107.a.iii. Target state: skeleton PLAN jobs are **single-step** (`step_info.current_step=1`, `step_info.total_steps=1`) so after their child jobs finish they can be marked `completed` instead of re-woken, preventing duplicate planning and storage collisions.
        *   `[âœ…]` 107.a.iv. Integration target: `supabase/integration_tests/services/dialectic_full_dag_traversal.integration.test.ts` step `99.b.vi` must observe **exactly** `nÃ—3` Parenthesis planning documents (for `n=3`, exactly 9; not 21).
    *   `[âœ…]` 107.b. [TYPES] Add a dedicated skeleton payload type with required keys (no casts, no inline types)
        *   `[âœ…]` 107.b.i. In `supabase/functions/dialectic-service/dialectic.interface.ts`, introduce `DialecticSkeletonJobPayload` with required fields needed to construct a complete skeleton PLAN job payload, including:
        *   `[âœ…]` 107.b.ii Required job identity fields used by the worker: `projectId`, `sessionId`, `model_id`, `walletId`, `user_jwt`, `stageSlug`, `iterationNumber`.
        *   `[âœ…]` 107.b.iii Required skeleton-specific fields `planner_metadata` & `step_info`.
        *   `[âœ…]` 107.b.iv. Update the `DialecticJobPayload` union type in `dialectic.interface.ts` to include `DialecticSkeletonJobPayload` so it can be validated and carried through the system without casts.
        *   `[âœ…]` 107.b.v. Update `DialecticPlanJobPayload` in `dialectic.interface.ts` so `planner_metadata` is no longer present there (the skeleton payload owns it), and ensure any production usage sites that require `planner_metadata.recipe_step_id` are updated to depend on the correct payload type instead.
        *   `[âœ…]` 107.b.vi. [TYPE-GUARD-TEST] In `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.test.ts`, add tests proving:
            *   `[âœ…]` 107.b.vi.A `isDialecticSkeletonJobPayload` returns true only when `step_info` is present and `planner_metadata.recipe_step_id` is a non-empty string.
            *   `[âœ…]` 107.b.vi.B `isDialecticPlanJobPayload` rejects payloads that include `planner_metadata` (since it is no longer part of that payload type).
        *   `[âœ…]` 107.b.vii. [TYPE-GUARDS] In `supabase/functions/_shared/utils/type-guards/type_guards.dialectic.ts`, implement `isDialecticSkeletonJobPayload` and update `isDialecticPlanJobPayload` to match the new contract.
    *   `[âœ…]` 107.c. [TEST-UNIT] Update unit test to assert the target skeleton payload contract
        *   `[âœ…]` 107.c.i. In `supabase/functions/dialectic-worker/processComplexJob.intraStageDependency.test.ts`, assert the inserted skeleton PLAN job payload satisfies `isDialecticSkeletonJobPayload`, and that `payload.step_info.current_step === 1` and `payload.step_info.total_steps === 1`.
    *   `[âœ…]` 107.d. [BE] Update skeleton PLAN job creation to use the new payload type (no casts)
        *   `[âœ…]` 107.d.i. In `supabase/functions/dialectic-worker/processComplexJob.ts`, construct `DialecticSkeletonJobPayload` using explicitly typed intermediates (e.g. a `DialecticStepInfo` object and `DialecticStepPlannerMetadataWithRecipeStepId` object).
        *   `[âœ…]` 107.d.ii. Ensure `stageSlug` and `iterationNumber` are set explicitly and reliably (prefer DB row columns; fail loudly if missing), so the skeleton payload is complete without optional defaults.
        *   `[âœ…]` 107.d.iii. Ensure `payload.step_info` is set to `{ current_step: 1, total_steps: 1 }` for every skeleton PLAN job.
        *   `[âœ…]` 107.d.iv. Ensure the workerâ€™s payload validation accepts skeleton PLAN jobs and continues to validate non-skeleton PLAN jobs without weakening typing.
    *   `[âœ…]` 107.e. [TEST-UNIT] Rerun and expand tests proving the fix
        *   `[âœ…]` 107.e.i. Verify `processComplexJob.intraStageDependency.test.ts` passes and no other unit tests regress.
    *   `[ ]` 107.f. [TEST-INT] Prove Parenthesis no longer duplicates work
        *   `[ ]` 107.f.i. Run `supabase/integration_tests/services/dialectic_full_dag_traversal.integration.test.ts` and confirm step `99.b.vi` passes with exactly `nÃ—3` Parenthesis documents (for `n=3`, exactly 9).
    *   `[ ]` 107.g. [CRITERIA] Acceptance criteria
        *   `[ ]` 107.g.i. Skeleton PLAN job payloads are strictly typed as `DialecticSkeletonJobPayload` and include required `step_info` and required `planner_metadata.recipe_step_id`.
        *   `[ ]` 107.g.ii. Parenthesis integration test step `99.b.vi` produces exactly the expected number of rendered Parenthesis documents (no duplicates).
        *   `[ ]` 107.g.iii. No casts (`as`/`any`) and no inline types introduced; all new types live in `dialectic.interface.ts` and are enforced by type guards.
    *   `[ ]` 107.h. [COMMIT] `fix(dialectic): make skeleton plan payload explicit to prevent duplicate deferred planning`

*   `[âœ…]` 108. **resolveNextBlocker** Create helper function to dynamically resolve the job that will produce a required artifact
    *   `[âœ…]` 108.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 108.a.i. Code standards:
            *   `[âœ…]` 108.a.i.A Function signature MUST be `(deps, params)` with both objects explicitly typed
            *   `[âœ…]` 108.a.i.B All dependencies MUST be injected via `deps` (no direct imports for side-effectful collaborators)
            *   `[âœ…]` 108.a.i.C Return type MUST be explicitly annotated
        *   `[âœ…]` 108.a.ii. `resolveNextBlocker(deps: ResolveNextBlockerDeps, params: ResolveNextBlockerParams): Promise<ResolveNextBlockerResult | null>` in `supabase/functions/dialectic-worker/resolveNextBlocker.ts`
            *   `ResolveNextBlockerResult = { id: string; job_type: string; status: string }`
            *   `ResolveNextBlockerDeps` MUST include: `dbClient`, `logger` (and any recipe-step lookup dependency if needed for PLAN matching)
            *   `ResolveNextBlockerParams` MUST include: `projectId`, `sessionId`, `stageSlug`, `iterationNumber`, `modelSlug`, `requiredArtifactIdentity`
        *   `[âœ…]` 108.a.ii. Consumed by: `processComplexJob` deferred planning handler (step 109)
        *   `[âœ…]` 108.a.iii. Requires: Supabase client to query `dialectic_generation_jobs` table
        *   `[âœ…]` 108.a.iv. Required artifact identity MUST be *PathContext-inspired*, but it is NOT the same as `PathContext`.
            *   Rationale: `PathContext` is for constructing concrete storage paths and requires fields like `fileType` / `attemptCount` for documents, and it uses `modelSlug` (stable) rather than `modelId` (may change across sync runs).
            *   Define a separate `RequiredArtifactIdentity` that carries only what we reliably know at scheduling time (and what is stable/idempotent).
            *   Minimum required fields MUST include: `projectId`, `sessionId`, `stageSlug`, `iterationNumber`, `modelSlug`, `documentKey`.
            *   If additional disambiguation is needed (e.g. parallel lineage branches), add `branchKey`, `parallelGroup`, and/or `sourceGroupFragment` consistent with your path semantics.
            *   If you must persist it, persist as JSON (`results.required_artifact_identity`) â€” never a colon-delimited string.
        *   `[âœ…]` 108.a.v. Resolution priority: RENDER jobs > EXECUTE jobs > PLAN jobs (closer to artifact = higher priority)
        *   `[âœ…]` 108.a.vi. Scope MUST be model-safe and project-safe:
            *   Filter by `session_id`, `stage_slug`, `iteration_number`, AND stable model identity (`modelSlug` in payload/canonicalPathParams/pathContext) so Model A never blocks Model B.
            *   If existing job queries elsewhere are scoped to `project_id`, this helper MUST be too (prefer DB column; otherwise filter by `payload.projectId`).
        *   `[âœ…]` 108.a.vii. Matching logic MUST align to real payload contracts (no generic heuristics):
            *   RENDER: match the artifact/documentKey the render job will publish (prefer a dedicated render payload field; otherwise derive from canonical path params / render metadata used by your renderer).
            *   EXECUTE: match `payload.output_type` (preferred) or `payload.canonicalPathParams.contributionType` (fallback) against `documentKey`.
            *   PLAN: match `payload.planner_metadata.recipe_step_id` â†’ recipe step `output_type === documentKey`.
    *   `[âœ…]` 108.b. [TYPES] Verify existing types are sufficient
        *   `[âœ…]` 108.b.i. Confirm `DialecticJobRow` interface in `dialectic.interface.ts` includes `id`, `job_type`, `status`, `payload` fields for querying
        *   `[âœ…]` 108.b.ii. Introduce explicit types local to the worker module (no inline types in call sites):
            *   `ResolveNextBlockerDeps`
            *   `ResolveNextBlockerParams`
            *   `ResolveNextBlockerResult`
            *   `RequiredArtifactIdentity` (PathContext-inspired; includes stable `modelSlug`)
    *   `[âœ…]` 108.c. [TEST-UNIT] Unit tests for `resolveNextBlocker` in `supabase/functions/dialectic-worker/resolveNextBlocker.test.ts`
        *   `[âœ…]` 108.c.i. Assert: Given pending RENDER job for model C producing `master_plan` and `requiredArtifactKey` scoped to model C, returns that RENDER job (and never returns model A/B jobs)
        *   `[âœ…]` 108.c.ii. Assert: Given pending EXECUTE job (no RENDER) for model C producing `master_plan`, returns that EXECUTE job
        *   `[âœ…]` 108.c.iii. Assert: Given pending PLAN job (no EXECUTE, no RENDER) with recipe step producing `master_plan`, returns that PLAN job
        *   `[âœ…]` 108.c.iv. Assert: Given both pending RENDER and EXECUTE jobs for same artifact, returns RENDER job (higher priority)
        *   `[âœ…]` 108.c.v. Assert: Given completed RENDER job (not in-progress), does NOT return it; continues to check EXECUTE/PLAN
        *   `[âœ…]` 108.c.vi. Assert: Given no jobs producing the required artifact, returns `null`
        *   `[âœ…]` 108.c.vii. Assert: Given `requiredArtifactKey === null` or empty string, returns `null` without querying
        *   `[âœ…]` 108.c.viii. Assert: Correctly parses `"{projectId}:{sessionId}:{stageSlug}:{iterationNumber}:{modelId}:{artifactClass}:{documentKey}"` to extract all fields for scoping + matching
        *   `[âœ…]` 108.c.ix. Assert: Jobs with `status` in `['pending', 'processing', 'retrying', 'waiting_for_children', 'waiting_for_prerequisite']` are considered in-progress blockers
    *   `[âœ…]` 108.d. [BE] Implement `resolveNextBlocker` in `supabase/functions/dialectic-worker/resolveNextBlocker.ts`
        *   `[âœ…]` 108.d.i. Accept a typed `requiredArtifactIdentity` object (PathContext-shaped) and avoid string parsing
        *   `[âœ…]` 108.d.ii. Return `null` early if identity is missing required fields (project/session/stage/iteration/modelSlug/documentKey)
        *   `[âœ…]` 108.d.iii. Define `inProgressStatuses` array: `['pending', 'processing', 'retrying', 'waiting_for_children', 'waiting_for_prerequisite']`
        *   `[âœ…]` 108.d.iv. Query RENDER jobs: `SELECT id, job_type, status, payload FROM dialectic_generation_jobs WHERE session_id = ? AND stage_slug = ? AND iteration_number = ? AND job_type = 'RENDER' AND status IN (inProgressStatuses)` (and ALSO scope to `project_id` if available). Filter results by `modelSlug` from payload.
        *   `[âœ…]` 108.d.v. Filter RENDER results by `payloadProducesDocumentKey(payload, documentKey)`; if match found, return it
        *   `[âœ…]` 108.d.vi. Query EXECUTE jobs: same WHERE clause but `job_type = 'EXECUTE'`
        *   `[âœ…]` 108.d.vii. Filter EXECUTE results by `payloadProducesDocumentKey(payload, documentKey)`; if match found, return it
        *   `[âœ…]` 108.d.viii. Query PLAN jobs: same WHERE clause but `job_type = 'PLAN'`
        *   `[âœ…]` 108.d.ix. Filter PLAN results by `payloadProducesDocumentKey(payload, documentKey)` (check `planner_metadata.recipe_step_id` maps to step with `output_type === documentKey`); if match found, return it
        *   `[âœ…]` 108.d.x. If no matches at any level, return `null`
        *   `[âœ…]` 108.d.xi. Implement helper `jobProducesDocumentKey(job, documentKey, artifactClass)` with job_type-specific matching:
            *   RENDER: match what the render job will write (MUST align to renderer payload contract)
            *   EXECUTE: match `payload.output_type` (preferred), fallback to `payload.canonicalPathParams?.contributionType`
            *   PLAN: match `payload.planner_metadata.recipe_step_id` â†’ recipe step `output_type`
    *   `[âœ…]` 108.e. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 108.e.i. Verify RENDER > EXECUTE > PLAN priority ordering
        *   `[âœ…]` 108.e.ii. Verify in-progress status filtering works correctly
        *   `[âœ…]` 108.e.iii. Verify artifact key parsing handles edge cases
    *   `[âœ…]` 108.f. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 108.f.i. Function returns the job closest to producing the required artifact (RENDER preferred over EXECUTE preferred over PLAN)
        *   `[âœ…]` 108.f.ii. Function only returns jobs that are in-progress (not completed or failed)
        *   `[âœ…]` 108.f.iii. Function uses PathContext-inspired identity (stable `modelSlug`) and enforces model-safe + project-safe scoping
        *   `[âœ…]` 108.f.iv. Function returns `null` when no producing job exists
        *   `[âœ…]` 108.f.v. Function is pure DB query + filter logic; no side effects
    *   `[âœ…]` 108.g. [COMMIT] `feat(dialectic): add resolveNextBlocker helper for artifact-driven prerequisite resolution`

*   `[âœ…]` 109. **processComplexJob** Implement artifact-driven prerequisite resolution with idempotent re-wait logic
    *   `[âœ…]` 109.a. [DEPS] Dependencies and signature
        *   `[âœ…]` 109.a.i. `processComplexJob(dbClient, job, projectOwnerUserId, ctx, authToken)` in `supabase/functions/dialectic-worker/processComplexJob.ts` already exists
        *   `[âœ…]` 109.a.ii. Depends on: `resolveNextBlocker` (step 108) for dynamic blocker resolution
        *   `[âœ…]` 109.a.iii. Uses existing `results` JSONB column to store a PathContext-shaped `required_artifact_identity` on skeleton jobs (no schema change required)
        *   `[âœ…]` 109.a.iv. Skeleton job creation (lines 716-766) must store `required_artifact_identity` in `results` field (typed object, not a string)
        *   `[âœ…]` 109.a.v. Deferred planning handler (lines 170-261) must read `required_artifact_identity` from `job.results` and use `resolveNextBlocker` to find next blocker
        *   `[âœ…]` 109.a.vi. Current hack at lines 191-215 (check for pending RENDER child) is replaced by general `resolveNextBlocker` call
    *   `[âœ…]` 109.b. [TYPES] No new types required
        *   `[âœ…]` 109.b.i. `results` column is `Json | null` which accepts `{ required_artifact_identity: RequiredArtifactIdentity }`
        *   `[âœ…]` 109.b.ii. `isRecord` type guard from `type_guards.ts` can validate `job.results` shape; add/extend a guard if needed for `RequiredArtifactIdentity`
    *   `[âœ…]` 109.c. [TEST-UNIT] Unit tests for skeleton job creation storing `required_artifact_key` in `supabase/functions/dialectic-worker/processComplexJob.intraStageDependency.test.ts`
        *   `[âœ…]` 109.c.i. Assert: Skeleton PLAN job `results` field contains `{ required_artifact_identity: { ... } }` with PathContext-shaped identity
        *   `[âœ…]` 109.c.ii. Assert: `required_artifact_identity` includes `projectId`, `sessionId`, `stageSlug`, `iterationNumber`, `modelSlug`, and `documentKey` for the missing input
        *   `[âœ…]` 109.c.iii. Assert: Skeleton job still has `prerequisite_job_id` set to current best-guess job (backward compatible)
    *   `[âœ…]` 109.d. [TEST-UNIT] Unit tests for deferred planning idempotent re-wait behavior in `supabase/functions/dialectic-worker/processComplexJob.intraStageDependency.test.ts`
        *   `[âœ…]` 109.d.i. Assert: When skeleton job wakes and `findSourceDocuments` succeeds, proceeds to plan (existing behavior preserved)
        *   `[âœ…]` 109.d.ii. Assert: When skeleton job wakes and `findSourceDocuments` throws, calls `resolveNextBlocker` with `job.results.required_artifact_identity`
        *   `[âœ…]` 109.d.iii. Assert: When `resolveNextBlocker` returns a different job ID than `job.prerequisite_job_id`, updates job to `waiting_for_prerequisite` with new `prerequisite_job_id` and returns early
        *   `[âœ…]` 109.d.iv. Assert: When `resolveNextBlocker` returns `null`, throws the original `findSourceDocuments` error (real error condition)
        *   `[âœ…]` 109.d.v. Assert: When `resolveNextBlocker` returns the same job ID as current `prerequisite_job_id`, throws the original error (already waiting on correct job, still not ready)
        *   `[âœ…]` 109.d.vi. Assert: Re-chaining logs informative message: `"Re-chaining job {id} to wait for {nextBlocker.id} (type: {nextBlocker.job_type})"`
    *   `[âœ…]` 109.e. [BE] Update skeleton PLAN job creation in `processComplexJob.ts` (lines 716-766)
        *   `[âœ…]` 109.e.i. After line 760 where `skeletonPlanJob` is constructed, set `results: { required_artifact_identity: <PathContext-shaped identity> }`
        *   `[âœ…]` 109.e.ii. Ensure `missingDocumentKey` variable (from line 520-534) is in scope for skeleton creation block
        *   `[âœ…]` 109.e.iii. Verify `results` field passes `isJson` check (line 739)
    *   `[âœ…]` 109.f. [BE] Update deferred planning handler in `processComplexJob.ts` (lines 170-261) to use artifact-driven resolution
        *   `[âœ…]` 109.f.i. Remove lines 191-215 (the current RENDER-checking hack)
        *   `[âœ…]` 109.f.ii. After fetching recipe step (line 186), extract `requiredArtifactIdentity` from `job.results` (PathContext-shaped object); validate shape before use
        *   `[âœ…]` 109.f.iii. Wrap `findSourceDocuments` call (lines 217-222) in try/catch block
        *   `[âœ…]` 109.f.iv. In catch block: call `const nextBlocker = await resolveNextBlocker(deps, { projectId, sessionId, stageSlug, iterationNumber, modelSlug, requiredArtifactIdentity });`
        *   `[âœ…]` 109.f.v. If `nextBlocker !== null && nextBlocker.id !== job.prerequisite_job_id`: log re-chain message, update job to `waiting_for_prerequisite` with `prerequisite_job_id: nextBlocker.id`, return early
        *   `[âœ…]` 109.f.vi. Otherwise (nextBlocker is null or same as current): re-throw the original `findSourceDocuments` error
        *   `[âœ…]` 109.f.vii. Add import for `resolveNextBlocker` at top of file
    *   `[âœ…]` 109.g. [TEST-UNIT] Rerun and verify all unit tests pass
        *   `[âœ…]` 109.g.i. Verify skeleton job creation stores `required_artifact_key`
        *   `[âœ…]` 109.g.ii. Verify deferred planning handler correctly re-chains when artifact not ready
        *   `[âœ…]` 109.g.iii. Verify no regressions in existing `processComplexJob` behavior
    *   `[âœ…]` 109.h. [TEST-INT] Integration test proving artifact-driven resolution works across multiple wake cycles
        *   `[âœ…]` 109.h.i. Assert: Skeleton job waiting on PLAN job, PLAN completes, skeleton wakes, artifact still not ready (EXECUTE running), skeleton re-chains to EXECUTE job
        *   `[âœ…]` 109.h.ii. Assert: Skeleton re-chains from EXECUTE to RENDER when EXECUTE completes but RENDER is pending
        *   `[âœ…]` 109.h.iii. Assert: After RENDER completes, skeleton wakes and successfully proceeds to plan
        *   `[âœ…]` 109.h.iv. Assert: Parenthesis stage with `generate-milestone-schema` waiting on `master_plan` artifact successfully completes after RENDER job finishes
        *   `[âœ…]` 109.h.v. Add test to `supabase/integration_tests/services/handle_job_completion.integration.test.ts` or create new `artifact_driven_prereq.integration.test.ts`
    *   `[âœ…]` 109.i. [CRITERIA] Acceptance criteria
        *   `[âœ…]` 109.i.i. Skeleton jobs store `required_artifact_key` in `results` column (no schema migration required)
        *   `[âœ…]` 109.i.ii. Deferred planning handler never throws `findSourceDocuments` error when artifact is simply not ready yet
        *   `[âœ…]` 109.i.iii. Jobs correctly re-chain through PLAN â†’ EXECUTE â†’ RENDER until artifact exists
        *   `[âœ…]` 109.i.iv. Waking is idempotent: same job can wake multiple times and re-wait without error
        *   `[âœ…]` 109.i.v. Arbitrary-length dependency chains work without special-casing (supports N levels deep)
        *   `[âœ…]` 109.i.vi. When artifact truly cannot be produced (no producing job exists), original error is thrown
        *   `[âœ…]` 109.i.vii. Backward compatible: existing `prerequisite_job_id` field still used, just dynamically updated
    *   `[âœ…]` 109.j. [COMMIT] `fix(dialectic): implement artifact-driven prerequisite resolution with idempotent re-wait`