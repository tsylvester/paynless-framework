# FileManagerService

## Overview

The `FileManagerService` is a critical component within the `supabase/functions/_shared/` directory. Its primary purpose is to provide a centralized and standardized way to manage all file operations related to the Dialectic feature. This service ensures that:

1.  **Consistent File Pathing**: All files are stored in Supabase Storage using a predefined, logical directory structure. This structure is essential for organization, future export features, and potentially for direct user interaction with the file system (e.g., via GitHub integration). The paths are generated by the `constructStoragePath` utility, driven by the `PathContext`.
2.  **Database Synchronization**: Every file uploaded to storage has a corresponding metadata record created in the appropriate database table (`dialectic_project_resources` or `dialectic_contributions`). This link is vital for file discoverability, managing permissions (via RLS on the tables), and associating files with their respective projects, sessions, stages, and AI contributions.
3.  **Simplified File Operations**: It abstracts the complexities of direct Supabase Storage calls and database inserts/updates related to file metadata, providing a simpler API for other backend services.
4.  **Atomic Operations (Best Effort)**: When registering a file, it first uploads to storage and then creates the database record. If the database insert fails, it attempts to clean up the orphaned file from storage.

Using `FileManagerService` for all file-related tasks is **mandatory** to maintain data integrity and consistency across the application.

## Core Concepts

### `FileType`

A string literal union that defines the type of file being handled. This type dictates the storage path construction and the target database table for metadata. Key types include:

```typescript
export enum FileType {
  ProjectReadme = 'project_readme', // The main README for a dialectic project.
  MasterPlan = 'master_plan',
  PendingFile = 'pending_file',
  CurrentFile = 'current_file',
  CompleteFile = 'complete_file',
  InitialUserPrompt = 'initial_user_prompt', // The initial user-provided prompt file for a project.
  UserFeedback = 'user_feedback', // User's consolidated feedback on a stage.
  ModelContributionMain = 'model_contribution_main', // For the primary content (e.g., Markdown) of an AI model's output for a stage.
  ModelContributionRawJson = 'model_contribution_raw_json', // For the raw JSON response from the AI provider for a stage.
  ContributionDocument = 'contribution_document', // A refined/derived document (e.g., PRD, checklist) within a stage's 'documents' folder.
  ProjectSettingsFile = 'project_settings_file',
  GeneralResource = 'general_resource', // A general file resource uploaded by a user for an iteration (in 0_seed_inputs/general_resource).
  SeedPrompt = 'seed_prompt', // The fully constructed prompt sent to a model for a specific stage.
  // Intermediate artifacts for multi-step stages
  PairwiseSynthesisChunk = 'pairwise_synthesis_chunk',
  ReducedSynthesis = 'reduced_synthesis',
  Synthesis = 'synthesis',
  RagContextSummary = 'rag_context_summary',
}
```

### `PathContext`

An object providing the necessary context to construct a unique and correct storage path for a file.

```typescript
export interface PathContext {
  projectId: string;
  fileType: FileType;
  sessionId?: string;
  iteration?: number;
  stageSlug?: string;
  contributionType?: ContributionType | null; // e.g., 'hypothesis', 'critique', 'synthesis' (align with stage or be more specific)
  modelSlug?: string;
  attemptCount?: number;
  originalFileName?: string; // Made optional, validation per fileType
  sourceModelSlugs?: string[];
  sourceAnchorType?: string;
  sourceAnchorModelSlug?: string;
  sourceAttemptCount?: number;
  pairedModelSlug?: string;
  isContinuation?: boolean;
  turnIndex?: number;
}
```

### `UploadContext`

An object containing all information needed by `uploadAndRegisterFile` to store a file and its metadata.

```typescript
export interface UploadContext {
  pathContext: PathContext;
  fileContent: Buffer | ArrayBuffer | string;
  mimeType: string;
  sizeBytes: number;
  userId: string | null; // Allow null for system-generated contributions
  description: string;
  resourceTypeForDb?: string; // To directly populate dialectic_project_resources.resource_type

  // Specific for 'model_contribution_main' fileType
  contributionMetadata?: ContributionMetadata;

  // Specific for 'user_feedback' fileType
  feedbackTypeForDb?: string; // To directly populate dialectic_feedback.feedback_type
  resourceDescriptionForDb?: Json | null; // To directly populate dialectic_feedback.resource_description (jsonb)
}

export interface ContributionMetadata {
  sessionId: string;
  modelIdUsed: string; // FK to ai_providers.id
  modelNameDisplay: string; // For dialectic_contributions.model_name
  stageSlug: string;
  iterationNumber: number;
  rawJsonResponseContent: string; // The actual JSON string content for the raw AI response.
  target_contribution_id?: string;
  document_relationships?: Json | null;
  isIntermediate?: boolean;
  tokensUsedInput?: number;
  tokensUsedOutput?: number;
  processingTimeMs?: number;
  seedPromptStoragePath: string; // Path to the seed prompt that generated this contribution
  citations?: Json | null;
  contributionType?: ContributionType | null;
  errorDetails?: string | null;
  promptTemplateIdUsed?: string | null;
  editVersion?: number;
  isLatestEdit?: boolean;
  originalModelContributionId?: string | null;
  isContinuation?: boolean;
  turnIndex?: number;
}
```

### File Tree Generated by File Manager

{repo_root}/  (Root of the user's GitHub repository)
└── {project_name_slug}/
    ├── project_readme.md      (Optional high-level project description, goals, defined by user or initial setup, *Generated at project finish, not start, not yet implemented*)
    ├── {user_prompt}.md (the initial prompt submitted by the user to begin the project generated by createProject, whether provided as a file or text string, *Generated at project start, implemented*)
    ├── project_settings.json (The json object includes keys for the dialectic_domain row, dialectic_process_template, dialectic_stage_transitions, dialectic_stages, dialectic_process_associations, domain_specific_prompt_overlays, and system_prompt used for the project where the key is the table and the value is an object containing the values of the row, *Generated on project finish, not project start, not yet implemented*)
    ├── {export_project_file}.zip (a zip file of the entire project for the user to download generated by exportProject)
    ├── general_resource (all optional)
    │    ├── `{deployment_context}` (where/how the solution will be implemented), 
    │    ├── `{domain_standards}` (domain-specific quality standards and best practices), 
    │    ├── `{success_criteria}` (measurable outcomes that define success), 
    │    ├── `{constraint_boundaries}` (non-negotiable requirements and limitations), 
    │    ├── `{stakeholder_considerations}` (who will be affected and how),
    │    ├── `{reference_documents}` (user-provided reference materials and existing assets), 
    │    └── `{compliance_requirements}` (regulatory, legal, or organizational compliance mandates)    
    ├── Pending/          (System-managed folder populated as the final step of the Paralysis stage)
    │   └── ...                     (When the user begins their work, they move the first file they're going to work on from Pending to Current)
    ├── Current/          (User-managed folder for the file they are actively working on for this project)
    │   └── ...                     (This is the file the user is currently working on, drawn from Pending)
    ├── Complete/         (User-managed folder for the files they have already completed for this project)       
    │   └── ...                     (When the user finishes all the items in the Current file, they move it to Complete, and move the next Pending file into Current)
    └── session_{session_id_short}/  (Each distinct run of the dialectic process)
        └── iteration_{N}/        (N being the iteration number, e.g., "iteration_1")
            ├── 1_thesis/
            │   ├── raw_responses
            │   │   ├── {model_slug}_{n}_thesis_raw.json
            |   |   └── {model_slug}_{n}_{stage_slug}_continuation_{n}_raw.json
            │   ├── _work/                              (Storage for intermediate, machine-generated artifacts that are not final outputs)
            │   │   ├── {model_slug}_{n}_{stage_slug}_continuation_{n}.md
            │   │   └── ... (other continuations for the same model and other models)
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_{n}_thesis.md (Contains YAML frontmatter + AI response, appends a count so a single model can provide multiple contributions)
            │   ├── ... (other models' hypothesis outputs)
            │   ├── user_feedback_hypothesis.md   (User's feedback on this stage)
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            ├── 2_antithesis/
            │   ├── raw_responses
            │   |   ├── {model_slug}_critiquing_{source_model_slug}_{n}_antithesis_raw.json
            |   |   └── {model_slug}_{n}_{stage_slug}_continuation_{n}_raw.json
            │   ├── _work/                              (Storage for intermediate, machine-generated artifacts that are not final outputs)
            │   │   ├── {model_slug}_{n}_{stage_slug}_continuation_{n}.md
            │   │   └── ... (other continuations for the same model and other models)
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_critiquing_{source_model_slug}_{n}_antithesis.md
            │   ├── ...
            │   ├── user_feedback_antithesis.md
            │   └── documents/                    (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])                
            ├── 3_synthesis/
            │   ├── raw_responses/
            │   │   ├── {model_slug}_from_{source_model_slugs}_{n}_pairwise_synthesis_chunk_raw.json
            │   │   ├── {model_slug}_reducing_{source_contribution_id_short}_{n}_reduced_synthesis_raw.json
            │   │   ├── {model_slug}_{n}_final_synthesis_raw.json
            |   |   └── {model_slug}_{n}_{stage_slug}_continuation_{n}_raw.json
            │   ├── _work/                              (Storage for intermediate, machine-generated artifacts that are not final outputs)
            │   │   ├── {model_slug}_from_{source_model_slugs}_{n}_pairwise_synthesis_chunk.md
            │   │   ├── {model_slug}_reducing_{source_contribution_id_short}_{n}_reduced_synthesis.md
            │   │   ├── {model_slug}_{n}_{stage_slug}_continuation_{n}.md
            │   │   └── ... (other continuations for the same model and other models)
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_{n}_final_synthesis.md
            │   ├── ...
            │   ├── user_feedback_synthesis.md
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │        └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            ├── 4_parenthesis/
            │   ├── raw_responses
            │   │   ├── {model_slug}_{n}_{stage_slug}_raw.json
            |   |   └──{model_slug}_{n}_{stage_slug}_continuation_{n}_raw.json
            │   ├── _work/                              (Storage for intermediate, machine-generated artifacts that are not final outputs)
            │   │   ├── {model_slug}_{n}_{stage_slug}_continuation_{n}.md
            │   │   └── ... (other continuations for the same model and other models)
            │   ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
            │   ├── {model_slug}_{n}_{stage_slug}.md
            │   ├── ...
            │   ├── user_feedback_parenthesis.md
            │   └── documents/                      (Optional refined documents, e.g., PRDs from each model)
            │       └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])
            └── 5_paralysis/
                ├── raw_responses
                │   ├──{model_slug}_{n}_{stage_slug}_raw.json
                |   └──{model_slug}_{n}_{stage_slug}_continuation_{n}_raw.json
                ├── _work/                              (Storage for intermediate, machine-generated artifacts that are not final outputs)
                │   ├── {model_slug}_{n}_{stage_slug}_continuation_{n}.md
                │   └── ... (other continuations for the same model and other models)
                ├── seed_prompt.md  (The complete prompt sent to the model for completion for this stage, including the stage prompt template, stage overlays, and user's input)
                ├── {model_slug}_{n}_{stage_slug}.md
                ├── ...
                └── documents/                      (Optional refined documents, e.g., PRDs from each model)
                    └── (generated from .json object located at Database['dialectic_stages']['row']['expected_output_artifacts'])

## Public Methods

### `constructor(supabaseClient: SupabaseClient<Database>)`

Initializes a new instance of the `FileManagerService`.

*   **Parameters**:
    *   `supabaseClient`: An initialized Supabase client instance.
*   **Throws**:
    *   Error if the `SB_CONTENT_STORAGE_BUCKET` environment variable is not set.

### `async uploadAndRegisterFile(context: UploadContext): Promise<FileManagerResponse>`

Uploads a file to Supabase Storage and creates a corresponding metadata record in either `dialectic_project_resources` or `dialectic_contributions` table based on `context.pathContext.fileType`. If `context.pathContext.fileType` is `'model_contribution_main'` and `context.contributionMetadata.rawJsonResponseContent` is provided, it will also attempt to upload the raw JSON response to a corresponding path.

*   **Parameters**:
    *   `context`: `UploadContext` - The full context for the file upload.
*   **Returns**: `Promise<FileManagerResponse>`
    *   `FileManagerResponse`: An object `{ record: YourTableRecord | null, error: { message: string, details?: string } | null }`.
        *   `record`: The newly created database record from `dialectic_project_resources` or `dialectic_contributions`.
        *   `error`: An error object if the operation failed at any stage (storage upload, database insert).

### `async getFileSignedUrl(fileId: string, table: 'dialectic_project_resources' | 'dialectic_contributions' | 'dialectic_feedback'): Promise<{ signedUrl: string | null; error: Error | null }>`

Retrieves a temporary, short-lived signed URL for a file stored in Supabase Storage, allowing secure, direct client-side access (e.g., for downloads or viewing).

*   **Parameters**:
    *   `fileId`: `string` - The UUID of the file record in the database.
    *   `table`: `'dialectic_project_resources' | 'dialectic_contributions' | 'dialectic_feedback'` - The table where the file's metadata is stored.
*   **Returns**: `Promise<{ signedUrl: string | null; error: Error | null }>`
    *   `signedUrl`: The temporary URL if successful.
    *   `error`: An error object if the file record is not found or URL generation fails.

### `async assembleAndSaveFinalDocument(rootContributionId: string): Promise<{ finalPath: string | null; error: Error | null }>`

Assembles a chain of contribution chunks into a single final document and uploads it, overwriting the content of the root contribution file. This method is crucial for completing "continuation" jobs where a model generates a long document in several parts.

It works by:
1.  Fetching the root contribution to identify the session.
2.  Fetching all contributions for that session.
3.  Traversing the chain of contributions starting from the root, ordering them via the `target_contribution_id` field.
4.  Downloading the content of each chunk in order.
5.  Concatenating the content into a single string.
6.  Uploading the final string to the storage path of the original root contribution, effectively replacing the initial chunk with the complete document.

*   **Parameters**:
    *   `rootContributionId`: `string` - The UUID of the very first contribution record in the continuation chain.
*   **Returns**: `Promise<{ finalPath: string | null; error: Error | null }>`
    *   `finalPath`: The storage path of the final, assembled document if successful.
    *   `error`: An error object if any part of the process fails (fetching, downloading, concatenating, or uploading).

## Architecture and Testing

To ensure the `FileManagerService` is reliable and easy to test, its implementation follows the Dependency Inversion Principle.

### `IFileManager` Interface

The core of the architecture is the `IFileManager` interface (defined in `supabase/functions/_shared/types/file_manager.types.ts`). This interface defines the public contract for any file manager implementation.

```typescript
// From: supabase/functions/_shared/types/file_manager.types.ts
export interface IFileManager {
  uploadAndRegisterFile(context: UploadContext): Promise<FileManagerResponse>;
  assembleAndSaveFinalDocument(rootContributionId: string): Promise<{ finalPath: string | null; error: Error | null; }>;
  getFileSignedUrl(fileId: string, table: 'dialectic_project_resources' | 'dialectic_contributions' | 'dialectic_feedback'): Promise<{ signedUrl: string | null; error: Error | null }>;
}
```

By depending on this abstraction rather than the concrete `FileManagerService` class, other services can easily swap the real implementation with a mock for testing purposes.

### `MockFileManagerService`

For unit testing services that use the file manager, a mock implementation, `MockFileManagerService`, is provided in `supabase/functions/_shared/services/file_manager.mock.ts`.

This mock class implements the `IFileManager` interface. Its methods are Deno `spy` objects, which allows for:

1.  **Configuring Return Values**: You can set up the mock to return specific success or error responses for different test scenarios.
2.  **Asserting Calls**: You can verify that the file manager's methods were called with the correct arguments and the expected number of times.

#### Example Usage in a Test:

```typescript
// In a test file (e.g., executeModelCallAndSave.test.ts)
import { MockFileManagerService } from '../_shared/services/file_manager.mock.ts';
import { assertEquals } from 'https://deno.land/std/testing/asserts.ts';

Deno.test('some function should call assembleAndSaveFinalDocument on stop', async () => {
  // 1. Setup
  const fileManager = new MockFileManagerService();
  const deps = { fileManager }; // Dependencies for the function under test

  const rootId = 'some-root-id';
  // ... logic to call your service/function which should trigger the assembly
  await myFunctionThatUsesFileManager(deps, rootId);

  // 2. Assert
  const assembleSpy = fileManager.assembleAndSaveFinalDocument;
  assertEquals(assembleSpy.calls.length, 1);
  assertEquals(assembleSpy.calls[0].args[0], rootId);
});
```

## Usage Examples

It's crucial that other backend services (Edge Functions) use `FileManagerService` for any operation that involves writing files related to the Dialectic feature.

### 1. Project Creation (`createProject.ts`)

When a user creates a new project and optionally uploads an initial prompt file:

```typescript
// In supabase/functions/dialectic-service/createProject.ts

// ... (setup, payload parsing)
if (promptFile) {
  const fileManager = new FileManagerService(dbAdminClient);
  const fileBuffer = await promptFile.arrayBuffer();

  const uploadResult = await fileManager.uploadAndRegisterFile({
    pathContext: {
      projectId: newProjectData.id,
      fileType: 'initial_user_prompt',
      originalFileName: promptFile.name,
    },
    fileContent: Buffer.from(fileBuffer),
    mimeType: promptFile.type,
    sizeBytes: promptFile.size,
    userId: user.id,
    description: 'Initial project prompt file',
  });

  if (uploadResult.error || !uploadResult.record) {
    // Handle error, potentially roll back project creation
    console.error("Error uploading initial prompt file:", uploadResult.error);
    // ...
  } else {
    // Link uploadResult.record.id to dialectic_projects.initial_prompt_resource_id
  }
}
// ...
```

### 2. Session Start (`startSession.ts`)

When a new Dialectic session is initiated, the fully assembled seed prompt is saved using the `FileManagerService`.

```typescript
// In supabase/functions/dialectic-service/startSession.ts

// ... (after assembling the seed prompt into `assembledSeedPrompt`)
const seedPromptBuffer = Buffer.from(assembledSeedPrompt, 'utf-8');
const seedPromptUploadResult = await fileManager.uploadAndRegisterFile({
    pathContext: {
        projectId: project.id,
        fileType: FileType.SeedPrompt, 
        sessionId: newSessionRecord.id,
        iteration: 1,
        stageSlug: stageContext.slug,
        originalFileName: `seed_prompt.md`,
    },
    fileContent: seedPromptBuffer,
    mimeType: 'text/markdown',
    sizeBytes: seedPromptBuffer.byteLength,
    userId: userId,
    description: formatResourceDescription({
        type: 'seed_prompt',
        session_id: newSessionRecord.id,
        stage_slug: stageContext.slug,
        iteration: 1,
        original_file_name: `seed_prompt.md`,
        project_id: project.id,
    }),
});

if (seedPromptUploadResult.error || !seedPromptUploadResult.record) {
    // Handle error
}
// ...
```

### 3. Saving AI Model Contributions (`generateContributions.ts`)

When an AI model generates content for a stage (e.g., Thesis, Synthesis):

```typescript
// In supabase/functions/dialectic-service/generateContributions.ts (simplified)

// ... (after receiving aiResponse from callUnifiedAIModel)
const fileManager = new FileManagerService(dbClient);

const contributionUpload = await fileManager.uploadAndRegisterFile({
  pathContext: {
    projectId: sessionDetails.project_id,
    sessionId: sessionDetails.id,
    iteration: currentIterationNumber,
    stageSlug: stage.slug,
    modelSlug: sanitizeForPath(providerDetails.api_identifier || providerDetails.name),
    originalFileName: `${sanitizeForPath(providerDetails.api_identifier || providerDetails.name)}_${stage.slug}.md`,
    fileType: 'model_contribution_main',
  },
  fileContent: aiResponse.content, // The main Markdown/text output
  mimeType: aiResponse.contentType || 'text/markdown',
  sizeBytes: new TextEncoder().encode(aiResponse.content).length,
  userId: null, // AI contributions are system-generated in this context
  description: `Contribution for stage ${stage.slug} from model ${providerDetails.name}`,
  contributionMetadata: {
    sessionId: sessionDetails.id,
    rawJsonResponseContent: JSON.stringify(aiResponse.rawProviderResponse || {}), // The raw JSON
    modelIdUsed: modelIdForCall, // Actual ID of the AI provider/model config
    modelNameDisplay: providerDetails.name,
    stageSlug: stage.slug,
    iterationNumber: currentIterationNumber,
    tokensUsedInput: aiResponse.inputTokens,
    tokensUsedOutput: aiResponse.outputTokens,
    processingTimeMs: aiResponse.processingTimeMs,
    seedPromptStoragePath: seedPromptResource?.storage_path, // Path of the seed prompt file used
    // ... other metadata like citations, contributionType, etc.
  }
});

if (contributionUpload.error || !contributionUpload.record) {
  // Handle failed contribution saving
} else {
  // `contributionUpload.record` is the new dialectic_contributions row
  // Note: The raw JSON is uploaded by FileManagerService itself if rawJsonResponseContent is provided.
  // The path to the raw JSON is stored in `contributionUpload.record.raw_response_storage_path`.
}
// ...
```

### 4. Cloning a Project (Conceptual) (`cloneProject.ts`)

When cloning a project, `FileManagerService` would be used to duplicate each file from the source project into the new project's structure, creating new database records for each.

```typescript
// In supabase/functions/dialectic-service/cloneProject.ts (conceptual)

// ... (create new project record for `newProjectId`)
const fileManager = new FileManagerService(dbClient);

// 1. Fetch all `dialectic_project_resources` for `sourceProjectId`
for (const resource of sourceProjectResources) {
  // 2. Download/read content of `resource.storage_path`
  const { data: fileBlob, error: downloadError } = await dbClient.storage
    .from(resource.storage_bucket)
    .download(resource.storage_path);
  
  if (downloadError || !fileBlob) continue; // Skip if cannot download
  const fileContent = await fileBlob.arrayBuffer();

  // 3. Upload and register for the new project
  await fileManager.uploadAndRegisterFile({
    pathContext: {
      projectId: newProjectId, // New project ID
      fileType: resource.file_type, // Assuming file_type is stored or can be derived
      originalFileName: resource.file_name,
      // NOTE: `fileType` might need adjustment if it implies unique roles like 'initial_user_prompt'
      // It might be better to classify cloned files as 'general_resource' or similar in the new project.
    },
    fileContent: Buffer.from(fileContent),
    mimeType: resource.mime_type,
    sizeBytes: resource.size_bytes,
    userId: newProjectOwnerId,
    description: resource.resource_description, // Copy description
  });
}

// 4. Repeat for `dialectic_contributions` across all sessions of the source project,
//    adjusting `sessionId`, `iteration`, etc., for the new project structure.
// ...
```

## Important Considerations

*   **Central Authority**: Treat `FileManagerService` as the sole authority for creating file records and determining storage paths. Directly manipulating Supabase Storage or the file metadata tables (`dialectic_project_resources`, `dialectic_contributions`) outside of this service will lead to inconsistencies and bugs.
*   **Environment Variables**: The service relies on `SB_CONTENT_STORAGE_BUCKET` being correctly set in your Supabase project's environment variables.
*   **Error Handling**: Always check the `error` field in the response from `uploadAndRegisterFile`. Implement appropriate rollback or compensation logic in the calling service if an error occurs (e.g., deleting a newly created project record if its initial prompt file fails to upload).
*   **Database Schema**: The `FileManagerService` assumes the structure of `dialectic_project_resources` and `dialectic_contributions` tables matches the fields it attempts to populate. Ensure your database migrations align with these expectations (see `types_db.ts`).
*   **Testing**: When writing unit tests for services that depend on file operations, always inject `MockFileManagerService` to isolate your tests from the actual database and storage.

By adhering to the `FileManagerService`, developers can ensure a robust, maintainable, and consistent file management system for the Dialectic feature. 